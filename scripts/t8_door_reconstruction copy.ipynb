{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph\n",
    "import rdflib\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t8_utils as t8\n",
    "\n",
    "from typing import Dict, Any, Tuple,List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[0]\n",
    "\n",
    "print(path)\n",
    "input_folder_t4=path/'data'/'t4'/'train' \n",
    "input_folder_t6=path/'data'/'t6'/'train'\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t8'/ 'train'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "grid_resolution = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_walls...\n",
      "145 wallNodes detected!\n"
     ]
    }
   ],
   "source": [
    "graphfiles=utl.get_list_of_files(input_folder_t6,'.ttl')\n",
    "for f in graphfiles[:1]: #only read the first one\n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    wallNodes=tl.graph_path_to_nodes(f)\n",
    "    \n",
    "    for n in wallNodes:\n",
    "        n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(n.orientedBounds)))\n",
    "\n",
    "    print(f'{len(wallNodes)} wallNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_small1...\n"
     ]
    }
   ],
   "source": [
    "pcdfiles=utl.get_list_of_files(input_folder_t4,'.laz')\n",
    "for f_pcd in pcdfiles[:1]: #only read the first one\n",
    "    pcdNodes = t8.match_graph_with_las(f_pcd,class_dict, nodes = wallNodes, getResources=True, getNormals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallNodes: \n",
    "    n.derivedFrom = next((p for p in pcdNodes if n.object_id == p.object_id), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dtrings from the graph to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallNodes:\n",
    "    n.startpoint = ut.literal_to_array(n.start_pt) #np.asarray(n.start_pt[1:-1].split(), dtype=float)\n",
    "    n.endpoint = ut.literal_to_array(n.end_pt) #np.asarray(n.end_pt[1:-1].split(), dtype=float)\n",
    "    n.normal = ut.literal_to_array(n.normal) #np.asarray(n.normal[1:-1].split(), dtype=float)\n",
    "    n.height = float(n.height)\n",
    "    n.name = n.subject.split('///')[-1]\n",
    "    if n.width == 0.127 or n.width == 0.2:\n",
    "        n.singleFaced = True\n",
    "    else:\n",
    "        n.singleFaced = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the full point cloud into a mesh and add it to a raycasting scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxelsize =  0.018880786132812497\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cut a part out of the full resolution pointcloud\n",
    "# joined_pcd = full_res_point_cloud_o3d.crop(expanded_bounding_box)\n",
    "#Create a messh from this point cloud \n",
    "octree=pt.pcd_to_octree(gmu.join_geometries([n.pcd for n in pcdNodes]),12) #if octree is None else octree\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "\n",
    "\n",
    "#Create a identity array containing the color so this can be retrieved afterwards\n",
    "original_colors=np.asarray(mesh.vertex_colors)\n",
    "indices=np.asarray(mesh.triangles)[:,0]\n",
    "triangle_colors=original_colors[indices]\n",
    "#append black color at the end of the array for the invalid hits\n",
    "triangle_colors=np.vstack((triangle_colors,np.array([0,0,0])))\n",
    "\n",
    "# Create raycasting scene\n",
    "scene = o3d.t.geometry.RaycastingScene()\n",
    "mesh=o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "scene.add_triangles(mesh) \n",
    "\n",
    "# Calculate the size of each octree node based on octree depth and overall size\n",
    "def calculate_node_size(octree_depth, octree_size):\n",
    "    num_voxels_per_dim = 2 ** octree_depth\n",
    "    voxel_size = octree_size / num_voxels_per_dim\n",
    "    return voxel_size\n",
    "\n",
    "# Example usage:\n",
    "octree_depth = octree.max_depth  # Example value for max_depth\n",
    "octree_size = octree.size  # Example size of the octree in world units\n",
    "voxel_size = calculate_node_size(octree_depth, octree_size)\n",
    "print(\"Voxelsize = \", voxel_size)\n",
    "octree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the pointcloud and wall data to create an ortho foto of the wall and use object detection\n",
    "(Can also be used to retrieve other elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 0.01\n",
    "\n",
    "for n in wallNodes:\n",
    "    \n",
    "    length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "    surface = length * n.height\n",
    "    image_size = (int(length / image_resolution), int(n.height / image_resolution))\n",
    "    n.orthos = []\n",
    "    \n",
    "\n",
    "    if not surface < 3 and n.height > 1.5 and length > 0.8:  \n",
    "        #Create an ortho of the dominant side of the wall      \n",
    "        ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = n.normal, scene=scene, triangle_colors = triangle_colors)\n",
    "        ortho = t8.fill_black_pixels(ortho, region = 10)\n",
    "        n.orthos.append(ortho)\n",
    "        #Also create an ortho of the other side of the wall\n",
    "        if not n.singleFaced: #Single faced wall only needs one side\n",
    "            ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = -n.normal, scene=scene, triangle_colors = triangle_colors, dominant = False)\n",
    "            ortho = t8.fill_black_pixels(ortho, region = 10)\n",
    "            n.orthos.append(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounding DINO\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "# from segment_anything import build_sam, SamPredictor \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# diffusers\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1711403380909/work/aten/src/ATen/native/TensorShape.cpp:3549.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "Model loaded from /home/sdegeyter/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    groundingdino_model = t8.load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pointcloud = []\n",
    "\n",
    "\n",
    "for n in wallNodes:\n",
    "    TEXT_PROMPT = \"Door\"\n",
    "    BOX_TRESHOLD = 0.20\n",
    "    TEXT_TRESHOLD = 0.5\n",
    "    \n",
    "    n.boxes = []\n",
    "    n.logits = []\n",
    "    n.phrases = []\n",
    "    \n",
    "    if len(n.orthos) > 0:\n",
    "        for ortho in n.orthos:\n",
    "            boxes = None\n",
    "            image = load_image(Image.fromarray((ortho * 255).astype(np.uint8)))\n",
    "\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=groundingdino_model, \n",
    "                image=image, \n",
    "                caption=TEXT_PROMPT, \n",
    "                box_threshold=BOX_TRESHOLD, \n",
    "                text_threshold=TEXT_TRESHOLD\n",
    "            )\n",
    "            \n",
    "            n.boxes.append(boxes)\n",
    "            n.logits.append(logits)\n",
    "            n.phrases.append(phrases)                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_of_values_smaller_than_max(arr):\n",
    "    \"\"\"\n",
    "    Return the indices of all values in the array that are smaller than the maximum value.\n",
    "\n",
    "    Args:\n",
    "        arr (np.ndarray): The input array.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Indices of values smaller than the maximum value.\n",
    "    \"\"\"\n",
    "    if np.asarray(arr).size == 0:\n",
    "        return np.array([])  # Return an empty array if the input is empty\n",
    "    \n",
    "    max_value = np.max(arr)\n",
    "    indices = np.where(arr < max_value)[0]\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doors_0 : Door Score: 0.7873185962438585 => Referencelevel: 0.01; Width: 0.85; height: 2.2\n",
      "Doors_1 : Door Score: 0.7782544881105424 => Referencelevel: 0.01; Width: 0.63; height: 2.19\n",
      "Doors_2 : Door Score: 0.9826827863515967 => Referencelevel: 0.0; Width: 1.3; height: 2.31\n",
      "Doors_3 : Door Score: 0.850829178094864 => Referencelevel: 0.02; Width: 1.16; height: 2.21\n",
      "Doors_4 : Door Score: 0.8595124125480653 => Referencelevel: 0.01; Width: 0.88; height: 2.1\n",
      "Doors_5 : Door Score: 0.9618811101730369 => Referencelevel: 0.02; Width: 0.92; height: 2.09\n",
      "Doors_6 : Door Score: 0.8628721674283347 => Referencelevel: 0.03; Width: 0.89; height: 2.07\n",
      "Doors_7 : Door Score: 0.9774538766160762 => Referencelevel: 0.02; Width: 1.05; height: 2.2\n",
      "Doors_8 : Door Score: 0.8504207770029705 => Referencelevel: 0.01; Width: 0.94; height: 2.12\n",
      "Doors_9 : Door Score: 0.7751466025908789 => Referencelevel: 0.05; Width: 1.26; height: 2.2\n",
      "Doors_10 : Door Score: 0.8329984784126283 => Referencelevel: 0.04; Width: 1.16; height: 2.15\n",
      "Doors_11 : Door Score: 0.8007132848103842 => Referencelevel: 0.04; Width: 1.16; height: 2.16\n",
      "Doors_12 : Door Score: 0.8413719673951467 => Referencelevel: 0.01; Width: 1.14; height: 2.21\n",
      "Doors_13 : Door Score: 0.8052024930715562 => Referencelevel: 0.02; Width: 1.14; height: 2.2\n",
      "Doors_14 : Door Score: 0.8069887797037761 => Referencelevel: 0.01; Width: 1.13; height: 2.2\n",
      "Doors_15 : Door Score: 0.7827632913986843 => Referencelevel: 0.02; Width: 1.13; height: 2.19\n",
      "Doors_16 : Door Score: 0.7669798100988071 => Referencelevel: 0.04; Width: 1.14; height: 2.15\n",
      "Doors_17 : Door Score: 0.9482494525104153 => Referencelevel: 0.02; Width: 0.97; height: 2.37\n",
      "Doors_18 : Door Score: 0.9555332693847828 => Referencelevel: 0.07; Width: 1.04; height: 2.15\n",
      "Doors_19 : Door Score: 0.8323256711165111 => Referencelevel: 0.03; Width: 1.14; height: 2.19\n",
      "Doors_20 : Door Score: 0.8354633490244548 => Referencelevel: 0.02; Width: 1.14; height: 2.2\n",
      "Doors_21 : Door Score: 0.8301724831263225 => Referencelevel: 0.02; Width: 0.86; height: 2.12\n",
      "Doors_22 : Door Score: 0.7689594144622486 => Referencelevel: 0.03; Width: 1.01; height: 2.19\n",
      "Doors_23 : Door Score: 0.9707322049207827 => Referencelevel: 0.03; Width: 1.15; height: 2.2\n",
      "Doors_24 : Door Score: 0.8302534560362499 => Referencelevel: 0.01; Width: 1.12; height: 2.21\n",
      "Doors_25 : Door Score: 0.7831167519092561 => Referencelevel: 0.02; Width: 0.78; height: 2.2\n",
      "Doors_26 : Door Score: 0.7701271166404089 => Referencelevel: 0.0; Width: 0.82; height: 2.39\n",
      "Doors_27 : Door Score: 0.8448898434638978 => Referencelevel: 0.02; Width: 0.83; height: 2.09\n",
      "Doors_28 : Door Score: 0.8287272691726686 => Referencelevel: 0.03; Width: 1.14; height: 2.19\n",
      "Doors_29 : Door Score: 0.9642500178254982 => Referencelevel: 0.03; Width: 1.16; height: 2.21\n",
      "Doors_30 : Door Score: 0.8576863845189413 => Referencelevel: 0.01; Width: 1.14; height: 2.21\n",
      "Doors_31 : Door Score: 0.8534509976704916 => Referencelevel: 0.02; Width: 1.13; height: 2.21\n",
      "Doors_32 : Door Score: 0.847329471508662 => Referencelevel: 0.01; Width: 1.12; height: 2.21\n",
      "Doors_33 : Door Score: 0.8445894161860149 => Referencelevel: 0.02; Width: 1.17; height: 2.22\n",
      "Doors_34 : Door Score: 0.9667297632314706 => Referencelevel: 0.01; Width: 1.16; height: 2.22\n",
      "Doors_35 : Door Score: 0.9767087657120884 => Referencelevel: 0.0; Width: 1.18; height: 2.23\n",
      "Doors_36 : Door Score: 0.8163191169500352 => Referencelevel: 0.01; Width: 1.17; height: 2.22\n",
      "Doors_37 : Door Score: 0.7851596464713415 => Referencelevel: 0.03; Width: 1.15; height: 2.19\n",
      "Doors_38 : Door Score: 0.795103360215823 => Referencelevel: 0.04; Width: 1.14; height: 2.17\n",
      "Doors_39 : Door Score: 0.7955130527416866 => Referencelevel: 0.04; Width: 1.14; height: 2.17\n",
      "Doors_40 : Door Score: 0.7923954615990322 => Referencelevel: 0.04; Width: 1.1; height: 2.16\n",
      "Doors_41 : Door Score: 0.8039199004570644 => Referencelevel: 0.0; Width: 0.88; height: 2.18\n",
      "Doors_42 : Door Score: 0.8466259578863781 => Referencelevel: 0.02; Width: 1.14; height: 2.21\n",
      "Doors_43 : Door Score: 0.8472904304663341 => Referencelevel: 0.02; Width: 1.12; height: 2.21\n",
      "Doors_44 : Door Score: 0.977105428346461 => Referencelevel: 0.04; Width: 1.19; height: 2.19\n",
      "Doors_45 : Door Score: 0.957938745303896 => Referencelevel: 0.03; Width: 1.31; height: 2.23\n",
      "Doors_46 : Door Score: 0.9661023173829595 => Referencelevel: 0.13; Width: 0.78; height: 2.04\n",
      "Doors_47 : Door Score: 0.9455895292585701 => Referencelevel: 0.01; Width: 1.18; height: 2.22\n",
      "Doors_48 : Door Score: 0.9663863344057978 => Referencelevel: 0.02; Width: 0.72; height: 2.11\n",
      "Doors_49 : Door Score: 0.979683293325667 => Referencelevel: 0.02; Width: 1.08; height: 2.21\n",
      "Doors_50 : Door Score: 0.8141814907391867 => Referencelevel: 0.01; Width: 1.13; height: 2.22\n",
      "Doors_51 : Door Score: 0.7882613430420559 => Referencelevel: 0.02; Width: 1.15; height: 2.21\n",
      "Doors_52 : Door Score: 0.9738242239249766 => Referencelevel: 0.02; Width: 1.15; height: 2.21\n",
      "Doors_53 : Door Score: 0.9723942126981553 => Referencelevel: 0.01; Width: 1.16; height: 2.21\n",
      "Doors_54 : Door Score: 0.971340061484659 => Referencelevel: 0.01; Width: 1.15; height: 2.21\n",
      "Doors_55 : Door Score: 0.8465007682641348 => Referencelevel: 0.02; Width: 0.93; height: 2.16\n",
      "Doors_56 : Door Score: 0.7707312817374866 => Referencelevel: 0.02; Width: 0.98; height: 2.15\n",
      "Doors_57 : Door Score: 0.7951745827992758 => Referencelevel: 0.01; Width: 1.13; height: 2.21\n",
      "Doors_58 : Door Score: 0.812789896130562 => Referencelevel: 0.01; Width: 1.19; height: 2.24\n",
      "Doors_59 : Door Score: 0.8571037391821544 => Referencelevel: 0.01; Width: 1.14; height: 2.21\n",
      "Doors_60 : Door Score: 0.8307584663232168 => Referencelevel: 0.02; Width: 1.13; height: 2.2\n",
      "Doors_61 : Door Score: 0.825841381152471 => Referencelevel: 0.03; Width: 1.14; height: 2.19\n",
      "Doors_62 : Door Score: 0.849181228876114 => Referencelevel: 0.02; Width: 1.12; height: 2.2\n",
      "Doors_63 : Door Score: 0.8519775311152141 => Referencelevel: 0.02; Width: 1.11; height: 2.21\n",
      "Doors_64 : Door Score: 0.8420666197935741 => Referencelevel: 0.02; Width: 1.12; height: 2.21\n",
      "Doors_65 : Door Score: 0.9738979722954834 => Referencelevel: 0.02; Width: 1.14; height: 2.21\n",
      "Doors_66 : Door Score: 0.9795775032026424 => Referencelevel: 0.01; Width: 1.07; height: 2.21\n",
      "Doors_67 : Door Score: 0.9757749096123813 => Referencelevel: 0.01; Width: 1.16; height: 2.22\n",
      "Doors_68 : Door Score: 0.8317899644374849 => Referencelevel: 0.01; Width: 1.13; height: 2.21\n",
      "1.0763768115942027\n",
      "[[0, 1, 15], [2, 12, 18], [3], [4], [5], [6], [7], [8], [9], [10], [11], [13], [14, 16, 17, 23], [19, 21, 24, 25, 68], [20], [22], [26], [27], [28], [29], [30], [31], [32], [33], [34], [35], [36], [37, 40, 41], [38, 39], [42, 43, 46], [44], [45], [47], [48], [49], [50], [51], [52], [53], [54], [55], [56, 57], [58], [59], [60], [61], [62], [63], [64], [65], [66], [67]]\n",
      "[['Doors_0', 0.7873185962438585], ['Doors_1', 0.7782544881105424], ['Doors_15', 0.7827632913986843]]\n",
      "[['Doors_2', 0.9826827863515967], ['Doors_12', 0.8413719673951467], ['Doors_18', 0.9555332693847828]]\n",
      "[['Doors_14', 0.8069887797037761], ['Doors_16', 0.7669798100988071], ['Doors_17', 0.9482494525104153], ['Doors_23', 0.9707322049207827]]\n",
      "[['Doors_19', 0.8323256711165111], ['Doors_21', 0.8301724831263225], ['Doors_24', 0.8302534560362499], ['Doors_25', 0.7831167519092561], ['Doors_68', 0.8317899644374849]]\n",
      "[['Doors_37', 0.7851596464713415], ['Doors_40', 0.7923954615990322], ['Doors_41', 0.8039199004570644]]\n",
      "[['Doors_38', 0.795103360215823], ['Doors_39', 0.7955130527416866]]\n",
      "[['Doors_42', 0.8466259578863781], ['Doors_43', 0.8472904304663341], ['Doors_46', 0.9661023173829595]]\n",
      "[['Doors_56', 0.7707312817374866], ['Doors_57', 0.7951745827992758]]\n",
      "Number of doors: 69\n"
     ]
    }
   ],
   "source": [
    "from utils.t8_utils import calculate_percentage_black_pixels\n",
    "\n",
    "\n",
    "doorNodes = []\n",
    "pointcloud = []\n",
    "\n",
    "wall = 0\n",
    "door_count = 0\n",
    "image = 0\n",
    "id_count = 4000\n",
    "    \n",
    "door_count = 0\n",
    "doorNodes = []\n",
    "\n",
    "class_id = 5\n",
    "for n in wallNodes:#[72:73]: #^22:24 interessante muren\n",
    "    potential_door_boxes_wall = []\n",
    "    potential_door_info_wall = []\n",
    "    \n",
    "    if (len(n.orthos) == 1 and len(n.boxes[0]) > 0) or len(n.orthos) == 2 and (len(n.boxes[0]) > 0 or len(n.boxes[1]) > 0) :\n",
    "        for j, boxes in enumerate(n.boxes):\n",
    "            potential_door_boxes_face = []\n",
    "            potential_door_info_face = []\n",
    "            if len(boxes) > 0: \n",
    "                for i, box in enumerate(boxes):\n",
    "                    probability = float(n.logits[j][i])\n",
    "                    opening_width = round(int(np.asarray(box)[2]*n.orthos[j].shape[1])* image_resolution, 2)    \n",
    "                    opening_height = round(int(np.asarray(box)[3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                    \n",
    "                    detection_center_u = int(np.asarray(box)[0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(box)[1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                    \n",
    "                    reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                    # print((str(j) + \"-\" +str(image)))\n",
    "                    score = t8.is_door(probability, opening_width, opening_height, reference_level, prob_weight=0.15, width_weight=0.15, height_weight=0.3, ref_level_weight=0.3, name = (str(j) + \"-\" +str(image)) )\n",
    "                    \n",
    "                    if score >= 0.6:\n",
    "                        # annotated_frame = annotate(image_source= n.orthos[j], boxes=box.unsqueeze(0), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[j][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(wall) + \"-Face_\" + str(j) +\"-\" +str(image) +\"-\"+  str(score) +'-DOOR.png')))\n",
    "                        # image += 1\n",
    "                        \n",
    "                        box1 = copy.deepcopy(box)\n",
    "                        box = box.unsqueeze(0)\n",
    "\n",
    "                        if j == 1:\n",
    "                            box1[0] = 1-box1[0]\n",
    "\n",
    "                        potential_door_boxes_face.append(np.asarray(box1))\n",
    "                        potential_door_info_face.append([opening_width, opening_height, image, reference_level, score])\n",
    "                            \n",
    "            potential_door_boxes_wall.append(potential_door_boxes_face)\n",
    "            potential_door_info_wall.append(potential_door_info_face)\n",
    "            \n",
    "        #merge largely overlapping bounding boxes\n",
    "        for i, face_boxes in enumerate(potential_door_boxes_wall):\n",
    "            face_boxes = t8.find_and_merge_high_iou_boxes(face_boxes, threshold=0.8, info = potential_door_info_wall[i])\n",
    "    \n",
    "        #For Double faced walls look if the detection is found on both sides.\n",
    "        if len(potential_door_boxes_wall) == 2 and not len(potential_door_boxes_wall[0]) == 0 and not len(potential_door_boxes_wall[1]) == 0:\n",
    "            # print(\"Double Faced\")\n",
    "            matches, unmatched_boxes0, unmatched_boxes1 = t8.find_best_matches(potential_door_boxes_wall[0], potential_door_boxes_wall[1], potential_door_info_wall[0], potential_door_info_wall[1], iou_weight=0.33, param_weight=0.33, doorness_weight=0.33)\n",
    "\n",
    "            for id0, id1, bestscore in matches:\n",
    "                if not id0 == None and not id1 == None:\n",
    "                    # compare the parameters of the different matches\n",
    "                    info0 = potential_door_info_wall[0][id0]\n",
    "                    info1 = potential_door_info_wall[1][id1]\n",
    "          \n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(np.asarray([potential_door_boxes_wall[0][id0]])), logits=torch.from_numpy(np.array([info0[-1]])), phrases=[n.phrases[0][id0]])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(wall) + \"-Face_0-\" +str(image) +\"-\"+  str(info0[-1]) +'-DOOR.png')))\n",
    "                    # image += 1\n",
    "                    \n",
    "                    # annotated_frame = annotate(image_source= n.orthos[1], boxes=torch.from_numpy(np.asarray([potential_door_boxes_wall[1][id1]])), logits=torch.from_numpy(np.array([info1[-1]])), phrases=[n.phrases[1][id1]])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(wall) + \"-Face_1-\" +str(image) +\"-\"+  str(info1[-1]) +'-DOOR.png')))\n",
    "                    # image += 1\n",
    "                    \n",
    "                    detectionbox = t8.combine_boxes(potential_door_boxes_wall[0][id0], potential_door_boxes_wall[1][id1])\n",
    "                    \n",
    "                    opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                    # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                    \n",
    "                    boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                    \n",
    "                    doornode = BIMNode(\n",
    "                        name= \"Doors_\" + str(door_count),\n",
    "                        axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                        startpoint= boundaryPoints[0],\n",
    "                        endpoint= boundaryPoints[1],\n",
    "                        doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                        height = opening_height,\n",
    "                        doornessScore = bestscore,\n",
    "                        singleFaced = False,\n",
    "                        depth = n.width,\n",
    "                        object_id = class_id *4000 + door_count,\n",
    "                        blackness = percentage_black_pixles,\n",
    "                        host = n)\n",
    "                    \n",
    "                    doorNodes.append(doornode)\n",
    "                    print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                    door_count += 1 \n",
    "                    \n",
    "            #If the detection is not found on both sides of the wall but it is a double faced wall we add a penalty\n",
    "            for id0 in unmatched_boxes0: #Two faced walls with a detection on only one side\n",
    "                score = potential_door_info_wall[0][id0][4]-0.2\n",
    "                if score > 0.7:\n",
    "                    detectionbox = np.array([potential_door_boxes_wall[0][id0]])\n",
    "                    \n",
    "                    opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                    \n",
    "                    boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "        \n",
    "                    doornode = BIMNode(\n",
    "                        name= \"Doors_\" + str(door_count),\n",
    "                        axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                        startpoint= boundaryPoints[0],\n",
    "                        endpoint= boundaryPoints[1],\n",
    "                        doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                        height = opening_height,\n",
    "                        doornessScore = score,\n",
    "                        singleFaced = True,\n",
    "                        depth = n.width,\n",
    "                        object_id = class_id *4000 + door_count,\n",
    "                        blackness = percentage_black_pixles,\n",
    "                        host = n)\n",
    "                    \n",
    "                    doorNodes.append(doornode)\n",
    "                    print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                    door_count += 1 \n",
    "                \n",
    "            for id1 in unmatched_boxes1: #Two faced walls with a detection on only one side\n",
    "                score = potential_door_info_wall[1][id1][4]-0.2\n",
    "                if score > 0.7:\n",
    "                    detectionbox = np.array([potential_door_boxes_wall[1][id1]])\n",
    "\n",
    "                    opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[1], image_resolution = image_resolution)\n",
    "                      \n",
    "                    boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                    doornode = BIMNode(\n",
    "                        name= \"Doors_\" + str(door_count),\n",
    "                        axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                        startpoint= boundaryPoints[0],\n",
    "                        endpoint= boundaryPoints[1],\n",
    "                        doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                        height = opening_height,\n",
    "                        doornessScore = score,\n",
    "                        singleFaced = True,\n",
    "                        depth = n.width,\n",
    "                        object_id = class_id *4000 + door_count,\n",
    "                        blackness = percentage_black_pixles,\n",
    "                        host = n)\n",
    "                    \n",
    "                    doorNodes.append(doornode)\n",
    "                    print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                    door_count += 1 \n",
    "\n",
    "        else: #For single faced walls\n",
    "            for i, box in enumerate(potential_door_boxes_wall[0]):\n",
    "                #This are single faced walls so the penalty is less.\n",
    "                score = potential_door_info_wall[0][i][4]-0.1\n",
    "                # image_resource = t8.extract_box_with_margin(n.orthos[0], np.array([box])[0])\n",
    "                # image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                # Image.fromarray(image_resource).save(os.path.join(output_folder,(\"BlackDoor_\" + str(door_count) + '.png')))\n",
    "                # bl_px = t8.calculate_percentage_black_pixels(image_resource)\n",
    "                \n",
    "                if score > 0.75: #and bl_px > 0.6:\n",
    "                    detectionbox = np.array([box])\n",
    "                    \n",
    "                    opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                     \n",
    "                    boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                    doornode = BIMNode(\n",
    "                        name= \"Doors_\" + str(door_count),\n",
    "                        axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                        startpoint= boundaryPoints[0],\n",
    "                        endpoint= boundaryPoints[1],\n",
    "                        doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                        height = opening_height,\n",
    "                        doornessScore = score,\n",
    "                        singleFaced = True,\n",
    "                        depth = n.width,\n",
    "                        object_id = class_id *4000 + door_count,\n",
    "                        blackness = percentage_black_pixles,\n",
    "                        host = n)\n",
    "                    \n",
    "                    doorNodes.append(doornode)\n",
    "                    print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                    door_count += 1 \n",
    "          \n",
    "            if len(potential_door_boxes_wall) > 1:    \n",
    "                for i, box in enumerate(potential_door_boxes_wall[1]):\n",
    "                    #This are single faced walls so the penalty is less.\n",
    "                    score = potential_door_info_wall[1][i][4]-0.1\n",
    "                    \n",
    "                    \n",
    "                    if score > 0.75:\n",
    "                        detectionbox = np.array([box])\n",
    "                        \n",
    "                        opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[1], image_resolution = image_resolution)\n",
    "                            \n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                        \n",
    "                        doornode = BIMNode(\n",
    "                            name= \"Doors_\" + str(door_count),\n",
    "                            axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                            startpoint= boundaryPoints[0],\n",
    "                            endpoint= boundaryPoints[1],\n",
    "                            doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                            height = opening_height,\n",
    "                            doornessScore = score,\n",
    "                            singleFaced = True,\n",
    "                            depth = n.width,\n",
    "                            object_id = class_id *4000 + door_count,\n",
    "                            blackness = percentage_black_pixles,\n",
    "                            host = n)\n",
    "                        \n",
    "                        doorNodes.append(doornode)\n",
    "                        print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                        door_count += 1 \n",
    "        \n",
    "    wall += 1\n",
    "    \n",
    "if len(doorNodes) >= 1:\n",
    "    for n in doorNodes:\n",
    "        pointList=[]\n",
    "        points=np.asarray(n.axis.points)\n",
    "        # pointList.extend(points+n.sign*n.normal*n.width/2)\n",
    "        pointList.extend(points+n.host.normal*n.host.width/2)\n",
    "\n",
    "        # pointList.extend(points-n.sign*n.normal*n.width/2)\n",
    "        pointList.extend(points-n.host.normal*n.host.width/2)\n",
    "\n",
    "        pointList.extend(np.array(pointList)+np.array([0,0,n.height]))\n",
    "        pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "        box=pcd.get_oriented_bounding_box()\n",
    "        n.resource = o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "        n.resource.paint_uniform_color(ut.literal_to_array(n.host.color))\n",
    "        n.doorBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "        n.doorBox.paint_uniform_color([0,0,1])\n",
    "        \n",
    "        n.center = t8.compute_center(n.startpoint, n.endpoint)\n",
    "        n.cartesianTransform = copy.deepcopy(n.host.cartesianTransform)\n",
    "        n.cartesianTransform[:3,3] = n.center\n",
    "        n.normal = n.host.normal\n",
    "        n.rotation = t8.get_angle_with_x_axis(n.startpoint, n.endpoint)\n",
    "        \n",
    "    lines = []\n",
    "    # Function to calculate the distance between two points\n",
    "    def calculate_distance(point1, point2):\n",
    "        return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "\n",
    "    avg_doorWidth = np.mean(np.array([e.doorWidth for e in doorNodes]))\n",
    "    print(avg_doorWidth)\n",
    "    #remove single faced doors that are in a 90 degree angle with double faced doors.\n",
    "    dbscan = DBSCAN(eps=1.5*avg_doorWidth, min_samples=1, metric=t8.calculate_distance) #eps=1.5*avg_doorWidth\n",
    "    labels = dbscan.fit_predict([n.center for n in doorNodes])\n",
    "\n",
    "    cluster_ids = [-1] * len(doorNodes)\n",
    "    unique_labels = set(labels)\n",
    "\n",
    "    current_cluster_id = 0\n",
    "    for label in unique_labels:\n",
    "        cluster_lines = [doorNodes[i] for i in range(len(doorNodes)) if labels[i] == label]\n",
    "        for line in cluster_lines:\n",
    "            line_index = None\n",
    "            for i, l in enumerate(doorNodes):\n",
    "                if np.array_equal(l, line):\n",
    "                    line_index = i\n",
    "                    break\n",
    "            cluster_ids[line_index] = current_cluster_id\n",
    "        current_cluster_id += 1\n",
    "\n",
    "    all_clusters_indices = []\n",
    "\n",
    "    # Get unique cluster labels\n",
    "    unique_labels = np.unique(cluster_ids)\n",
    "\n",
    "    # Iterate through each unique cluster label\n",
    "    for cluster_label in unique_labels:\n",
    "        if not cluster_label == -1:\n",
    "            cluster_indices = [i for i, label in enumerate(cluster_ids) if label == cluster_label]\n",
    "            all_clusters_indices.append(cluster_indices)\n",
    "        else: \n",
    "            for i, label in enumerate(cluster_ids):\n",
    "                if label == cluster_label:\n",
    "                    all_clusters_indices.append([i])\n",
    "    print(all_clusters_indices) \n",
    "    # FP = []\n",
    "    for cluster_indices in all_clusters_indices:\n",
    "        if len(cluster_indices) > 1:\n",
    "            doors_to_check = []\n",
    "            for i in cluster_indices:\n",
    "                doors_to_check.append([doorNodes[i].name, doorNodes[i].doornessScore, doorNodes[i].blackness])\n",
    "                # if doorNodes[i].singleFaced and not doorNodes[i].blackness <0.1:\n",
    "                #     # print(f\"door: {doorNodes[i].name} will be removed\")\n",
    "                #     FP.append(doorNodes[i].subject)\n",
    "            print(doors_to_check)\n",
    "\n",
    "    \n",
    "        # ids = indices_of_values_smaller_than_max(blackness)\n",
    "        # for doornode_id in ids:\n",
    "            \n",
    "\n",
    "    # doorNodes = [doornode for doornode in doorNodes if doornode.subject not in FP]\n",
    "\n",
    "    door_count = len(doorNodes)\n",
    "    # print(f'name: {n.name}, score: {n.doornessScore} ,doorWidth: {n.doorWidth}, height: {n.height}')\n",
    "    \n",
    "print(f\"Number of doors: {door_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groundtruthPath = '/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t0/05_MedOffice_01_F2_doors.json'\n",
    "# groundtruthNodes = []\n",
    "\n",
    "# with open(groundtruthPath) as gt:\n",
    "#     data = json.load(gt)\n",
    "    \n",
    "# for item in data:\n",
    "#     doorNode = Node(\n",
    "#         id = item['id'],\n",
    "#         width = item['width'],\n",
    "#         height = item['height'],\n",
    "#         depth = item['depth'],\n",
    "#         center = item['loc'], \n",
    "#         rotation = item['rotation'], \n",
    "#         host = item['host_id']\n",
    "#     )\n",
    "#     groundtruthNodes.append(doorNode)\n",
    "# print(len(groundtruthNodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #match the graphs with the training data\n",
    "\n",
    "# input_folder_gt=path/'data'/'t1'/'train'\n",
    "\n",
    "# gt_files=utl.get_list_of_files(input_folder_gt,'.ttl')\n",
    "# gt_files_obj=utl.get_list_of_files(input_folder_gt,'.obj')\n",
    "# for f_gt,f_gt_obj in zip(gt_files[:1],gt_files_obj[:1]): #only read the first one\n",
    "    \n",
    "#     #import objects\n",
    "#     mesh_dict=utl.load_obj_and_create_meshes(f_gt_obj)\n",
    "    \n",
    "#     #import graph\n",
    "#     pcdNodes_gt=tl.graph_path_to_nodes(graphPath=str(f_gt))\n",
    "#     pcdNodes_gt_doors=[n for n in pcdNodes_gt if n.class_id==4]\n",
    "\n",
    "#     #add objects to the nodes\n",
    "#     for n in pcdNodes_gt_doors:\n",
    "#         mesh=next((mesh for name, mesh in mesh_dict.items() if name == n.name),None)\n",
    "#         n.resource=mesh\n",
    "#         n.lineset=o3d.geometry.LineSet.create_from_triangle_mesh(mesh)\n",
    "#         n.lineset.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "#         #compute the normal from start to end point\n",
    "#         n.resource.compute_triangle_normals()\n",
    "        \n",
    "#         n.normal =np.asarray( n.resource.triangle_normals)[11]\n",
    "       \n",
    "        \n",
    "#         # direction = (ut.literal_to_array(n_gt.end_pt) - ut.literal_to_array(n.start_pt))/np.linalg.norm(ut.literal_to_array(n_gt.end_pt) - ut.literal_to_array(n.start_pt))\n",
    "#         # n.normal = np.cross(direction, np.array([0, 0, 1]))\n",
    "#         # if np.linalg.norm(normal) == 0:\n",
    "#         #     normal = np.cross(direction, np.array([0, 1, 0]))\n",
    "#         # n.normal = normal / np.linalg.norm(normal)\n",
    "        \n",
    "        \n",
    "#     print(f'{len(pcdNodes_gt_doors)} pcdNodes_gt_doors detected!') # there are only 144 walls in the training data, yet 161 are found here\n",
    "#     print(f'{len(doorNodes)} doorNodes detected!') # there are only 144 walls in the training data, yet 161 are found here\n",
    "    \n",
    "#     #match the walls with the ground truth\n",
    "#     for n in doorNodes:\n",
    "        \n",
    "#         #create lineset\n",
    "#         n.lineset=o3d.geometry.LineSet.create_from_triangle_mesh(n.resource)\n",
    "#         # n.lineset.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "                \n",
    "#         #find the corresponding ground truth wall \n",
    "#         pose=n.cartesianTransform[:3,3]\n",
    "#         distances=[np.linalg.norm(pose-n.cartesianTransform[:3,3]) for n in pcdNodes_gt_doors]\n",
    "#         idx=np.argmin(distances)\n",
    "#         n_gt=pcdNodes_gt_doors[idx]\n",
    "#         # n_gt.color=n.color\n",
    "#         n.corresponding_gt=n_gt.name\n",
    "#         n.corresponding_normal=n_gt.normal\n",
    "        \n",
    "#         #create a line from the n.resource.get_center() along the n.normal in red and along the n_gt.normal in green\n",
    "#         line=o3d.geometry.LineSet()\n",
    "#         line.points=o3d.utility.Vector3dVector([n.resource.get_center(),n.resource.get_center()+n.normal])\n",
    "#         line.lines=o3d.utility.Vector2iVector([[0,1]])\n",
    "#         line.colors=o3d.utility.Vector3dVector([[1,0,0]])\n",
    "#         n.lineset+=line\n",
    "#         line=o3d.geometry.LineSet()\n",
    "#         line.points=o3d.utility.Vector3dVector([n.resource.get_center(),n.resource.get_center()+n_gt.normal])\n",
    "#         line.lines=o3d.utility.Vector2iVector([[0,1]])\n",
    "#         line.colors=o3d.utility.Vector3dVector([[0,1,0]])\n",
    "#         n.lineset+=line\n",
    "        \n",
    "        \n",
    "#         #make comparison\n",
    "#         # n.center_diff=np.round(np.min(np.array([np.linalg.norm(ut.literal_to_array(n_gt.loc)-n.center)])),2)\n",
    "#         n.height_diff=np.round(np.abs(n_gt.height-n.height),2)\n",
    "#         n.width_diff=np.round(n_gt.width-n.doorWidth,2)\n",
    "#         print(f'door {n.get_name()}, height_diff of {n.height_diff} (gt height is {np.round(n_gt.height,2)}), width_diff of {n.width_diff} (gt width is {np.round(n_gt.width,2)})')\n",
    "#     print(f'len of elements width_def >0.03: {len([e for e in doorNodes if np.abs(e.width_diff)>0.03])}/{len(doorNodes)}')\n",
    "#     print(f'len of elements height_diff>0.1: {len([e for e in doorNodes if np.abs(e.height_diff)>0.1])}/{len(doorNodes)}')\n",
    "#     print(f'mean height: {np.mean(np.array([e.height for e in doorNodes]))}')\n",
    "#     print(f'mean width: {np.mean(np.array([e.doorWidth for e in doorNodes]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t8.write_obj_with_submeshes(os.path.join(output_folder,f'{ut.get_filename(f)}_doors.obj') , [n.resource for n in doorNodes], [n.name for n in doorNodes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to file: /home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t8/train/05_MedOffice_01_F2_doors.json\n"
     ]
    }
   ],
   "source": [
    "reform_name='_'.join(ut.get_filename(f).split('_')[:4])+'_doors'\n",
    "\n",
    "json_data=t8.doors_to_json(doorNodes)\n",
    "with open(os.path.join(output_folder,reform_name+'.json'), 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)\n",
    "print(\"JSON data written to file:\", os.path.join(output_folder,reform_name+'.json'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
