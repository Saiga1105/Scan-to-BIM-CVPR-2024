{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph\n",
    "import rdflib\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import matplotlib.pyplot as plt\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t8_utils as t8\n",
    "\n",
    "from typing import Dict, Any, Tuple,List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[0]\n",
    "\n",
    "print(path)\n",
    "input_folder_t4=path/'data'/'t4'/'train' \n",
    "input_folder_t6=path/'data'/'t6'/'train'\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t8'/ 'train'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "grid_resolution = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_small1_walls...\n",
      "145 wallNodes detected!\n"
     ]
    }
   ],
   "source": [
    "graphfiles=utl.get_list_of_files(input_folder_t6,'.ttl')\n",
    "for f in graphfiles[:1]: #only read the first one\n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    wallNodes=tl.graph_path_to_nodes(f)\n",
    "    \n",
    "    for n in wallNodes:\n",
    "        n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(n.orientedBounds)))\n",
    "\n",
    "    print(f'{len(wallNodes)} wallNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 05_MedOffice_01_F2_small1...\n",
      "Unassigned : 1 Nodes found\n",
      "Floors : 2 Nodes found\n",
      "Ceilings : 3 Nodes found\n",
      "Walls : 148 Nodes found\n",
      "Columns : 173 Nodes found\n",
      "Doors : 289 Nodes found\n",
      "Windows : 289 Nodes found\n"
     ]
    }
   ],
   "source": [
    "pcdfiles=utl.get_list_of_files(input_folder_t4,'.laz')\n",
    "\n",
    "for f in pcdfiles[:1]: #only read the first one\n",
    "    pcdNodes=[]\n",
    "    \n",
    "    # check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    las = laspy.read(f) if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las,getNormals=True) if 'pcd' not in globals() else pcd # this is the slowest step\n",
    "    \n",
    "    #seperate initial objects\n",
    "    for c in class_dict['classes']:\n",
    "        if c['id'] in [255,0,1,2,3,4,5]:\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            for j in np.unique(object_labels):\n",
    "                indices=np.where(object_labels==j)[0]\n",
    "                object_pcd=class_pcd.select_by_index(indices)\n",
    "                pcdNodes.append(PointCloudNode(resource=object_pcd,\n",
    "                                            class_id=c['id'],\n",
    "                                            object_id=j,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=c['name']+f'_{str(j)}'))\n",
    "                \n",
    "            \n",
    "            #all further processing will be placed here (or in functions)!\n",
    "            print( c['name'], f': {len(pcdNodes)} Nodes found')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 clutterNodes detected!\n",
      "1 floorsNodes detected!\n",
      "1 ceilingsNodes detected!\n",
      "145 wallNodes detected!\n",
      "25 columnNodes detected!\n",
      "116 doorNodes detected!\n",
      "0 windowNodes detected!\n"
     ]
    }
   ],
   "source": [
    "clutterPCDNodes=[n for n in pcdNodes if 'Unassigned' in n.subject and type(n)==PointCloudNode]\n",
    "floorPCDNodes=[n for n in pcdNodes if 'Floors' in n.subject and type(n)==PointCloudNode]\n",
    "ceilingPCDNodes=[n for n in pcdNodes if 'Ceilings' in n.subject and type(n)==PointCloudNode]\n",
    "wallPCDNodes=[n for n in pcdNodes if 'Walls' in n.subject and type(n)==PointCloudNode]\n",
    "columnPCDNodes=[n for n in pcdNodes if 'Columns' in n.subject and type(n)==PointCloudNode]\n",
    "doorPCDNodes=[n for n in pcdNodes if 'Doors' in n.subject and type(n)==PointCloudNode]\n",
    "windowPCDNodes=[n for n in pcdNodes if 'Windows' in n.subject and type(n)==PointCloudNode]\n",
    "\n",
    "print(f'{len(clutterPCDNodes)} clutterNodes detected!')\n",
    "print(f'{len(floorPCDNodes)} floorsNodes detected!')\n",
    "print(f'{len(ceilingPCDNodes)} ceilingsNodes detected!')\n",
    "print(f'{len(wallPCDNodes)} wallNodes detected!')\n",
    "print(f'{len(columnPCDNodes)} columnNodes detected!')\n",
    "print(f'{len(doorPCDNodes)} doorNodes detected!')\n",
    "print(f'{len(windowPCDNodes)} windowNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match point clouds with graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in clutterPCDNodes+floorPCDNodes+ceilingPCDNodes+columnPCDNodes+doorPCDNodes+windowPCDNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((las['classes']==n.class_id) & (las['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(las.xyz[idx])\n",
    "    red = las['red'][idx]\n",
    "    green = las['green'][idx]\n",
    "    blue = las['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = las['red'][idx] >> 8 & 0xFF\n",
    "        green = las['green'][idx] >> 8 & 0xFF\n",
    "        blue = las['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.vstack((red,green,blue)).transpose())\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallPCDNodes:#+ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((las['classes']==n.class_id) & (las['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(las.xyz[idx])\n",
    "    pcd.paint_uniform_color([0.5,0.5,0.5])\n",
    "    \n",
    "    red = las['red'][idx]\n",
    "    green = las['green'][idx]\n",
    "    blue = las['blue'][idx]\n",
    "    #if color is 32 bit, only keep 8 bit color\n",
    "    if red.max()>255:\n",
    "        red = las['red'][idx] >> 8 & 0xFF\n",
    "        green = las['green'][idx] >> 8 & 0xFF\n",
    "        blue = las['blue'][idx] >> 8 & 0xFF\n",
    "    # if colorspace is [0-255] -> remap to [0-1]\n",
    "    if red.max() >1:\n",
    "        red=red/255\n",
    "        green=green/255\n",
    "        blue=blue/255\n",
    "    \n",
    "    pcd.colors=o3d.utility.Vector3dVector(np.column_stack((red, green, blue)))\n",
    "\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match PointCloudNodes to BIMNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m wallNodes:\n\u001b[0;32m----> 2\u001b[0m     n\u001b[38;5;241m.\u001b[39mderivedFrom \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwallPCDNodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mderivedFrom\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwallNodes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     n\u001b[38;5;241m.\u001b[39mobject_id \u001b[38;5;241m=\u001b[39m n\u001b[38;5;241m.\u001b[39mderivedFrom\u001b[38;5;241m.\u001b[39mobject_id\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    n.derivedFrom = next(p for p in wallPCDNodes if p.subject.toPython() in [w.derivedFrom for w in wallNodes])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dtrings from the graph to arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m wallNodes:\n\u001b[0;32m----> 2\u001b[0m     n\u001b[38;5;241m.\u001b[39mstartpoint \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstartpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      3\u001b[0m     n\u001b[38;5;241m.\u001b[39mendpoint \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n\u001b[38;5;241m.\u001b[39mendpoint[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m      4\u001b[0m     n\u001b[38;5;241m.\u001b[39mnormal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n\u001b[38;5;241m.\u001b[39mnormal[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    n.startpoint = np.asarray(n.startpoint[1:-1].split(), dtype=float)\n",
    "    n.endpoint = np.asarray(n.endpoint[1:-1].split(), dtype=float)\n",
    "    n.normal = np.asarray(n.normal[1:-1].split(), dtype=float)\n",
    "    n.height = float(n.height)\n",
    "    n.name = n.subject.split('///')[-1]\n",
    "    n.object_id = n.derivedFrom.object_id\n",
    "    if n.wallThickness == 0.127:\n",
    "        n.singleFaced = True\n",
    "    else:\n",
    "        n.singleFaced = False\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the full resolution point cloud for a more accurate result (unlabeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laz = laspy.read(os.path.join(Path(os.getcwd()).parents[0]/'data',\"full_resolution_populierenhof.las\"))\n",
    "full_res_point_cloud_o3d = gmu.las_to_pcd(las)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the full point cloud into a mesh and add it to a raycasting scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voxelsize =  0.02052154296875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cut a part out of the full resolution pointcloud\n",
    "# joined_pcd = full_res_point_cloud_o3d.crop(expanded_bounding_box)\n",
    "#Create a messh from this point cloud \n",
    "octree=pt.pcd_to_octree(full_res_point_cloud_o3d,12) #if octree is None else octree\n",
    "full_res_point_cloud_o3d = None\n",
    "mesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "\n",
    "\n",
    "#Create a identity array containing the color so this can be retrieved afterwards\n",
    "original_colors=np.asarray(mesh.vertex_colors)\n",
    "indices=np.asarray(mesh.triangles)[:,0]\n",
    "triangle_colors=original_colors[indices]\n",
    "#append black color at the end of the array for the invalid hits\n",
    "triangle_colors=np.vstack((triangle_colors,np.array([0,0,0])))\n",
    "\n",
    "# Create raycasting scene\n",
    "scene = o3d.t.geometry.RaycastingScene()\n",
    "mesh=o3d.t.geometry.TriangleMesh.from_legacy(mesh)\n",
    "scene.add_triangles(mesh) \n",
    "\n",
    "# Calculate the size of each octree node based on octree depth and overall size\n",
    "def calculate_node_size(octree_depth, octree_size):\n",
    "    num_voxels_per_dim = 2 ** octree_depth\n",
    "    voxel_size = octree_size / num_voxels_per_dim\n",
    "    return voxel_size\n",
    "\n",
    "# Example usage:\n",
    "octree_depth = octree.max_depth  # Example value for max_depth\n",
    "octree_size = octree.size  # Example size of the octree in world units\n",
    "voxel_size = calculate_node_size(octree_depth, octree_size)\n",
    "print(\"Voxelsize = \", voxel_size)\n",
    "octree = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Using the pointcloud and wall data to create an ortho foto of the wall and use object detection\n",
    "(Can also be used to retrieve other elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_resolution = 0.01\n",
    "\n",
    "for n in wallNodes:\n",
    "    \n",
    "    length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "    surface = length * n.height\n",
    "    image_size = (int(length / image_resolution), int(n.height / image_resolution))\n",
    "    n.orthos = []\n",
    "    \n",
    "\n",
    "    if not surface < 3 and n.height > 1.5 and length > 0.8:  \n",
    "        #Create an ortho of the dominant side of the wall      \n",
    "        ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = n.normal, scene=scene, triangle_colors = triangle_colors)\n",
    "        ortho = t8.fill_black_pixels(ortho, region = 10)\n",
    "        n.orthos.append(ortho)\n",
    "        #Also create an ortho of the other side of the wall\n",
    "        if not n.singleFaced: #Single faced wall only needs one side\n",
    "            ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = -n.normal, scene=scene, triangle_colors = triangle_colors, dominant = False)\n",
    "            ortho = t8.fill_black_pixels(ortho, region = 10)\n",
    "            n.orthos.append(ortho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision.ops import box_convert\n",
    "\n",
    "# Grounding DINO\n",
    "from groundingdino.models import build_model\n",
    "from groundingdino.util.slconfig import SLConfig\n",
    "from groundingdino.util.utils import clean_state_dict\n",
    "from groundingdino.util.inference import annotate, load_image, predict\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# segment anything\n",
    "# from segment_anything import build_sam, SamPredictor \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# diffusers\n",
    "import torch\n",
    "\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this command for evaluate the Grounding DINO model\n",
    "# Or you can download the model by yourself\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /opt/conda/conda-bld/pytorch_1711403380909/work/aten/src/ATen/native/TensorShape.cpp:3549.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "Model loaded from /home/sdegeyter/.cache/huggingface/hub/models--ShilongLiu--GroundingDINO/snapshots/a94c9b567a2a374598f05c584e96798a170c56fb/groundingdino_swinb_cogcoor.pth \n",
      " => _IncompatibleKeys(missing_keys=[], unexpected_keys=['label_enc.weight', 'bert.embeddings.position_ids'])\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast\n",
    "with autocast():\n",
    "    groundingdino_model = t8.load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "2024-05-27 12:50:01.138818: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 12:50:03.153540: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdegeyter/.conda/envs/pointcept/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-05-27 12:50:03.153695: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/sdegeyter/.conda/envs/pointcept/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2024-05-27 12:50:03.153712: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "pointcloud = []\n",
    "\n",
    "\n",
    "for n in wallNodes:\n",
    "    TEXT_PROMPT = \"Door\"\n",
    "    BOX_TRESHOLD = 0.30\n",
    "    TEXT_TRESHOLD = 0.5\n",
    "    \n",
    "    n.boxes = []\n",
    "    n.logits = []\n",
    "    n.phrases = []\n",
    "    \n",
    "    if len(n.orthos) > 0:\n",
    "        \n",
    "        for ortho in n.orthos:\n",
    "            boxes = None\n",
    "            image = load_image(Image.fromarray((ortho * 255).astype(np.uint8)))\n",
    "\n",
    "            boxes, logits, phrases = predict(\n",
    "                model=groundingdino_model, \n",
    "                image=image, \n",
    "                caption=TEXT_PROMPT, \n",
    "                box_threshold=BOX_TRESHOLD, \n",
    "                text_threshold=TEXT_TRESHOLD\n",
    "            )\n",
    "            \n",
    "            n.boxes.append(boxes)\n",
    "            n.logits.append(logits)\n",
    "            n.phrases.append(phrases)                  \n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "doorNodes = []\n",
    "pointcloud = []\n",
    "\n",
    "wall = 0\n",
    "count = 0\n",
    "image = 0\n",
    "id_count = 4000\n",
    "class_id = 5\n",
    "for n in wallNodes:#[72:73]: #^22:24 interessante muren\n",
    "    potential_door_boxes_wall = []\n",
    "    potential_door_info_wall = []\n",
    "    \n",
    "    if len(n.orthos) > 0 and (len(n.boxes[0]) > 0 or len(n.boxes[1]) > 0):\n",
    "        \n",
    "        for j, boxes in enumerate(n.boxes):\n",
    "            potential_door_boxes_face = []\n",
    "            potential_door_info_face = []\n",
    "            if len(boxes) > 0: \n",
    "                for i, box in enumerate(boxes):\n",
    "                    probability = float(n.logits[j][i])\n",
    "                    # print(\"Probability: \", probability)\n",
    "                    \n",
    "                    opening_width = round(int(np.asarray(box)[2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                    # print(\"Opening Width:\", opening_width)\n",
    "                    \n",
    "                    opening_height = round(int(np.asarray(box)[3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                    # print(\"Opening height:\", opening_height)\n",
    "                    \n",
    "            \n",
    "                    detection_center_u = int(np.asarray(box)[0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(box)[1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                    \n",
    "                    reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                    # print(\"Reference Level:\", reference_level)\n",
    "                    \n",
    "                    score = t8.is_door(probability, opening_width, opening_height, reference_level)\n",
    "\n",
    "                    if score >= 0.3:\n",
    "                        # print(f\"Door {count}\")\n",
    "                        box1 = copy.deepcopy(box)\n",
    "                        box = box.unsqueeze(0)\n",
    "\n",
    "                        if j == 1:\n",
    "                            box1[0] = 1-box1[0]\n",
    "\n",
    "                        # image = extract_box_with_margin(n.orthos[j], box[0])\n",
    "                        # image = image[...,::-1] # BGR to RGB\n",
    "\n",
    "                        potential_door_boxes_face.append(np.asarray(box1))\n",
    "                        potential_door_info_face.append([opening_width, opening_height, image, reference_level, score])\n",
    "                              \n",
    "            potential_door_boxes_wall.append(potential_door_boxes_face)\n",
    "            potential_door_info_wall.append(potential_door_info_face)\n",
    "        #merge largely overlapping bounding boxes\n",
    "        for face_boxes in potential_door_boxes_wall:\n",
    "            face_boxes = t8.find_and_merge_high_iou_boxes(face_boxes)\n",
    "    \n",
    "        #For Double faced walls look if the detection is found on both sides.\n",
    "        if len(potential_door_boxes_wall) == len(n.orthos) and not len(potential_door_boxes_wall[0]) == 0 and not len(potential_door_boxes_wall[1]) == 0:\n",
    "            matches, unmatched_boxes0, unmatched_boxes1 = t8.find_best_matches(potential_door_boxes_wall[0], potential_door_boxes_wall[1], potential_door_info_wall[0], potential_door_info_wall[1])\n",
    "            \n",
    "            for id0 in unmatched_boxes0:\n",
    "                score = potential_door_info_wall[0][id0][4]\n",
    "                if score > 0.7:\n",
    "                    detectionbox = np.array([potential_door_boxes_wall[0][id0]])\n",
    "                    image_resource = t8.extract_box_with_margin(n.orthos[0], detectionbox[0])\n",
    "                    image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                    if t8.calculate_percentage_black_pixels(image_resource) < 0.3:\n",
    "                        \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[0][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(image) + \"-\" +  str(calculate_percentage_black_pixels(image_resource)) +'-DOOR.png')))\n",
    "                        # image +=1\n",
    "                        \n",
    "                        opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                        \n",
    "                        opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                        \n",
    "                        detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                        detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                        reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "\n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "            \n",
    "                        doornode = BIMNode()\n",
    "                        doornode.name= \"Doors_\" + str(count)\n",
    "                        doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                        doornode.startpoint= boundaryPoints[0]\n",
    "                        doornode.endpoint= boundaryPoints[1]\n",
    "                        doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                        doornode.height = opening_height\n",
    "                        doornode.doornessScore = bestscore\n",
    "                        doornode.singleFaced = True\n",
    "                        doornode.depth = n.wallThickness\n",
    "                        doornode.object_id = class_id *4000 + count\n",
    "                        \n",
    "                        doornode.host = n\n",
    "                        doorNodes.append(doornode)\n",
    "                        count += 1 \n",
    "                \n",
    "            for id1 in unmatched_boxes1:\n",
    "                score = potential_door_info_wall[1][id1][4]\n",
    "                if score > 0.7:\n",
    "                    detectionbox = np.array([potential_door_boxes_wall[1][id1]])\n",
    "                    image_resource = t8.extract_box_with_margin(n.orthos[1], detectionbox[0])\n",
    "                    image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                    if t8.calculate_percentage_black_pixels(image_resource) < 0.3:\n",
    "                        \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[1], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[1][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(image) + \"-\" +  str(calculate_percentage_black_pixels(image_resource)) +'-DOOR.png')))\n",
    "                        # image +=1\n",
    "                        box = np.asarray(potential_door_boxes_wall[1][id1])\n",
    "                        box[0] = 1-box[0]\n",
    "                        potential_door_boxes_wall[1][id1] = box\n",
    "                        opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                        \n",
    "                        opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                        \n",
    "                        detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                        detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                        reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                        \n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                        doornode = BIMNode()\n",
    "                        doornode.name= \"Doors_\" + str(count)\n",
    "                        doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                        doornode.startpoint= boundaryPoints[0]\n",
    "                        doornode.endpoint= boundaryPoints[1]\n",
    "                        doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                        doornode.height = opening_height\n",
    "                        doornode.doornessScore = bestscore\n",
    "                        doornode.singleFaced = True\n",
    "                        doornode.depth = n.wallThickness\n",
    "                        doornode.object_id = class_id *4000 + count\n",
    "                        \n",
    "                        doornode.host = n\n",
    "                        doorNodes.append(doornode)\n",
    "                        count += 1 \n",
    "\n",
    "            for id0, id1, bestscore in matches:\n",
    "                if not id0 == None and not id1 == None:\n",
    "                    # compare the parameters of the different matches\n",
    "                    info0 = potential_door_info_wall[0][id0]\n",
    "                    info1 = potential_door_info_wall[1][id1]\n",
    "                    image = info0[2]\n",
    "                    # # boxestemp = np.array([potential_door_boxes_wall[0][id0],potential_door_boxes_wall[1][id1]])\n",
    "                    # boxes0 = potential_door_boxes_wall[0][id0]\n",
    "                    # box = np.asarray(potential_door_boxes_wall[1][id1])\n",
    "                    # box[0] = 1-box[0]\n",
    "                    # potential_door_boxes_wall[1][id1] = box\n",
    "                    # potential_door_boxes_wall[1][id1][0] = 1-potential_door_boxes_wall[1][id1][0]\n",
    "                    \n",
    "                    detectionbox = t8.combine_boxes(potential_door_boxes_wall[0][id0], potential_door_boxes_wall[1][id1])              \n",
    "                    # Image.fromarray(image).save(os.path.join(output_folder,(str(count) +'-DOOR.png')))\n",
    "                    # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([bestscore])), phrases=[n.phrases[0][id0]])\n",
    "                    # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                    # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(image) +'-DOOR.png')))\n",
    "                    image +=1\n",
    "                    \n",
    "                    \n",
    "                    opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                    # print(\"Opening Width:\", opening_width)\n",
    "                    \n",
    "                    opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                    \n",
    "                    detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                    detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                    reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                    \n",
    "                    # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                    \n",
    "                    boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                    \n",
    "                    doornode = BIMNode()\n",
    "                    doornode.name= \"Doors_\" + str(count)\n",
    "                    doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                    doornode.startpoint= boundaryPoints[0]\n",
    "                    doornode.endpoint= boundaryPoints[1]\n",
    "                    doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                    doornode.height = opening_height\n",
    "                    doornode.doornessScore = bestscore\n",
    "                    doornode.singleFaced = False\n",
    "                    doornode.depth = n.wallThickness\n",
    "                    doornode.object_id = class_id *4000 + count\n",
    "                    \n",
    "                    doornode.host = n\n",
    "                    doorNodes.append(doornode)\n",
    "                    count += 1 \n",
    "        else: #For single faced walls \n",
    "            for i, box in enumerate(potential_door_boxes_wall[0]):\n",
    "                score = potential_door_info_wall[0][i][4]\n",
    "                if score > 0.7:\n",
    "                    detectionbox = np.array([box])\n",
    "                    image_resource = t8.extract_box_with_margin(n.orthos[0], detectionbox[0])\n",
    "                    image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                    if t8.calculate_percentage_black_pixels(image_resource) < 0.3:\n",
    "                        \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[0][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(image) + \"-\" +  str(calculate_percentage_black_pixels(image_resource)) +'-DOOR.png')))\n",
    "                        # image +=1\n",
    "                        \n",
    "                        opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                        # print(\"Opening Width:\", opening_width)\n",
    "                        \n",
    "                        opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                        \n",
    "                        detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                        detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                        reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                        \n",
    "                        # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                        doornode = BIMNode()\n",
    "                        doornode.name= \"Doors_\" + str(count)\n",
    "                        doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                        doornode.startpoint= boundaryPoints[0]\n",
    "                        doornode.endpoint= boundaryPoints[1]\n",
    "                        doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                        doornode.height = opening_height\n",
    "                        doornode.doornessScore = bestscore\n",
    "                        doornode.singleFaced = True\n",
    "                        doornode.depth = n.wallThickness\n",
    "                        doornode.object_id = class_id *4000 + count\n",
    "                                            \n",
    "                        doornode.host = n\n",
    "                        doorNodes.append(doornode)\n",
    "                        count += 1\n",
    "                     \n",
    "            for i, box in enumerate(potential_door_boxes_wall[1]):\n",
    "                score = potential_door_info_wall[1][i][4]\n",
    "                if score >= 0.7:\n",
    "                    detectionbox = np.array([box])\n",
    "                    image_resource = t8.extract_box_with_margin(n.orthos[1], detectionbox[0])\n",
    "                    image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                    if t8.calculate_percentage_black_pixels(image_resource) < 0.3:\n",
    "                        \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[1], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[1][i]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(str(image) + \"-\" +  str(calculate_percentage_black_pixels(image_resource)) +'-DOOR.png')))\n",
    "                        # image +=1\n",
    "                        \n",
    "                        opening_width = round(int(np.asarray(detectionbox)[0][2]*n.orthos[j].shape[1])* image_resolution, 2)\n",
    "                        # print(\"Opening Width:\", opening_width)\n",
    "                        \n",
    "                        opening_height = round(int(np.asarray(detectionbox)[0][3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                        \n",
    "                        detection_center_u = int(np.asarray(detectionbox)[0][0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                        detection_center_v = int(np.asarray(detectionbox)[0][1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                        reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                        \n",
    "                        # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                        \n",
    "                        doornode = BIMNode()\n",
    "                        doornode.name= \"Doors_\" + str(count)\n",
    "                        doornode.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "                        doornode.startpoint= boundaryPoints[0]\n",
    "                        doornode.endpoint= boundaryPoints[1]\n",
    "                        doornode.doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2)\n",
    "                        doornode.height = opening_height\n",
    "                        doornode.doornessScore = bestscore\n",
    "                        doornode.singleFaced = True\n",
    "                        doornode.depth = n.wallThickness\n",
    "                        doornode.object_id = class_id *4000 + count\n",
    "\n",
    "\n",
    "                        doornode.host = n\n",
    "                        doorNodes.append(doornode)\n",
    "                        count += 1 \n",
    "    wall += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angle_with_x_axis(start_point, end_point):\n",
    "    # Calculate the direction vector of the line\n",
    "    direction_vector = np.array(end_point) - np.array(start_point)\n",
    "    \n",
    "    # Calculate the angle with the x-axis\n",
    "    # x-axis direction vector\n",
    "    x_axis_vector = np.array([1, 0, 0])\n",
    "    \n",
    "    # Dot product of direction vector and x-axis vector\n",
    "    dot_product = np.dot(direction_vector, x_axis_vector)\n",
    "    \n",
    "    # Magnitude (length) of the direction vector\n",
    "    magnitude_direction_vector = np.linalg.norm(direction_vector)\n",
    "    \n",
    "    # Magnitude of the x-axis vector (which is 1)\n",
    "    magnitude_x_axis_vector = np.linalg.norm(x_axis_vector)\n",
    "    \n",
    "    # Calculate the cosine of the angle\n",
    "    cos_theta = dot_product / (magnitude_direction_vector * magnitude_x_axis_vector)\n",
    "    \n",
    "    # Calculate the angle in radians\n",
    "    theta_radians = np.arccos(cos_theta)\n",
    "    \n",
    "    # Convert the angle to degrees\n",
    "    theta_degrees = np.degrees(theta_radians)\n",
    "    \n",
    "    return theta_degrees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.78502280505978\n",
      "name: Doors_0, score: 0.9695304682379797 ,doorWidth: 0.87, height: 2.12\n",
      "1.3821368877184934\n",
      "name: Doors_1, score: 0.9693370941148303 ,doorWidth: 0.94, height: 2.14\n",
      "89.98907740019823\n",
      "name: Doors_2, score: 0.9629327635675227 ,doorWidth: 0.87, height: 2.12\n",
      "179.91193955569642\n",
      "name: Doors_3, score: 0.9746929097926005 ,doorWidth: 0.89, height: 2.1\n",
      "89.87172489455205\n",
      "name: Doors_4, score: 0.9696995368446713 ,doorWidth: 0.94, height: 2.14\n",
      "89.86066241295532\n",
      "name: Doors_5, score: 0.9699331354029762 ,doorWidth: 0.9, height: 2.11\n",
      "0.11879854052313533\n",
      "name: Doors_6, score: 0.9152734712771989 ,doorWidth: 0.96, height: 2.15\n",
      "89.85136724662975\n",
      "name: Doors_7, score: 0.9443849406883149 ,doorWidth: 1.03, height: 2.16\n",
      "179.92320719261494\n",
      "name: Doors_8, score: 0.9546706772086225 ,doorWidth: 0.73, height: 2.04\n",
      "89.74200600684131\n",
      "name: Doors_9, score: 0.8611966507675779 ,doorWidth: 0.84, height: 2.09\n",
      "89.9198662404139\n",
      "name: Doors_10, score: 0.9666590800136377 ,doorWidth: 0.88, height: 2.09\n",
      "89.91986624041402\n",
      "name: Doors_11, score: 0.9582763293013411 ,doorWidth: 0.89, height: 2.09\n",
      "89.91986624041401\n",
      "name: Doors_12, score: 0.966249319801721 ,doorWidth: 0.87, height: 2.1\n",
      "89.9139198315614\n",
      "name: Doors_15, score: 0.966249319801721 ,doorWidth: 0.84, height: 2.04\n",
      "89.9139198315614\n",
      "name: Doors_16, score: 0.971206164058145 ,doorWidth: 0.88, height: 2.1\n",
      "89.91391983156142\n",
      "name: Doors_17, score: 0.9717408642598839 ,doorWidth: 0.87, height: 2.1\n",
      "89.842340482899\n",
      "name: Doors_18, score: 0.9432259596333021 ,doorWidth: 0.92, height: 2.13\n",
      "179.95372480717046\n",
      "name: Doors_19, score: 0.9432259596333021 ,doorWidth: 0.99, height: 2.15\n",
      "89.85087976361912\n",
      "name: Doors_20, score: 0.9207572021927737 ,doorWidth: 1.01, height: 2.35\n",
      "179.8977702912018\n",
      "name: Doors_21, score: 0.9574231463964968 ,doorWidth: 0.85, height: 2.11\n",
      "179.8977702912018\n",
      "name: Doors_22, score: 0.9651083510120821 ,doorWidth: 0.78, height: 2.08\n",
      "89.86603668211808\n",
      "name: Doors_23, score: 0.8697679164052645 ,doorWidth: 1.18, height: 2.12\n",
      "179.7422786515457\n",
      "name: Doors_24, score: 0.9568443304199523 ,doorWidth: 0.85, height: 2.15\n",
      "179.72563777881874\n",
      "name: Doors_25, score: 0.9568443304199523 ,doorWidth: 1.27, height: 2.34\n",
      "90.38066373353723\n",
      "name: Doors_26, score: 0.9568443304199523 ,doorWidth: 1.02, height: 2.16\n",
      "89.92471367179368\n",
      "name: Doors_27, score: 0.9163950290237344 ,doorWidth: 0.99, height: 2.13\n",
      "1.0620898349441192\n",
      "name: Doors_28, score: 0.8973283387282489 ,doorWidth: 0.98, height: 2.08\n",
      "179.93646185858697\n",
      "name: Doors_29, score: 0.9707532010296165 ,doorWidth: 0.89, height: 2.13\n",
      "179.96307600761506\n",
      "name: Doors_30, score: 0.9401916145432283 ,doorWidth: 0.9, height: 2.09\n",
      "179.96307600761506\n",
      "name: Doors_31, score: 0.9706054260177537 ,doorWidth: 0.78, height: 2.05\n",
      "179.96307600761506\n",
      "name: Doors_32, score: 0.963247944378984 ,doorWidth: 0.87, height: 2.05\n",
      "179.96307600761506\n",
      "name: Doors_33, score: 0.9847176208006418 ,doorWidth: 0.82, height: 2.03\n",
      "0.04874897765506724\n",
      "name: Doors_34, score: 0.9590006248932779 ,doorWidth: 0.82, height: 2.1\n",
      "0.048748977670019955\n",
      "name: Doors_35, score: 0.967004135589873 ,doorWidth: 0.81, height: 2.11\n",
      "89.88537306014713\n",
      "name: Doors_36, score: 0.967004135589873 ,doorWidth: 1.02, height: 2.13\n",
      "89.8853730601472\n",
      "name: Doors_37, score: 0.9670746661999412 ,doorWidth: 0.94, height: 2.08\n",
      "89.74258941195728\n",
      "name: Doors_38, score: 0.9670746661999412 ,doorWidth: 0.64, height: 2.18\n",
      "90.08973969712858\n",
      "name: Doors_39, score: 0.970831012868719 ,doorWidth: 0.73, height: 2.08\n",
      "89.81024730717013\n",
      "name: Doors_40, score: 0.9447007110123437 ,doorWidth: 0.93, height: 2.12\n",
      "89.78679104931709\n",
      "name: Doors_41, score: 0.9629924553580923 ,doorWidth: 0.85, height: 1.76\n",
      "0.10947468149778451\n",
      "name: Doors_43, score: 0.970263521975141 ,doorWidth: 0.88, height: 2.1\n",
      "90.08207566276207\n",
      "name: Doors_44, score: 0.943535875587997 ,doorWidth: 0.86, height: 2.14\n",
      "90.14467252517193\n",
      "name: Doors_45, score: 0.904332134383671 ,doorWidth: 0.92, height: 2.11\n",
      "179.95657474087994\n",
      "name: Doors_46, score: 0.9586383527285669 ,doorWidth: 1.02, height: 2.23\n",
      "179.07212529113949\n",
      "name: Doors_47, score: 0.9586383527285669 ,doorWidth: 1.12, height: 2.09\n",
      "0.043986400451619924\n",
      "name: Doors_49, score: 0.9615261421325262 ,doorWidth: 0.86, height: 2.09\n",
      "179.97881253527947\n",
      "name: Doors_50, score: 0.9615261421325262 ,doorWidth: 0.18, height: 2.11\n",
      "90.07214680725141\n",
      "name: Doors_51, score: 0.9496727336913031 ,doorWidth: 0.85, height: 2.09\n",
      "90.07214680725141\n",
      "name: Doors_52, score: 0.9322766614322577 ,doorWidth: 0.87, height: 2.09\n",
      "89.98481744098612\n",
      "name: Doors_53, score: 0.9382327446220986 ,doorWidth: 0.88, height: 2.09\n",
      "90.06987344780272\n",
      "name: Doors_54, score: 0.9499236707674794 ,doorWidth: 0.71, height: 2.1\n",
      "90.06141183501053\n",
      "name: Doors_55, score: 0.9676072823579367 ,doorWidth: 0.84, height: 2.1\n",
      "179.96073924585644\n",
      "name: Doors_56, score: 0.9662307845554803 ,doorWidth: 0.88, height: 2.09\n",
      "0.4502489640666492\n",
      "name: Doors_57, score: 0.8071715330232776 ,doorWidth: 0.88, height: 2.1\n",
      "179.86986191303015\n",
      "name: Doors_58, score: 0.9743536823415979 ,doorWidth: 0.9, height: 1.75\n",
      "179.86986191303293\n",
      "name: Doors_59, score: 0.9430447715158103 ,doorWidth: 0.71, height: 1.78\n",
      "179.93335295892354\n",
      "name: Doors_60, score: 0.9516115484526174 ,doorWidth: 0.73, height: 2.1\n",
      "179.80408648600695\n",
      "name: Doors_61, score: 0.968239287990214 ,doorWidth: 0.88, height: 2.11\n"
     ]
    }
   ],
   "source": [
    "for n in doorNodes:\n",
    "    pointList=[]\n",
    "    points=np.asarray(n.axis.points)\n",
    "    # pointList.extend(points+n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points+n.host.normal*n.host.wallThickness/2)\n",
    "\n",
    "    # pointList.extend(points-n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points-n.host.normal*n.host.wallThickness/2)\n",
    "\n",
    "    pointList.extend(np.array(pointList)+np.array([0,0,n.height]))\n",
    "    pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "    box=pcd.get_oriented_bounding_box()\n",
    "    n.resource = o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "    n.resource.paint_uniform_color(ut.literal_to_array(n.host.color))\n",
    "    n.doorBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "    n.doorBox.paint_uniform_color([0,0,1])\n",
    "    \n",
    "    n.center = t8.compute_center(n.startpoint, n.endpoint)\n",
    "    n.cartesianTransform = copy.deepcopy(n.host.cartesianTransform)\n",
    "    n.cartesianTransform[:3,3] = n.center\n",
    "    n.normal = n.host.normal\n",
    "    n.rotation = get_angle_with_x_axis(n.startpoint, n.endpoint)\n",
    "\n",
    "    print(f'name: {n.name}, score: {n.doornessScore} ,doorWidth: {n.doorWidth}, height: {n.height}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "door: Doors_13 will be removed\n",
      "door: Doors_14 will be removed\n",
      "door: Doors_42 will be removed\n",
      "door: Doors_48 will be removed\n"
     ]
    }
   ],
   "source": [
    "lines = []\n",
    "# # Function to calculate the distance between two points\n",
    "# def calculate_distance(point1, point2):\n",
    "#     return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "\n",
    "avg_doorWidth = np.mean(np.array([e.doorWidth for e in doorNodes]))\n",
    "#remove single faced doors that are in a 90 degree angle with double faced doors.\n",
    "dbscan = DBSCAN(eps=1.5*avg_doorWidth, min_samples=1, metric=t8.calculate_distance)\n",
    "labels = dbscan.fit_predict([n.center for n in doorNodes])\n",
    "\n",
    "cluster_ids = [-1] * len(doorNodes)\n",
    "unique_labels = set(labels)\n",
    "\n",
    "current_cluster_id = 0\n",
    "for label in unique_labels:\n",
    "    cluster_lines = [doorNodes[i] for i in range(len(doorNodes)) if labels[i] == label]\n",
    "    for line in cluster_lines:\n",
    "        line_index = None\n",
    "        for i, l in enumerate(doorNodes):\n",
    "            if np.array_equal(l, line):\n",
    "                line_index = i\n",
    "                break\n",
    "        cluster_ids[line_index] = current_cluster_id\n",
    "    current_cluster_id += 1\n",
    "\n",
    "all_clusters_indices = []\n",
    "\n",
    "# Get unique cluster labels\n",
    "unique_labels = np.unique(cluster_ids)\n",
    "\n",
    "# Iterate through each unique cluster label\n",
    "for cluster_label in unique_labels:\n",
    "    if not cluster_label == -1:\n",
    "        cluster_indices = [i for i, label in enumerate(cluster_ids) if label == cluster_label]\n",
    "        all_clusters_indices.append(cluster_indices)\n",
    "    else: \n",
    "        for i, label in enumerate(cluster_ids):\n",
    "            if label == cluster_label:\n",
    "                all_clusters_indices.append([i])\n",
    "            \n",
    "FP = []\n",
    "for cluster_indices in all_clusters_indices:\n",
    "    if len(cluster_indices) > 1:\n",
    "        doors_to_check = []\n",
    "        for i in cluster_indices:\n",
    "            if doorNodes[i].singleFaced:\n",
    "                print(f\"door: {doorNodes[i].name} will be removed\")\n",
    "                FP.append(doorNodes[i].subject)\n",
    "\n",
    "doorNodes = [doornode for doornode in doorNodes if doornode.subject not in FP]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "groundtruthPath = '/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t0/05_MedOffice_01_F2_doors.json'\n",
    "groundtruthNodes = []\n",
    "\n",
    "with open(groundtruthPath) as gt:\n",
    "    data = json.load(gt)\n",
    "    \n",
    "for item in data:\n",
    "    doorNode = Node(\n",
    "        id = item['id'],\n",
    "        width = item['width'],\n",
    "        height = item['height'],\n",
    "        depth = item['depth'],\n",
    "        center = item['loc'], \n",
    "        rotation = item['rotation'], \n",
    "        host = item['host_id']\n",
    "    )\n",
    "    groundtruthNodes.append(doorNode)\n",
    "print(len(groundtruthNodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62 pcdNodes_gt_doors detected!\n",
      "58 doorNodes detected!\n",
      "door Doors_0, height_diff of 0.09 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_1, height_diff of 0.07 (gt height is 2.21), width_diff of 0.13 (gt width is 1.07)\n",
      "door Doors_2, height_diff of 0.09 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_3, height_diff of 0.11 (gt height is 2.21), width_diff of 0.18 (gt width is 1.07)\n",
      "door Doors_4, height_diff of 0.07 (gt height is 2.21), width_diff of 0.13 (gt width is 1.07)\n",
      "door Doors_5, height_diff of 0.1 (gt height is 2.21), width_diff of 0.07 (gt width is 0.97)\n",
      "door Doors_6, height_diff of 0.06 (gt height is 2.21), width_diff of 0.01 (gt width is 0.97)\n",
      "door Doors_7, height_diff of 0.05 (gt height is 2.21), width_diff of 0.04 (gt width is 1.07)\n",
      "door Doors_8, height_diff of 0.17 (gt height is 2.21), width_diff of 0.34 (gt width is 1.07)\n",
      "door Doors_9, height_diff of 0.12 (gt height is 2.21), width_diff of 0.23 (gt width is 1.07)\n",
      "door Doors_10, height_diff of 0.12 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_11, height_diff of 0.12 (gt height is 2.21), width_diff of 0.18 (gt width is 1.07)\n",
      "door Doors_12, height_diff of 0.11 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_15, height_diff of 0.17 (gt height is 2.21), width_diff of 0.23 (gt width is 1.07)\n",
      "door Doors_16, height_diff of 0.11 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_17, height_diff of 0.11 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_18, height_diff of 0.08 (gt height is 2.21), width_diff of 0.15 (gt width is 1.07)\n",
      "door Doors_19, height_diff of 0.06 (gt height is 2.21), width_diff of 0.08 (gt width is 1.07)\n",
      "door Doors_20, height_diff of 0.14 (gt height is 2.21), width_diff of 0.06 (gt width is 1.07)\n",
      "door Doors_21, height_diff of 0.1 (gt height is 2.21), width_diff of 0.22 (gt width is 1.07)\n",
      "door Doors_22, height_diff of 0.13 (gt height is 2.21), width_diff of 0.29 (gt width is 1.07)\n",
      "door Doors_23, height_diff of 0.09 (gt height is 2.21), width_diff of -0.11 (gt width is 1.07)\n",
      "door Doors_24, height_diff of 0.06 (gt height is 2.21), width_diff of 0.22 (gt width is 1.07)\n",
      "door Doors_25, height_diff of 0.13 (gt height is 2.21), width_diff of -0.2 (gt width is 1.07)\n",
      "door Doors_26, height_diff of 0.05 (gt height is 2.21), width_diff of 0.05 (gt width is 1.07)\n",
      "door Doors_27, height_diff of 0.08 (gt height is 2.21), width_diff of 0.08 (gt width is 1.07)\n",
      "door Doors_28, height_diff of 0.13 (gt height is 2.21), width_diff of 0.09 (gt width is 1.07)\n",
      "door Doors_29, height_diff of 0.08 (gt height is 2.21), width_diff of 0.18 (gt width is 1.07)\n",
      "door Doors_30, height_diff of 0.12 (gt height is 2.21), width_diff of 0.17 (gt width is 1.07)\n",
      "door Doors_31, height_diff of 0.16 (gt height is 2.21), width_diff of 0.29 (gt width is 1.07)\n",
      "door Doors_32, height_diff of 0.16 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_33, height_diff of 0.18 (gt height is 2.21), width_diff of 0.25 (gt width is 1.07)\n",
      "door Doors_34, height_diff of 0.11 (gt height is 2.21), width_diff of 0.25 (gt width is 1.07)\n",
      "door Doors_35, height_diff of 0.1 (gt height is 2.21), width_diff of 0.26 (gt width is 1.07)\n",
      "door Doors_36, height_diff of 0.08 (gt height is 2.21), width_diff of 0.05 (gt width is 1.07)\n",
      "door Doors_37, height_diff of 0.13 (gt height is 2.21), width_diff of 0.13 (gt width is 1.07)\n",
      "door Doors_38, height_diff of 0.03 (gt height is 2.21), width_diff of 0.43 (gt width is 1.07)\n",
      "door Doors_39, height_diff of 0.13 (gt height is 2.21), width_diff of 0.34 (gt width is 1.07)\n",
      "door Doors_40, height_diff of 0.09 (gt height is 2.21), width_diff of 0.14 (gt width is 1.07)\n",
      "door Doors_41, height_diff of 0.45 (gt height is 2.21), width_diff of 0.22 (gt width is 1.07)\n",
      "door Doors_43, height_diff of 0.11 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_44, height_diff of 0.07 (gt height is 2.21), width_diff of 0.21 (gt width is 1.07)\n",
      "door Doors_45, height_diff of 0.1 (gt height is 2.21), width_diff of 0.15 (gt width is 1.07)\n",
      "door Doors_46, height_diff of 0.02 (gt height is 2.21), width_diff of 0.05 (gt width is 1.07)\n",
      "door Doors_47, height_diff of 0.12 (gt height is 2.21), width_diff of -0.05 (gt width is 1.07)\n",
      "door Doors_49, height_diff of 0.12 (gt height is 2.21), width_diff of 0.21 (gt width is 1.07)\n",
      "door Doors_50, height_diff of 0.1 (gt height is 2.21), width_diff of 0.89 (gt width is 1.07)\n",
      "door Doors_51, height_diff of 0.12 (gt height is 2.21), width_diff of 0.22 (gt width is 1.07)\n",
      "door Doors_52, height_diff of 0.12 (gt height is 2.21), width_diff of 0.2 (gt width is 1.07)\n",
      "door Doors_53, height_diff of 0.12 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_54, height_diff of 0.11 (gt height is 2.21), width_diff of 0.36 (gt width is 1.07)\n",
      "door Doors_55, height_diff of 0.11 (gt height is 2.21), width_diff of 0.23 (gt width is 1.07)\n",
      "door Doors_56, height_diff of 0.12 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_57, height_diff of 0.11 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "door Doors_58, height_diff of 0.46 (gt height is 2.21), width_diff of 0.17 (gt width is 1.07)\n",
      "door Doors_59, height_diff of 0.43 (gt height is 2.21), width_diff of 0.36 (gt width is 1.07)\n",
      "door Doors_60, height_diff of 0.11 (gt height is 2.21), width_diff of 0.34 (gt width is 1.07)\n",
      "door Doors_61, height_diff of 0.1 (gt height is 2.21), width_diff of 0.19 (gt width is 1.07)\n",
      "len of elements width_def >0.03: 57/58\n",
      "len of elements height_diff>0.1: 34/58\n",
      "mean height: 2.097758620689655\n",
      "mean width: 0.8794827586206897\n"
     ]
    }
   ],
   "source": [
    "#match the graphs with the training data\n",
    "\n",
    "input_folder_gt=path/'data'/'t1'/'train'\n",
    "\n",
    "gt_files=utl.get_list_of_files(input_folder_gt,'.ttl')\n",
    "gt_files_obj=utl.get_list_of_files(input_folder_gt,'.obj')\n",
    "for f_gt,f_gt_obj in zip(gt_files[:1],gt_files_obj[:1]): #only read the first one\n",
    "    \n",
    "    #import objects\n",
    "    mesh_dict=utl.load_obj_and_create_meshes(f_gt_obj)\n",
    "    \n",
    "    #import graph\n",
    "    pcdNodes_gt=tl.graph_path_to_nodes(graphPath=str(f_gt))\n",
    "    pcdNodes_gt_doors=[n for n in pcdNodes_gt if n.class_id==4]\n",
    "\n",
    "    #add objects to the nodes\n",
    "    for n in pcdNodes_gt_doors:\n",
    "        mesh=next((mesh for name, mesh in mesh_dict.items() if name == n.name),None)\n",
    "        n.resource=mesh\n",
    "        n.lineset=o3d.geometry.LineSet.create_from_triangle_mesh(mesh)\n",
    "        n.lineset.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "        #compute the normal from start to end point\n",
    "        n.resource.compute_triangle_normals()\n",
    "        \n",
    "        n.normal =np.asarray( n.resource.triangle_normals)[11]\n",
    "       \n",
    "        \n",
    "        # direction = (ut.literal_to_array(n_gt.end_pt) - ut.literal_to_array(n.start_pt))/np.linalg.norm(ut.literal_to_array(n_gt.end_pt) - ut.literal_to_array(n.start_pt))\n",
    "        # n.normal = np.cross(direction, np.array([0, 0, 1]))\n",
    "        # if np.linalg.norm(normal) == 0:\n",
    "        #     normal = np.cross(direction, np.array([0, 1, 0]))\n",
    "        # n.normal = normal / np.linalg.norm(normal)\n",
    "        \n",
    "        \n",
    "    print(f'{len(pcdNodes_gt_doors)} pcdNodes_gt_doors detected!') # there are only 144 walls in the training data, yet 161 are found here\n",
    "    print(f'{len(doorNodes)} doorNodes detected!') # there are only 144 walls in the training data, yet 161 are found here\n",
    "    \n",
    "    #match the walls with the ground truth\n",
    "    for n in doorNodes:\n",
    "        \n",
    "        #create lineset\n",
    "        n.lineset=o3d.geometry.LineSet.create_from_triangle_mesh(n.resource)\n",
    "        # n.lineset.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "                \n",
    "        #find the corresponding ground truth wall \n",
    "        pose=n.cartesianTransform[:3,3]\n",
    "        distances=[np.linalg.norm(pose-n.cartesianTransform[:3,3]) for n in pcdNodes_gt_doors]\n",
    "        idx=np.argmin(distances)\n",
    "        n_gt=pcdNodes_gt_doors[idx]\n",
    "        # n_gt.color=n.color\n",
    "        n.corresponding_gt=n_gt.name\n",
    "        n.corresponding_normal=n_gt.normal\n",
    "        \n",
    "        #create a line from the n.resource.get_center() along the n.normal in red and along the n_gt.normal in green\n",
    "        line=o3d.geometry.LineSet()\n",
    "        line.points=o3d.utility.Vector3dVector([n.resource.get_center(),n.resource.get_center()+n.normal])\n",
    "        line.lines=o3d.utility.Vector2iVector([[0,1]])\n",
    "        line.colors=o3d.utility.Vector3dVector([[1,0,0]])\n",
    "        n.lineset+=line\n",
    "        line=o3d.geometry.LineSet()\n",
    "        line.points=o3d.utility.Vector3dVector([n.resource.get_center(),n.resource.get_center()+n_gt.normal])\n",
    "        line.lines=o3d.utility.Vector2iVector([[0,1]])\n",
    "        line.colors=o3d.utility.Vector3dVector([[0,1,0]])\n",
    "        n.lineset+=line\n",
    "        \n",
    "        \n",
    "        #make comparison\n",
    "        # n.center_diff=np.round(np.min(np.array([np.linalg.norm(ut.literal_to_array(n_gt.loc)-n.center)])),2)\n",
    "        n.height_diff=np.round(np.abs(n_gt.height-n.height),2)\n",
    "        n.width_diff=np.round(n_gt.width-n.doorWidth,2)\n",
    "        print(f'door {n.get_name()}, height_diff of {n.height_diff} (gt height is {np.round(n_gt.height,2)}), width_diff of {n.width_diff} (gt width is {np.round(n_gt.width,2)})')\n",
    "    print(f'len of elements width_def >0.03: {len([e for e in doorNodes if np.abs(e.width_diff)>0.03])}/{len(doorNodes)}')\n",
    "    print(f'len of elements height_diff>0.1: {len([e for e in doorNodes if np.abs(e.height_diff)>0.1])}/{len(doorNodes)}')\n",
    "    print(f'mean height: {np.mean(np.array([e.height for e in doorNodes]))}')\n",
    "    print(f'mean width: {np.mean(np.array([e.doorWidth for e in doorNodes]))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t8.write_obj_with_submeshes(os.path.join(output_folder,f'{ut.get_filename(f)}_doors.obj') , [n.resource for n in doorNodes], [n.name for n in doorNodes])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to file: /home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t8/test/05_MedOffice_01_F2_doors.json\n"
     ]
    }
   ],
   "source": [
    "reform_name='_'.join(ut.get_filename(f).split('_')[:4])+'_doors'\n",
    "\n",
    "json_data=t8.doors_to_json(doorNodes)\n",
    "with open(os.path.join(output_folder,reform_name+'.json'), 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)\n",
    "print(\"JSON data written to file:\", os.path.join(output_folder,reform_name+'.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
