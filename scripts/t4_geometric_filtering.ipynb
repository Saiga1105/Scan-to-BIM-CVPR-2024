{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T4 Combine Detection Results\n",
    "\n",
    "- import the t1 inferenced point clouds\n",
    "- import the t3 doors \n",
    "- export graphs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 110,
=======
   "execution_count": 1,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t1_utils as t1\n",
    "import utils.t2_utils as t2\n",
    "import utils.t4_utils as t4\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 111,
=======
   "execution_count": 2,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 112,
=======
   "execution_count": 3,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 113,
=======
   "execution_count": 4,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[2]\n",
    "\n",
    "print(path)\n",
    "input_folder=path/'data'/'t2'/'test' \n",
    "# input_folder=path/'data'/'t2'/'training' \n",
    "\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t4'/ 'test'\n",
    "# output_folder=path/'data'/'t4'/ 'training'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "resolution=0.05\n",
    "min_cluster_points=1000\n",
    "eps=0.5\n",
    "size=[12,12,100] #size wall boxes\n",
    "threshold_column_height=1.5#m\n",
    "threshold_wall_dim=0.5#m\n",
    "threshold_wall_verticallity=0.2# angle to horizontal\n",
    "threshold_door_dim=1.6#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import classes"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 114,
=======
   "execution_count": 5,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "{'classes': [{'name': 'unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'beams', 'id': 5, 'temp_id': 6, 'color': '#79c314'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
=======
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'windows', 'id': 5, 'temp_id': 6, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CREATE INITIAL OBJECT PCDS"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 115,
=======
   "execution_count": 6,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [],
   "source": [
    "files=utl.get_list_of_files(input_folder, '.laz')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 122,
=======
   "execution_count": 8,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 08_ShortOffice_01_F1_small_pred...\n",
<<<<<<< HEAD
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 2.6838 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 3.2593 seconds to execute.\n",
      ": 4 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 3.6791 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 4.5650 seconds to execute.\n",
      ": 9 clusters found\n",
      "walls\n",
      "Function fit_planes took 3.3032 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.1971 seconds to execute.\n",
      "Function fit_planes took 3.6148 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.3547 seconds to execute.\n",
      "Function fit_planes took 4.0537 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.9524 seconds to execute.\n",
      "Function fit_planes took 5.9125 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.2283 seconds to execute.\n",
      "Function fit_planes took 5.8499 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.5389 seconds to execute.\n",
      "Function fit_planes took 2.6425 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3674 seconds to execute.\n",
      "Function fit_planes took 2.0721 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.5615 seconds to execute.\n",
      "Function fit_planes took 6.3184 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.8250 seconds to execute.\n",
      "Function fit_planes took 1.1611 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.3290 seconds to execute.\n",
      "Function fit_planes took 3.3631 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.1360 seconds to execute.\n",
      "Function fit_planes took 2.8611 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.4589 seconds to execute.\n",
      "Function fit_planes took 2.8637 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.5108 seconds to execute.\n",
      ": 79 clusters found\n",
      "columns\n",
      ": 41 clusters found\n",
      "doors\n",
      ": 12 clusters found\n",
      "beams\n",
      "Created 145 PointCloudNodes created from 08_ShortOffice_01_F1_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\08_ShortOffice_01_F1_small_pred.laz\n",
      "DONE\n",
      "processing 08_ShortOffice_01_F2_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 2.5487 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 3.1244 seconds to execute.\n",
      ": 1 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 3.4120 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 4.2719 seconds to execute.\n",
      ": 3 clusters found\n",
      "walls\n",
      "Function fit_planes took 3.2662 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.1873 seconds to execute.\n",
      "Function fit_planes took 3.4132 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.2036 seconds to execute.\n",
      "Function fit_planes took 2.7938 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3084 seconds to execute.\n",
      "Function fit_planes took 3.7634 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.7302 seconds to execute.\n",
      "Function fit_planes took 4.2807 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 5.5210 seconds to execute.\n",
      "Function fit_planes took 5.3683 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.5655 seconds to execute.\n",
      "Function fit_planes took 2.4199 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.8480 seconds to execute.\n",
      "Function fit_planes took 6.0799 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.3983 seconds to execute.\n",
      "Function fit_planes took 1.9176 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.3677 seconds to execute.\n",
      "Function fit_planes took 2.7309 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.4891 seconds to execute.\n",
      "Function fit_planes took 2.8638 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3210 seconds to execute.\n",
      "Function fit_planes took 2.7102 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3013 seconds to execute.\n",
      ": 88 clusters found\n",
      "columns\n",
      ": 38 clusters found\n",
      "doors\n",
      ": 1 clusters found\n",
      "beams\n",
      "Created 131 PointCloudNodes created from 08_ShortOffice_01_F2_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\08_ShortOffice_01_F2_small_pred.laz\n",
      "DONE\n",
      "processing 11_MedOffice_05_F2_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 18.2685 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 21.0417 seconds to execute.\n",
      ": 3 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 19.8542 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 24.0820 seconds to execute.\n",
      ": 5 clusters found\n",
      "walls\n",
      "Function fit_planes took 2.8362 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.1638 seconds to execute.\n",
      "Function fit_planes took 2.4187 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.6264 seconds to execute.\n",
      "Function fit_planes took 1.3891 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.5556 seconds to execute.\n",
      "Function fit_planes took 1.8791 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.0942 seconds to execute.\n",
      "Function fit_planes took 3.4368 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.1695 seconds to execute.\n",
      "Function fit_planes took 1.9682 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.4638 seconds to execute.\n",
      "Function fit_planes took 2.4486 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.0787 seconds to execute.\n",
      "Function fit_planes took 1.9062 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.1804 seconds to execute.\n",
      "Function fit_planes took 2.5959 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.1515 seconds to execute.\n",
      "Function fit_planes took 2.0060 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.6216 seconds to execute.\n",
      "Function fit_planes took 6.9838 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 8.3961 seconds to execute.\n",
      "Function fit_planes took 11.4643 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 13.7195 seconds to execute.\n",
      "Function fit_planes took 9.4573 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 11.5291 seconds to execute.\n",
      "Function fit_planes took 2.9842 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.5329 seconds to execute.\n",
      "Function fit_planes took 3.6891 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.6005 seconds to execute.\n",
      "Function fit_planes took 6.1877 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.8938 seconds to execute.\n",
      "Function fit_planes took 1.2533 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.5213 seconds to execute.\n",
      "Function fit_planes took 7.0392 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 8.4708 seconds to execute.\n",
      "Function fit_planes took 8.8084 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 10.6460 seconds to execute.\n",
      "Function fit_planes took 7.0765 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 7.9692 seconds to execute.\n",
      "Function fit_planes took 2.9535 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.5102 seconds to execute.\n",
      "Function fit_planes took 1.1011 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.2481 seconds to execute.\n",
      "Function fit_planes took 0.5041 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.5322 seconds to execute.\n",
      "Function fit_planes took 1.9534 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.2938 seconds to execute.\n",
      "Function fit_planes took 2.3045 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.7881 seconds to execute.\n",
      "Function fit_planes took 5.5304 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.5637 seconds to execute.\n",
      "Function fit_planes took 1.9673 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.3903 seconds to execute.\n",
      "Function fit_planes took 2.6054 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.9580 seconds to execute.\n",
      "Function fit_planes took 1.4135 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.7568 seconds to execute.\n",
      "Function fit_planes took 1.4420 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6215 seconds to execute.\n",
      "Function fit_planes took 1.3685 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.5430 seconds to execute.\n",
      "Function fit_planes took 1.9112 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.1269 seconds to execute.\n",
      "Function fit_planes took 1.6253 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.8083 seconds to execute.\n",
      "Function fit_planes took 3.8311 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.1732 seconds to execute.\n",
      "Function fit_planes took 2.2509 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.6165 seconds to execute.\n",
      ": 118 clusters found\n",
      "columns\n",
      ": 19 clusters found\n",
      "doors\n",
      ": 10 clusters found\n",
      "beams\n",
      "Created 155 PointCloudNodes created from 11_MedOffice_05_F2_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\11_MedOffice_05_F2_small_pred.laz\n",
      "DONE\n",
      "processing 11_MedOffice_05_F4_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 13.0986 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 15.9593 seconds to execute.\n",
      ": 8 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 14.3543 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 18.0501 seconds to execute.\n",
      ": 9 clusters found\n",
      "walls\n",
      "Function fit_planes took 1.4650 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6661 seconds to execute.\n",
      "Function fit_planes took 1.8862 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.0469 seconds to execute.\n",
      "Function fit_planes took 3.0348 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.6289 seconds to execute.\n",
      "Function fit_planes took 1.1631 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.2669 seconds to execute.\n",
      "Function fit_planes took 1.7887 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.0698 seconds to execute.\n",
      "Function fit_planes took 1.5048 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.7980 seconds to execute.\n",
      "Function fit_planes took 0.2924 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.3040 seconds to execute.\n",
      "Function fit_planes took 6.8684 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 8.8203 seconds to execute.\n",
      "Function fit_planes took 1.8351 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.2840 seconds to execute.\n",
      "Function fit_planes took 1.2734 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.3901 seconds to execute.\n",
      "Function fit_planes took 1.6817 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.9346 seconds to execute.\n",
      "Function fit_planes took 2.7784 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.2983 seconds to execute.\n",
      "Function fit_planes took 0.2284 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.2324 seconds to execute.\n",
      "Function fit_planes took 1.4388 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6092 seconds to execute.\n",
      "Function fit_planes took 2.1306 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.2311 seconds to execute.\n",
      "Function fit_planes took 3.4419 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.6899 seconds to execute.\n",
      "Function fit_planes took 2.9121 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3605 seconds to execute.\n",
      "Function fit_planes took 5.3533 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.5995 seconds to execute.\n",
      "Function fit_planes took 3.8817 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.9195 seconds to execute.\n",
      "Function fit_planes took 2.3164 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.4444 seconds to execute.\n",
      "Function fit_planes took 2.8718 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.0500 seconds to execute.\n",
      "Function fit_planes took 5.4831 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.4148 seconds to execute.\n",
      "Function fit_planes took 7.5391 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 9.6506 seconds to execute.\n",
      "Function fit_planes took 11.8229 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 13.8813 seconds to execute.\n",
      "Function fit_planes took 3.4437 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.4504 seconds to execute.\n",
      "Function fit_planes took 1.8077 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.0543 seconds to execute.\n",
      "Function fit_planes took 1.9299 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.3138 seconds to execute.\n",
      "Function fit_planes took 6.9842 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 8.5002 seconds to execute.\n",
      "Function fit_planes took 7.4680 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 9.2865 seconds to execute.\n",
      "Function fit_planes took 2.5595 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.9801 seconds to execute.\n",
      "Function fit_planes took 2.0138 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.5144 seconds to execute.\n",
      "Function fit_planes took 1.6204 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.8146 seconds to execute.\n",
      "Function fit_planes took 1.0791 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.1996 seconds to execute.\n",
      "Function fit_planes took 1.2330 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.4548 seconds to execute.\n",
      "Function fit_planes took 2.0048 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.3472 seconds to execute.\n",
      ": 107 clusters found\n",
      "columns\n",
      ": 14 clusters found\n",
      "doors\n",
      ": 13 clusters found\n",
      "beams\n",
      "Created 151 PointCloudNodes created from 11_MedOffice_05_F4_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\11_MedOffice_05_F4_small_pred.laz\n",
      "DONE\n",
      "processing 25_Parking_01_F1_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 3.7094 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 4.9962 seconds to execute.\n",
      ": 18 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 2.4057 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 2.9938 seconds to execute.\n",
      ": 33 clusters found\n",
      "walls\n",
      "Function fit_planes took 1.5288 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6222 seconds to execute.\n",
      "Function fit_planes took 2.5004 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.9515 seconds to execute.\n",
      "Function fit_planes took 1.5870 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.9104 seconds to execute.\n",
      "Function fit_planes took 0.2554 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.2664 seconds to execute.\n",
      "Function fit_planes took 0.1220 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1220 seconds to execute.\n",
      "Function fit_planes took 5.4209 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.7017 seconds to execute.\n",
      "Function fit_planes took 5.1215 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 5.9956 seconds to execute.\n",
      "Function fit_planes took 2.7389 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.1519 seconds to execute.\n",
      "Function fit_planes took 2.2311 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.4892 seconds to execute.\n",
      "Function fit_planes took 0.4676 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.4998 seconds to execute.\n",
      "Function fit_planes took 1.7968 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.1381 seconds to execute.\n",
      "Function fit_planes took 5.0085 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 5.9705 seconds to execute.\n",
      "Function fit_planes took 0.2632 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.2671 seconds to execute.\n",
      "Function fit_planes took 0.3021 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.3096 seconds to execute.\n",
      "Function fit_planes took 0.5351 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.6017 seconds to execute.\n",
      "Function fit_planes took 1.5975 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.7214 seconds to execute.\n",
      "Function fit_planes took 0.2665 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.2730 seconds to execute.\n",
      "Function fit_planes took 0.4318 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.4658 seconds to execute.\n",
      "Function fit_planes took 0.7348 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.7946 seconds to execute.\n",
      "Function fit_planes took 0.1920 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.2090 seconds to execute.\n",
      ": 38 clusters found\n",
      "columns\n",
      ": 21 clusters found\n",
      "doors\n",
      ": 0 clusters found\n",
      "beams\n",
      "Created 110 PointCloudNodes created from 25_Parking_01_F1_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\25_Parking_01_F1_small_pred.laz\n",
      "DONE\n",
      "processing 25_Parking_01_F2_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 2.8872 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 3.6674 seconds to execute.\n",
      ": 21 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 3.0571 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 4.0568 seconds to execute.\n",
      ": 30 clusters found\n",
      "walls\n",
      "Function fit_planes took 0.3739 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.3837 seconds to execute.\n",
      "Function fit_planes took 0.1613 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1623 seconds to execute.\n",
      "Function fit_planes took 1.2923 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6198 seconds to execute.\n",
      "Function fit_planes took 1.3642 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.6409 seconds to execute.\n",
      "Function fit_planes took 1.1519 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.2839 seconds to execute.\n",
      "Function fit_planes took 0.1223 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1233 seconds to execute.\n",
      "Function fit_planes took 0.1251 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1261 seconds to execute.\n",
      "Function fit_planes took 1.1991 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.2833 seconds to execute.\n",
      "Function fit_planes took 5.9975 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 6.2402 seconds to execute.\n",
      "Function fit_planes took 3.0646 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 3.3368 seconds to execute.\n",
      "Function fit_planes took 0.9103 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.0161 seconds to execute.\n",
      "Function fit_planes took 0.3100 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.3415 seconds to execute.\n",
      "Function fit_planes took 0.5053 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.5219 seconds to execute.\n",
      "Function fit_planes took 0.3835 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.4286 seconds to execute.\n",
      "Function fit_planes took 0.4793 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.5264 seconds to execute.\n",
      "Function fit_planes took 3.8295 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 4.3623 seconds to execute.\n",
      "Function fit_planes took 0.3971 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.4031 seconds to execute.\n",
      "Function fit_planes took 0.1327 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1337 seconds to execute.\n",
      "Function fit_planes took 0.1266 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.1276 seconds to execute.\n",
      "Function fit_planes took 1.3189 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.4857 seconds to execute.\n",
      ": 33 clusters found\n",
      "columns\n",
      ": 25 clusters found\n",
      "doors\n",
      ": 0 clusters found\n",
      "beams\n",
      "Created 109 PointCloudNodes created from 25_Parking_01_F2_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\25_Parking_01_F2_small_pred.laz\n",
      "DONE\n",
      "processing 34_Parking_04_F1_small_pred...\n",
      "unassigned\n",
      "floors\n",
      "Function fit_planes took 0.4730 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 0.4928 seconds to execute.\n",
      ": 1 clusters found\n",
      "ceilings\n",
      "Function fit_planes took 0.4715 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters took 0.5791 seconds to execute.\n",
      ": 3 clusters found\n",
      "walls\n",
      "Function fit_planes took 1.6535 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.0056 seconds to execute.\n",
      "Function fit_planes took 0.8864 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 0.9711 seconds to execute.\n",
      "Function fit_planes took 2.3408 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 2.7052 seconds to execute.\n",
      "Function fit_planes took 1.5617 seconds to execute.\n",
      "Function split_point_cloud_in_planar_clusters2 took 1.8384 seconds to execute.\n",
      ": 12 clusters found\n",
      "columns\n",
      ": 1 clusters found\n",
      "doors\n",
      ": 1 clusters found\n",
      "beams\n",
      "Created 18 PointCloudNodes created from 34_Parking_04_F1_small_pred\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\34_Parking_04_F1_small_pred.laz\n",
      "DONE\n"
=======
      "Function fit_planes took 3.1143 seconds to execute.\n",
      "floors : 4 clusters found\n",
      "Function fit_planes took 11.6154 seconds to execute.\n",
      "ceilings : 9 clusters found\n",
      "Function fit_planes took 7.7359 seconds to execute.\n",
      "Function fit_planes took 7.1171 seconds to execute.\n",
      "Function fit_planes took 4.0049 seconds to execute.\n",
      "Function fit_planes took 7.3100 seconds to execute.\n",
      "Function fit_planes took 6.9514 seconds to execute.\n",
      "Function fit_planes took 3.2288 seconds to execute.\n",
      "Function fit_planes took 2.3468 seconds to execute.\n",
      "Function fit_planes took 8.2539 seconds to execute.\n",
      "Function fit_planes took 1.6029 seconds to execute.\n",
      "Function fit_planes took 4.8709 seconds to execute.\n",
      "Function fit_planes took 3.6841 seconds to execute.\n",
      "Function fit_planes took 3.7587 seconds to execute.\n",
      "walls : 257 clusters found\n",
      "columns : 42 clusters found\n",
      "doors : 7 clusters found\n",
      "Created 319 PointCloudNodes created from 08_ShortOffice_01_F1_small_pred\n"
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# for f in files[:1]:\n",
    "for f in files:\n",
    "    \n",
=======
    "for f in files[:1]:#, files_t2[:1], files_t3[:1]):\n",
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
    "    objectNodes=[]\n",
    "    \n",
    "    # check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)}...')      \n",
    "    las = laspy.read(f) if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las,getNormals=True) if 'pcd' not in globals() else pcd\n",
    "    \n",
    "    \n",
    "    #seperate initial objects\n",
    "    for c in class_dict['classes']:\n",
    "        \n",
    "        ##------------------------FLOORS CEILINGS--------------------------------------------\n",
    "        if c['id'] in [0,1]: #floors,ceilings CORRECT\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            \n",
    "            #retrieve objects from planar clusters\n",
    "            clustered_pcds,clustered_planes=t4.split_point_cloud_in_planar_clusters(class_pcd,\n",
    "                                                                                    sample_resolution=resolution,\n",
    "                                                                                    distance_threshold=0.05, \n",
    "                                                                                    min_inliers=1000,\n",
<<<<<<< HEAD
    "                                                                                    eps=eps,\n",
    "                                                                                    min_cluster_points=200) #this somehow created only 2 nodes in 05_MedOffice_01_F2 while there should be more nodes\n",
    "            objectNodes.extend(nodes)\n",
    "\n",
    "            print(f': {len(nodes)} clusters found')  \n",
=======
    "                                                                                    eps=0.5,\n",
    "                                                                                    min_cluster_points=200)\n",
    "            \n",
    "            for i,n in enumerate(clustered_pcds):\n",
    "                objectNodes.append(PointCloudNode(resource=n,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=i+1+c['id']*100, #+1 because 0 is clutter\n",
    "                                            plane=clustered_planes[i],\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(i+1+c['id']*100)))       \n",
    "            print( c['name'], f': {len(clustered_pcds)} clusters found')       \n",
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
    "        \n",
    "        ##------------------------WALLS--------------------------------------------\n",
    "        if c['id'] in [2]: \n",
<<<<<<< HEAD
    "            nodes,rest_pcd=t4.create_wall_nodes(las,pcd,f,c,sample_resolution=0.03,\n",
    "                                                distance_threshold=0.03, \n",
    "                                                min_inliers=200,\n",
    "                                                eps=eps,\n",
    "                                                threshold_min_cluster_points=threshold_min_cluster_points,\n",
    "                                                size=size,\n",
    "                                                threshold_wall_verticality=threshold_wall_verticality,\n",
    "                                                threshold_wall_dim=threshold_wall_dim,\n",
    "                                                threshold_clustering_distance=threshold_clustering_distance)\n",
    "            nodes=t4.merge_wall_nodes2(nodes,threshold_clustering_distance=threshold_clustering_distance)\n",
    "            \n",
    "            objectNodes.extend(nodes)\n",
    "            thrashNode.resource+=rest_pcd\n",
    "            print(f': {len(nodes)} clusters found')\n",
    "     \n",
=======
    "            counter=0\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            \n",
    "            #split into boxes (otherwise you will get horizontal planes mostly)\n",
    "            min_bound=pcd.get_min_bound()\n",
    "            max_bound=pcd.get_max_bound()            \n",
    "            box=o3d.geometry.AxisAlignedBoundingBox(min_bound=np.array([min_bound[0]-5,min_bound[1]-5,min_bound[2]-5]),\n",
    "                                        max_bound=np.array([max_bound[0]+5,max_bound[1]+5,max_bound[2]+5]))\n",
    "            boxes,names=gmu.divide_box_in_boxes(box,size=size)\n",
    "            \n",
    "            # select indices per boxes\n",
    "            sub_pcds=[]\n",
    "            for box,name in zip(boxes,names):\n",
    "                idxLists=box.get_point_indices_within_bounding_box(class_pcd.points)\n",
    "                sub_pcd=class_pcd.select_by_index(idxLists)\n",
    "            \n",
    "                #retrieve objects from planar clusters\n",
    "                if len(np.asarray(sub_pcd.points))<min_cluster_points:\n",
    "                    continue\n",
    "                clustered_pcds,clustered_planes=t4.split_point_cloud_in_planar_clusters(sub_pcd,\n",
    "                                                                                    sample_resolution=0.03,\n",
    "                                                                                    distance_threshold=0.03, \n",
    "                                                                                    min_inliers=200,\n",
    "                                                                                    eps=0.5,\n",
    "                                                                                    min_cluster_points=200)\n",
    " \n",
    "                if len(clustered_pcds)!=0:\n",
    "                    for p,pl in zip(clustered_pcds,clustered_planes):\n",
    "                        counter+=1\n",
    "                        objectNodes.append(PointCloudNode(resource=p,\n",
    "                                                    class_id=c['id'],\n",
    "                                                    class_name=c['name'],\n",
    "                                                    object_id=c['id']*100+counter, \n",
    "                                                    plane=pl,\n",
    "                                                    color=ut.random_color(),\n",
    "                                                    name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+counter)))       \n",
    "            print( c['name'], f': {counter} clusters found')  \n",
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
    "            \n",
    "        # ###------------------------COLUMNS--------------------------------------------\n",
    "        if c['id'] in [3]:\n",
    "            idx = np.where((las['classes'] == c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            object_pcds=[]\n",
    "            for i in np.unique(object_labels): \n",
    "                if i==0:\n",
    "                    potential_object_pcds=t4.split_point_cloud_by_dbscan(class_pcd.select_by_index(np.where(object_labels==i)[0]),eps=eps,min_cluster_points=min_cluster_points)\n",
    "                    #retain only clusters with sufficient height\n",
    "                    object_pcds.extend([p for p in potential_object_pcds])\n",
    "                else:           \n",
    "                    object_pcds.append(class_pcd.select_by_index(np.where(object_labels==i)[0]))\n",
    "            \n",
    "            for i,p in enumerate(object_pcds):    \n",
    "                objectNodes.append(PointCloudNode(resource=p,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=c['id']+i,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+i)))\n",
    "            print( c['name'], f': {len(object_pcds)} clusters found')       \n",
    "            \n",
    "        # ###------------------------DOORS--------------------------------------------\n",
    "        if c['id'] in [4]: \n",
    "            idx = np.where((las['classes'] == c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            object_pcds=[]\n",
    "            for i in np.unique(object_labels): \n",
    "                if i==0:\n",
    "                    object_pcds.extend(t4.split_point_cloud_by_dbscan(class_pcd.select_by_index(np.where(object_labels==i)[0]),eps=eps,min_cluster_points=min_cluster_points))\n",
    "                else:           \n",
    "                    object_pcds.append(class_pcd.select_by_index(np.where(object_labels==i)[0]))\n",
    "            \n",
    "            for i,p in enumerate(object_pcds):    \n",
    "                objectNodes.append(PointCloudNode(resource=p,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            object_id=c['id']+i,\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_'+c['name']+'_'+str(c['id']*100+i)))\n",
    "            print( c['name'], f': {len(object_pcds)} clusters found')      \n",
    "        else:\n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            thrashNode=PointCloudNode(resource=pcd,\n",
    "                                            class_id=c['id'],\n",
    "                                            class_name=c['name'],\n",
    "                                            color=ut.random_color(),\n",
    "                                            name=ut.get_filename(f)+'_unassigned')\n",
    "\n",
    "    print(f'Created {len(objectNodes)} PointCloudNodes created from {ut.get_filename(f)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([p.resource.paint_uniform_color(ut.random_color()) for p in nodes ])\n",
    "o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "stored_nodes=copy.deepcopy(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes=copy.deepcopy(stored_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "joined_pcd=gmu.join_geometries([p.paint_uniform_color(ut.random_color()) for p in clustered_pcds ])\n",
    "joined_meshes=gmu.join_geometries([p.paint_uniform_color(ut.random_color()) for p in clustered_plane_meshes ])\n",
    "o3d.visualization.draw_geometries([joined_pcd,joined_meshes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
=======
   "execution_count": 16,
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_e57Index': 0,\n",
       " 'pointCount': 14959,\n",
       " 'e57XmlPath': None,\n",
       " '_cartesianBounds': array([-2.28800000e+01, -1.35000000e+01,  9.39000000e+00,  1.91700000e+01,\n",
       "        -1.00000000e-02,  5.28571429e-02]),\n",
       " '_orientedBounds': array([[-2.00641522e+01,  2.22818819e+01,  4.63756496e-02],\n",
       "        [-1.12199082e+01,  1.50613484e+01,  5.91188445e-02],\n",
       "        [-2.52897033e+01,  1.58812512e+01,  5.27173734e-02],\n",
       "        [-2.00641253e+01,  2.22817896e+01, -2.45775967e-02],\n",
       "        [-1.64454323e+01,  8.66062540e+00, -5.49267805e-03],\n",
       "        [-2.52896764e+01,  1.58811589e+01, -1.82358730e-02],\n",
       "        [-1.12198813e+01,  1.50612561e+01, -1.18344018e-02],\n",
       "        [-1.64454592e+01,  8.66071767e+00,  6.54605683e-02]]),\n",
       " '_orientedBoundingBox': OrientedBoundingBox: center: (-18.2548, 15.4713, 0.0204415), extent: 11.4174, 8.26284, 0.0709533),\n",
       " '_subject': rdflib.term.URIRef('file:///08_ShortOffice_01_F1_small_pred_floors_2'),\n",
       " '_graph': None,\n",
       " '_graphPath': None,\n",
       " '_path': None,\n",
       " '_name': '08_ShortOffice_01_F1_small_pred_floors_2',\n",
       " '_timestamp': None,\n",
       " '_resource': PointCloud with 14959 points.,\n",
       " '_cartesianTransform': array([[ 1.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "         -1.85291309e+01],\n",
       "        [ 0.00000000e+00,  1.00000000e+00,  0.00000000e+00,\n",
       "          1.55886523e+01],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00,\n",
       "          1.60661608e-02],\n",
       "        [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "          1.00000000e+00]]),\n",
       " 'class_id': 0,\n",
       " 'class_name': 'floors',\n",
       " 'object_id': 2,\n",
       " 'plane': array([-3.93628552e-04, -5.59139325e-04,  9.99999766e-01, -3.76186822e-03]),\n",
       " 'color': array([0.01176471, 0.07843137, 0.54117647])}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{key:value for key, value in objectNodes[1].__dict__.items() if not key.startswith('__') and not callable(key)}              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pcd_slice=t2.slice_point_cloud(pcd, -100, pcd.get_center()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([p.resource.paint_uniform_color(ut.random_color()) for p in objectNodes])\n",
    "o3d.visualization.draw_geometries([joined_pcd,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS WALLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:238 \n",
      "Retained 153 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "# wall planes should be near vertical!\n",
    "wallNodes=[n for n in objectNodes if n.class_id == 2]\n",
    "print(f'Initial number of nodes:{len(wallNodes)} ')\n",
    "newWallNodes=[]\n",
    "\n",
    "for n in wallNodes:\n",
    "    dim=n.resource.get_oriented_bounding_box().extent\n",
    "    # check verticality and dimensions\n",
    "    if (np.abs(n.plane[2])<threshold_wall_verticallity) & (dim[0]>threshold_wall_dim) & (dim[1]>threshold_wall_dim):\n",
    "        newWallNodes.append(n)\n",
    "    else:\n",
    "        thrashNode.resource+=n.resource\n",
    "\n",
    "print(f'Retained {len(newWallNodes)} merged column nodes.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd1=gmu.join_geometries([p.resource.paint_uniform_color([1,0,0]) for p in wallNodes if p not in newWallNodes])\n",
    "\n",
    "# o3d.visualization.draw_geometries([joined_pcd1,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS DOORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:5 \n",
      "Retained 1 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "# wall planes should be near vertical!\n",
    "doorPcdNodes=[n for n in objectNodes if n.class_id == 4]\n",
    "print(f'Initial number of nodes:{len(doorPcdNodes)} ')\n",
    "newDoorPcdNodes=[]\n",
    "\n",
    "for n in doorPcdNodes:\n",
    "    dim=n.resource.get_oriented_bounding_box().extent\n",
    "    # check verticality and dimensions\n",
    "    if (dim[0]>threshold_door_dim) & (dim[1]>threshold_door_dim):\n",
    "        newDoorPcdNodes.append(n)\n",
    "    else:\n",
    "        thrashNode.resource+=n.resource\n",
    "\n",
    "print(f'Retained {len(newDoorPcdNodes)} merged column nodes.')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS COLUMNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial number of nodes:48 \n",
      "Retained 48 merged column nodes.\n"
     ]
    }
   ],
   "source": [
    "threshold_column_points=100\n",
    "threshold_clustering_distance=0.5\n",
    "threshold_column_height=1\n",
    "threshold_column_verticallity=0.2\n",
    "\n",
    "columnPcdNodes=[n for n in objectNodes if n.class_id == 3]\n",
    "print(f'Initial number of nodes:{len(columnPcdNodes)} ')\n",
    "\n",
    "for n in columnPcdNodes: \n",
    "    \n",
    "    #scrap horizontal columns\n",
    "    n.resource=n.resource.select_by_index(np.where(np.asarray(n.resource.normals)[:,2]<threshold_column_verticallity)[0])\n",
    "    n.get_oriented_bounding_box()\n",
    "    \n",
    "    if len(np.asarray(n.resource.points))<threshold_column_points or  (p.get_axis_aligned_bounding_box().max_bound[2]-p.get_axis_aligned_bounding_box().min_bound[2])>threshold_column_height:\n",
    "        columnPcdNodes.pop(n)\n",
    "        thrashNode.resource+=n.resource\n",
    "    else:\n",
    "        for m in columnPcdNodes:\n",
    "            if n!=m and len(np.asarray(n.resource.points))<len(np.asarray(m.resource.points)) and np.linalg.norm(n.cartesianTransform[0:3,3] - m.cartesianTransform[0:3,3]) < threshold_clustering_distance:\n",
    "                m.resource+=n.resource\n",
    "                columnPcdNodes.pop(n)\n",
    "                break\n",
    "print(f'Retained {len(columnPcdNodes)} merged column nodes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(n.color) for n in columnPcdNodes if n.resource is not None])\n",
    "o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTPUTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pcd_nodes=[n for n in objectNodes if n.class_id in [0,1,2]]+doorPcdNodes+columnPcdNodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Graph identifier=Nbdce8cadde464f199ab7743101b6ca42 (<class 'rdflib.graph.Graph'>)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl.nodes_to_graph(total_pcd_nodes,\n",
    "                graphPath=str(output_folder/f'{ut.get_filename(t1)}_pcdgraph.ttl'),\n",
    "                save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export point cloud\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PointCloud with 401102 points.\n"
     ]
    }
   ],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource for n  in total_pcd_nodes])\n",
    "print(joined_pcd)"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain labels\n",
    "labels_segmentation=[]\n",
    "labels_objects=[]\n",
    "\n",
    "for i,n in enumerate(total_pcd_nodes):\n",
    "    length=len(np.asarray(n.resource.points))\n",
    "    labels_segmentation.extend(list(np.full(length,n.class_id)))\n",
    "    labels_objects.extend(list(np.full(length,n.object_id)))  \n",
    "\n",
    "labels_classes=np.array(labels_segmentation)\n",
    "labels_objects=np.array(labels_objects)"
   ]
<<<<<<< HEAD
=======
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#interpolate labels\n",
    "indices,distances=gmu.compute_nearest_neighbors(np.asarray(las.xyz),np.asarray(joined_pcd.points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_c=np.full((las.xyz.shape[0],1),255)\n",
    "labels_o=np.full((las.xyz.shape[0],1),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3472028,)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inliers.shape\n",
    "outliers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 401938 is out of bounds for axis 0 with size 401938",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m inliers\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mwhere(distances\u001b[38;5;241m<\u001b[39mresolution)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#modify the labels_c array with the labels_classes array based on the inliers\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m labels_c[inliers]\u001b[38;5;241m=\u001b[39m\u001b[43mlabels_classes\u001b[49m\u001b[43m[\u001b[49m\u001b[43minliers\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m      6\u001b[0m labels_o[inliers]\u001b[38;5;241m=\u001b[39mlabels_objects[indices]\n",
      "\u001b[1;31mIndexError\u001b[0m: index 401938 is out of bounds for axis 0 with size 401938"
     ]
    }
   ],
   "source": [
    "#inliers\n",
    "inliers=np.where(distances<resolution)[0]\n",
    "\n",
    "#modify the labels_c array with the labels_classes array based on the inliers\n",
    "labels_c[inliers]=labels_classes[inliers]\n",
    "labels_o[inliers]=labels_objects[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers\n",
    "outliers=np.where(distances>=resolution)[0]\n",
    "labels_c[outliers]=labels_classes[outliers]\n",
    "labels_o[outliers]=labels_objects[outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new las\n",
    "header = laspy.LasHeader(point_format=3, version=\"1.2\")\n",
    "las = laspy.LasData(header)\n",
    "las.xyz=np.asarray(total_pcd.points)\n",
    "las.red=(np.asarray(total_pcd.colors)[:,0]*65535).astype(np.uint16)\n",
    "las.green=(np.asarray(total_pcd.colors)[:,1]*65535).astype(np.uint16)\n",
    "las.blue=(np.asarray(total_pcd.colors)[:,2]*65535).astype(np.uint16)\n",
    "\n",
    "gmu.las_add_extra_dimensions(las,(labels_segmentation[:,0],labels_objects[:,0],),['classes','objects'],['uint8','uint16'])\n",
    "print(list(las.point_format.dimension_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "las.write(str(output_folder/f'{ut.get_filename(t1)}_t4.laz'))\n",
    "print(str(output_folder/f'{ut.get_filename(t1)}_t4.laz'))"
   ]
>>>>>>> 8d7ef90ab82e7bd9023dc0b0c2a27bc6e73fb7ce
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
