{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "import os.path\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from tabulate import tabulate\n",
    "\n",
    "import json  \n",
    "import copy\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from PIL import Image\n",
    "\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context\n",
    "import utils as utl\n",
    "import utils.t8_utils as t8\n",
    "\n",
    "\n",
    "# Grounding DINO\n",
    "from groundingdino.util.inference import  annotate, load_image, predict\n",
    "from torch.cuda.amp import autocast\n",
    "\n",
    "# segment anything\n",
    "# from segment_anything import build_sam, SamPredictor \n",
    "\n",
    "\n",
    "# diffusers\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[0]\n",
    "\n",
    "print(path)\n",
    "input_folder_t4=path/'data'/'t4'/'train' \n",
    "input_folder_t6=path/'data'/'t6'/'train'\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t8'/ 'train'\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "ckpt_repo_id = \"ShilongLiu/GroundingDINO\"\n",
    "ckpt_filenmae = \"groundingdino_swinb_cogcoor.pth\"\n",
    "ckpt_config_filename = \"GroundingDINO_SwinB.cfg.py\"\n",
    "\n",
    "#parameters\n",
    "image_resolution = 0.01\n",
    "class_id = 5\n",
    "id_count = 4000\n",
    "\n",
    "t_score = 0.55\n",
    "\n",
    "TEXT_PROMPT = \"Door\"\n",
    "BOX_TRESHOLD = 0.20\n",
    "TEXT_TRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Grounding Dino Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with autocast():\n",
    "        groundingdino_model = t8.load_model_hf(ckpt_repo_id, ckpt_filenmae, ckpt_config_filename, device=\"cuda:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud_files=utl.get_list_of_files(input_folder_t4,'.laz')\n",
    "wall_files=utl.get_list_of_files(input_folder_t6,'.ttl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doors_0 : Door Score: 0.8269557893276216 => Referencelevel: 0.02; Width: 0.94; height: 2.01\n",
      "Doors_1 : Door Score: 0.6250131042798361 => Referencelevel: 0.03; Width: 0.98; height: 1.98\n",
      "Doors_2 : Door Score: 0.8070742080609005 => Referencelevel: 0.02; Width: 0.93; height: 2.01\n",
      "Doors_3 : Door Score: 0.7551244995660252 => Referencelevel: 0.0; Width: 0.88; height: 1.95\n",
      "Doors_4 : Door Score: 0.8452296296755474 => Referencelevel: 0.02; Width: 0.9; height: 2.02\n",
      "Doors_5 : Door Score: 0.8410633444786073 => Referencelevel: 0.02; Width: 0.93; height: 2.01\n",
      "Doors_6 : Door Score: 0.9774158401069819 => Referencelevel: 0.01; Width: 0.6; height: 2.12\n",
      "Doors_8 : Door Score: 0.5762718226512274 => Referencelevel: 0.01; Width: 0.98; height: 1.94\n",
      "Doors_11 : Door Score: 0.990124839047591 => Referencelevel: 0.01; Width: 0.92; height: 2.04\n",
      "Doors_12 : Door Score: 0.7818506250778835 => Referencelevel: 0.02; Width: 0.94; height: 2.03\n",
      "Doors_13 : Door Score: 0.6761306897799175 => Referencelevel: 0.0; Width: 0.85; height: 1.99\n",
      "Doors_14 : Door Score: 0.6189605094989142 => Referencelevel: 0.04; Width: 0.95; height: 1.97\n",
      "Doors_15 : Door Score: 0.8473989109198253 => Referencelevel: 0.02; Width: 0.91; height: 2.02\n",
      "Doors_16 : Door Score: 0.631058598359426 => Referencelevel: 0.0; Width: 0.84; height: 1.97\n",
      "Doors_18 : Door Score: 0.9936766177415849 => Referencelevel: 0.02; Width: 1.07; height: 2.02\n",
      "Doors_19 : Door Score: 0.8419360458850862 => Referencelevel: 0.01; Width: 0.91; height: 2.04\n",
      "Doors_20 : Door Score: 0.9714394550025465 => Referencelevel: 0.01; Width: 0.87; height: 2.0\n",
      "Doors_27 : Door Score: 0.8282699724038443 => Referencelevel: 0.01; Width: 0.93; height: 2.02\n",
      "Doors_28 : Door Score: 0.8203741153081259 => Referencelevel: 0.01; Width: 0.96; height: 2.03\n",
      "Doors_29 : Door Score: 0.60196528395017 => Referencelevel: 0.01; Width: 0.88; height: 1.94\n",
      "Doors_30 : Door Score: 0.6545131289629977 => Referencelevel: 0.01; Width: 1.96; height: 1.95\n",
      "Doors_31 : Door Score: 0.7466392327278151 => Referencelevel: 0.01; Width: 1.32; height: 1.95\n",
      "Doors_32 : Door Score: 0.8379722476005556 => Referencelevel: 0.02; Width: 0.92; height: 2.02\n",
      "Doors_33 : Door Score: 0.8342230955759685 => Referencelevel: 0.02; Width: 0.93; height: 2.02\n",
      "Doors_35 : Door Score: 0.7457169142613809 => Referencelevel: 0.01; Width: 0.93; height: 1.95\n",
      "Doors_37 : Door Score: 0.9890717342495919 => Referencelevel: 0.02; Width: 0.94; height: 2.02\n",
      "Doors_39 : Door Score: 0.6260960704364159 => Referencelevel: 0.01; Width: 0.41; height: 1.95\n",
      "Doors_40 : Door Score: 0.6703623435198771 => Referencelevel: 0.01; Width: 1.58; height: 1.94\n",
      "Doors_42 : Door Score: 0.8549597601095836 => Referencelevel: 0.02; Width: 0.91; height: 2.02\n",
      "Doors_43 : Door Score: 0.5914685235420863 => Referencelevel: 0.01; Width: 0.92; height: 1.94\n",
      "Doors_44 : Door Score: 0.843682094415029 => Referencelevel: 0.02; Width: 0.95; height: 2.02\n",
      "Doors_45 : Door Score: 0.6143128693103791 => Referencelevel: 0.02; Width: 0.88; height: 1.95\n",
      "Doors_47 : Door Score: 0.9887994188401436 => Referencelevel: 0.01; Width: 0.94; height: 2.03\n",
      "Doors_50 : Door Score: 0.6179794553915661 => Referencelevel: 0.01; Width: 0.88; height: 1.96\n",
      "Doors_51 : Door Score: 0.5742863737598614 => Referencelevel: 0.01; Width: 0.3; height: 1.93\n",
      "Doors_52 : Door Score: 0.5970085470085471 => Referencelevel: 0.01; Width: 1.56; height: 1.95\n",
      "Number of doors: 36\n",
      "JSON data written to file: /home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t8/train/32_ShortOffice_05_F2_doors.json\n",
      "/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t4/train/33_SmallBuilding_03_F1_small1.laz\n",
      "/home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t6/train/33_SmallBuilding_03_F1_walls.ttl\n",
      "processing 33_SmallBuilding_03_F1_small1...\n",
      "87 wallNodes detected!\n",
      "Matched 87 pointclouds to nodes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doors_0 : Door Score: 0.777350722750028 => Referencelevel: 0.0; Width: 0.8; height: 2.25\n",
      "Doors_1 : Door Score: 0.860120737552643 => Referencelevel: 0.01; Width: 0.91; height: 2.02\n",
      "Doors_2 : Door Score: 0.8588178197542827 => Referencelevel: 0.01; Width: 0.87; height: 2.01\n",
      "Doors_3 : Door Score: 0.6845021277666092 => Referencelevel: 0.02; Width: 1.07; height: 2.3\n",
      "Doors_4 : Door Score: 0.8558429817358654 => Referencelevel: 0.02; Width: 0.92; height: 2.03\n",
      "Doors_5 : Door Score: 0.6919818814705919 => Referencelevel: 0.0; Width: 0.87; height: 1.89\n",
      "Doors_6 : Door Score: 0.6883397453063648 => Referencelevel: 0.0; Width: 1.84; height: 2.41\n",
      "Doors_7 : Door Score: 0.9931517185436356 => Referencelevel: 0.0; Width: 0.96; height: 2.07\n",
      "Doors_11 : Door Score: 0.9917602406607735 => Referencelevel: 0.01; Width: 0.91; height: 2.0\n",
      "Doors_12 : Door Score: 0.7875632271501755 => Referencelevel: 0.02; Width: 0.9; height: 1.99\n",
      "Doors_13 : Door Score: 0.6360830970574716 => Referencelevel: 0.15; Width: 0.73; height: 2.0\n",
      "Doors_20 : Door Score: 0.9881244666046568 => Referencelevel: 0.02; Width: 0.87; height: 2.0\n",
      "Doors_21 : Door Score: 0.6754440397024155 => Referencelevel: 0.02; Width: 0.77; height: 2.22\n",
      "Doors_22 : Door Score: 0.8436543186505636 => Referencelevel: 0.01; Width: 0.94; height: 2.03\n",
      "Doors_23 : Door Score: 0.8943084920170131 => Referencelevel: 0.02; Width: 0.52; height: 2.17\n",
      "Doors_25 : Door Score: 0.9943692195746635 => Referencelevel: 0.01; Width: 0.91; height: 2.02\n",
      "Doors_26 : Door Score: 0.721335736182001 => Referencelevel: 0.0; Width: 0.87; height: 1.91\n",
      "Doors_27 : Door Score: 0.9885173903571236 => Referencelevel: 0.0; Width: 0.99; height: 2.05\n",
      "Doors_30 : Door Score: 0.8583625793457033 => Referencelevel: 0.01; Width: 0.89; height: 2.02\n",
      "Doors_31 : Door Score: 0.9914708899127114 => Referencelevel: 0.01; Width: 0.89; height: 2.02\n",
      "Doors_33 : Door Score: 0.9925850795374977 => Referencelevel: 0.01; Width: 0.92; height: 2.02\n",
      "Doors_34 : Door Score: 0.9859103250006835 => Referencelevel: 0.02; Width: 1.01; height: 2.03\n",
      "Doors_35 : Door Score: 0.9896215705407991 => Referencelevel: 0.03; Width: 0.92; height: 2.02\n",
      "Doors_36 : Door Score: 0.9914237351881134 => Referencelevel: 0.02; Width: 0.95; height: 2.01\n",
      "Doors_37 : Door Score: 0.9898018009132811 => Referencelevel: 0.02; Width: 0.94; height: 2.01\n",
      "Doors_38 : Door Score: 0.7993641237417858 => Referencelevel: 0.01; Width: 0.64; height: 2.03\n",
      "Doors_41 : Door Score: 0.9908463632067046 => Referencelevel: 0.02; Width: 1.06; height: 2.1\n",
      "Doors_42 : Door Score: 0.5989690124988556 => Referencelevel: 0.02; Width: 0.95; height: 1.9\n",
      "Doors_43 : Door Score: 0.7466676990618416 => Referencelevel: 0.02; Width: 1.86; height: 2.21\n",
      "Doors_45 : Door Score: 0.9886887181136345 => Referencelevel: 0.01; Width: 0.92; height: 2.01\n",
      "Doors_46 : Door Score: 0.7550189574228393 => Referencelevel: 0.0; Width: 0.9; height: 1.95\n",
      "Doors_47 : Door Score: 0.6224350126584371 => Referencelevel: 0.04; Width: 0.96; height: 1.93\n",
      "Doors_48 : Door Score: 0.6285497069358826 => Referencelevel: 0.0; Width: 0.89; height: 1.95\n",
      "Doors_49 : Door Score: 0.6230851006507874 => Referencelevel: 0.02; Width: 0.94; height: 1.93\n",
      "Doors_50 : Door Score: 0.6378286302089692 => Referencelevel: 0.02; Width: 0.84; height: 1.95\n",
      "Doors_51 : Door Score: 0.6247906903425853 => Referencelevel: 0.02; Width: 0.92; height: 1.95\n",
      "Doors_52 : Door Score: 0.6150484601656597 => Referencelevel: 0.02; Width: 0.86; height: 1.95\n",
      "Doors_53 : Door Score: 0.612737390200297 => Referencelevel: 0.01; Width: 0.9; height: 1.92\n",
      "Doors_54 : Door Score: 0.7584222430321906 => Referencelevel: 0.02; Width: 0.93; height: 1.95\n",
      "Doors_55 : Door Score: 0.5991151253382366 => Referencelevel: 0.0; Width: 0.95; height: 1.95\n",
      "Doors_56 : Door Score: 0.7801498608787856 => Referencelevel: 0.02; Width: 0.92; height: 1.98\n",
      "Doors_57 : Door Score: 0.7697524628043175 => Referencelevel: 0.02; Width: 0.88; height: 1.97\n",
      "Doors_58 : Door Score: 0.7831911592847772 => Referencelevel: 0.02; Width: 0.99; height: 1.99\n",
      "Doors_59 : Door Score: 0.6260993274052938 => Referencelevel: 0.02; Width: 0.91; height: 1.93\n",
      "Doors_60 : Door Score: 0.637676264444987 => Referencelevel: 0.02; Width: 0.87; height: 1.94\n",
      "Doors_61 : Door Score: 0.6400123655796052 => Referencelevel: 0.0; Width: 0.91; height: 1.95\n",
      "Doors_62 : Door Score: 0.6255544877052307 => Referencelevel: 0.01; Width: 0.75; height: 1.94\n",
      "Doors_63 : Door Score: 0.6310528635978699 => Referencelevel: 0.02; Width: 0.91; height: 1.95\n",
      "Doors_64 : Door Score: 0.8411130944887798 => Referencelevel: 0.02; Width: 0.9; height: 2.01\n",
      "Number of doors: 49\n",
      "JSON data written to file: /home/sdegeyter/Code/Scan-to-BIM-CVPR-2024/data/t8/train/33_SmallBuilding_03_F1_doors.json\n"
     ]
    }
   ],
   "source": [
    "for f_pcd in point_cloud_files:\n",
    "    project = f_pcd.split(\"/\")[-1].split(\".\")[-2].split(\"_small1\")[0]\n",
    "    for f_rdf in wall_files:\n",
    "        if project == f_rdf.split(\"/\")[-1].split(\".\")[-2].split(\"_walls\")[0]:\n",
    "            break\n",
    "    print(f_pcd)\n",
    "    print(f_rdf)\n",
    "    doorNodes = []\n",
    "    door_count = 0\n",
    "    print(f'processing {ut.get_filename(f_pcd)}...') \n",
    "    wallNodes=tl.graph_path_to_nodes(f_rdf)\n",
    "    for n in wallNodes:\n",
    "        n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(o3d.geometry.OrientedBoundingBox.create_from_points(o3d.utility.Vector3dVector(n.orientedBounds)))\n",
    "        n.pcd = None\n",
    "    print(f'{len(wallNodes)} wallNodes detected!')\n",
    "    \n",
    "    wallNodes = t8.match_graph_with_las(f_pcd,class_dict, nodes = wallNodes, getResources=True, getNormals=False)\n",
    "    \n",
    "    pcd_count = 0\n",
    "    for n in wallNodes:\n",
    "        if not n.pcd == None:\n",
    "            pcd_count += 1\n",
    "    print(f'Matched {pcd_count} pointclouds to nodes')\n",
    "    \n",
    "    pointcloud = gmu.join_geometries([n.pcd for n in wallNodes])\n",
    "    # print(pointcloud)\n",
    "    # o3d.io.write_point_cloud(os.path.join(output_folder, \"pointcloud.pcd\"), pointcloud)\n",
    "    # path = os.path.join(output_folder, \"pointcloud.pcd\")\n",
    "    # print(f\"Saved Pointcloud to {path}\")\n",
    "    for n in wallNodes: \n",
    "        n.derivedFrom = next((p for p in wallNodes if n.object_id == p.object_id), None)\n",
    "        n.startpoint = ut.literal_to_array(n.start_pt) #np.asarray(n.start_pt[1:-1].split(), dtype=float)\n",
    "        n.endpoint = ut.literal_to_array(n.end_pt) #np.asarray(n.end_pt[1:-1].split(), dtype=float)\n",
    "        n.normal = ut.literal_to_array(n.normal) #np.asarray(n.normal[1:-1].split(), dtype=float)\n",
    "        n.height = float(n.height)\n",
    "        n.name = n.subject.split('///')[-1]\n",
    "        if n.width == 0.127 or n.width == 0.2:\n",
    "            n.singleFaced = True\n",
    "        else:\n",
    "            n.singleFaced = False\n",
    "    \n",
    "    #Create a messh from this point cloud \n",
    "    octree=pt.pcd_to_octree(gmu.join_geometries([n.pcd for n in wallNodes]),12) #if octree is None else octree\n",
    "\n",
    "    # Calculate the size of each octree node based on octree depth and overall size\n",
    "    def calculate_node_size(octree_depth, octree_size):\n",
    "        num_voxels_per_dim = 2 ** octree_depth\n",
    "        voxel_size = octree_size / num_voxels_per_dim\n",
    "        return voxel_size\n",
    "\n",
    "    voxel_size = calculate_node_size(octree.max_depth, octree.size)\n",
    "    # print(\"Voxelsize = \", voxel_size)\n",
    "    \n",
    "    voxelmesh=gmu.octree_to_voxelmesh(octree) #if mesh is None else mesh\n",
    "    # o3d.io.write_triangle_mesh(os.path.join(output_folder, \"mesh.obj\"), voxelmesh)\n",
    "    # path = os.path.join(output_folder, \"mesh.obj\")\n",
    "    # print(f\"Saved Mesh to {path}\")\n",
    "    \n",
    "    #Create a identity array containing the color so this can be retrieved afterwards\n",
    "    original_colors=np.asarray(voxelmesh.vertex_colors)\n",
    "\n",
    "    indices=np.asarray(voxelmesh.triangles)[:,0]\n",
    "    triangle_colors=original_colors[indices]\n",
    "\n",
    "    #append black color at the end of the array for the invalid hits\n",
    "    triangle_colors=np.vstack((triangle_colors,np.array([0,0,0])))\n",
    "    \n",
    "    cpu_mesh=o3d.t.geometry.TriangleMesh.from_legacy(voxelmesh)\n",
    "    # o3d.io.write_triangle_mesh(os.path.join(output_folder, \"mesh.obj\"), cpu_mesh)\n",
    "    # path = os.path.join(output_folder, \"mesh.obj\")\n",
    "    # print(f\"Saved Mesh to {path}\")\n",
    "    \n",
    "    # Create raycasting scene\n",
    "    scene = o3d.t.geometry.RaycastingScene()\n",
    "    scene.add_triangles(cpu_mesh) \n",
    "    \n",
    "    wall = 0\n",
    "    for n in wallNodes:\n",
    "        length = np.sqrt(np.sum((n.endpoint - n.startpoint)**2))\n",
    "        surface = length * n.height\n",
    "        image_size = (int(length / image_resolution), int(n.height / image_resolution))\n",
    "        n.orthos = []\n",
    "        \n",
    "        if not surface < 3 and n.height > 1.5 and length > 0.8:  \n",
    "            #Create an ortho of the dominant side of the wall      \n",
    "            ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = n.normal, scene=scene, triangle_colors = triangle_colors, show = False)\n",
    "            ortho = t8.fill_black_pixels(ortho, region = 12)\n",
    "            n.orthos.append(ortho)\n",
    "            \n",
    "            # if np.max(ortho) <= 1.0:\n",
    "            #     ortho = ortho * 255.0\n",
    "            # ortho_uint8 = ortho.astype(np.uint8)\n",
    "            # Image.fromarray(ortho_uint8).save(os.path.join(output_folder,(\"Wall_\" + str(n.object_id) + \"-Face_\" + str(0) +'.png')))\n",
    "            # plt.imshow(n.orthos[0])\n",
    "            \n",
    "            #Also create an ortho of the other side of the wall\n",
    "            if not n.singleFaced: #Single faced wall only needs one side\n",
    "                ortho = t8.create_wall_ortho(startpoint = n.startpoint, endpoint= n.endpoint, height= n.height, resolution = image_resolution, direction = -n.normal, scene=scene, triangle_colors = triangle_colors, dominant = False)\n",
    "                ortho = t8.fill_black_pixels(ortho, region = 12)\n",
    "                n.orthos.append(ortho)\n",
    "                # if np.max(ortho) <= 1.0:\n",
    "                #     ortho = ortho * 255.0\n",
    "                # ortho_uint8 = ortho.astype(np.uint8)\n",
    "                # Image.fromarray(ortho_uint8).save(os.path.join(output_folder,(\"Wall_\" + str(n.object_id) + \"-Face_\" + str(1) +'.png')))\n",
    "        # plt.show()\n",
    "        wall +=1\n",
    "    for n in wallNodes:\n",
    "        n.boxes = []\n",
    "        n.logits = []\n",
    "        n.phrases = []\n",
    "            \n",
    "        if len(n.orthos) > 0:\n",
    "            for ortho in n.orthos:\n",
    "                \n",
    "                boxes = None\n",
    "                image = load_image(Image.fromarray((ortho * 255).astype(np.uint8)))\n",
    "\n",
    "                boxes, logits, phrases = predict(\n",
    "                    model=groundingdino_model, \n",
    "                    image=image, \n",
    "                    caption=TEXT_PROMPT, \n",
    "                    box_threshold=BOX_TRESHOLD, \n",
    "                    text_threshold=TEXT_TRESHOLD\n",
    "                )\n",
    "                n.boxes.append(boxes)\n",
    "                n.logits.append(logits)\n",
    "                n.phrases.append(phrases)\n",
    "    wall = 0\n",
    "    door_count = 0\n",
    "    doorNodes = []\n",
    "    \n",
    "\n",
    "    for n in wallNodes:\n",
    "        potential_door_boxes_wall = []\n",
    "        potential_door_info_wall = []\n",
    "        # print(f'Processing {n.name}')\n",
    "        \n",
    "        if (len(n.orthos) == 1 and len(n.boxes[0]) > 0) or len(n.orthos) == 2 and (len(n.boxes[0]) > 0 or len(n.boxes[1]) > 0) :\n",
    "            for j, boxes in enumerate(n.boxes):\n",
    "                potential_door_boxes_face = []\n",
    "                potential_door_info_face = []\n",
    "                if len(boxes) > 0: \n",
    "                    for i, box in enumerate(boxes):\n",
    "                        probability = float(n.logits[j][i])\n",
    "                        opening_width = round(int(np.asarray(box)[2]*n.orthos[j].shape[1])* image_resolution, 2)    \n",
    "                        opening_height = round(int(np.asarray(box)[3]*n.orthos[j].shape[0]) * image_resolution, 2)\n",
    "                        \n",
    "                        detection_center_u = int(np.asarray(box)[0]*n.orthos[j].shape[1]) * image_resolution\n",
    "                        detection_center_v = int(np.asarray(box)[1]*n.orthos[j].shape[0]) * image_resolution\n",
    "                        \n",
    "                        reference_level = round((n.orthos[j].shape[0]*image_resolution) - (detection_center_v + opening_height/2), 2)\n",
    "                        # print((str(j) + \"-\" +str(image)))\n",
    "                        score = t8.is_door(probability, opening_width, opening_height, reference_level, prob_weight=0.15, width_weight=0.15, height_weight=0.3, ref_level_weight=0.3, print_overview = False)\n",
    "                        if score >= 0:\n",
    "                            # annotated_frame = annotate(image_source= n.orthos[j], boxes=box.unsqueeze(0), logits=torch.from_numpy(np.array([score])), phrases=[n.phrases[j][i]])\n",
    "                            # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                            # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(n.object_id) + \"-Face_\" + str(j) +\"-\"+ str(score) +'-DOOR.png')))\n",
    "                            # image += 1\n",
    "                            \n",
    "                            box1 = copy.deepcopy(box)\n",
    "                            box = box.unsqueeze(0)\n",
    "\n",
    "                            if j == 1:\n",
    "                                box1[0] = 1-box1[0]\n",
    "\n",
    "                            potential_door_boxes_face.append(np.asarray(box1))\n",
    "                            potential_door_info_face.append([opening_width, opening_height, image, reference_level, score])\n",
    "                                \n",
    "                potential_door_boxes_wall.append(potential_door_boxes_face)\n",
    "                potential_door_info_wall.append(potential_door_info_face)\n",
    "            #merge largely overlapping bounding boxes\n",
    "            \n",
    "            for i, face_boxes in enumerate(potential_door_boxes_wall):\n",
    "                if len(face_boxes) > 2:\n",
    "                    face_boxes, potential_door_info_wall[i] = t8.find_and_merge_high_iou_boxes(face_boxes, threshold=0.8, info = potential_door_info_wall[i])\n",
    "        \n",
    "            #For Double faced walls look if the detection is found on both sides.\n",
    "            if len(potential_door_boxes_wall) == 2 and not len(potential_door_boxes_wall[0]) == 0 and not len(potential_door_boxes_wall[1]) == 0:\n",
    "                # print(\"Double Faced\")\n",
    "                matches, unmatched_boxes0, unmatched_boxes1 = t8.find_best_matches(potential_door_boxes_wall[0], potential_door_boxes_wall[1], potential_door_info_wall[0], potential_door_info_wall[1], iou_weight=0.33, param_weight=0.33, doorness_weight=0.33)\n",
    "\n",
    "                for id0, id1, bestscore in matches:\n",
    "                    if not id0 == None and not id1 == None:\n",
    "                        # compare the parameters of the different matches\n",
    "                        info0 = potential_door_info_wall[0][id0]\n",
    "                        info1 = potential_door_info_wall[1][id1]\n",
    "            \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(np.asarray([potential_door_boxes_wall[0][id0]])), logits=torch.from_numpy(np.array([info0[-1]])), phrases=[n.phrases[0][id0]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(wall) + \"-Face_0-\" +str(image) +\"-\"+  str(info0[-1]) +'-DOOR.png')))\n",
    "                        # image += 1\n",
    "                        \n",
    "                        # annotated_frame = annotate(image_source= n.orthos[1], boxes=torch.from_numpy(np.asarray([potential_door_boxes_wall[1][id1]])), logits=torch.from_numpy(np.array([info1[-1]])), phrases=[n.phrases[1][id1]])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Wall_\" + str(wall) + \"-Face_1-\" +str(image) +\"-\"+  str(info1[-1]) +'-DOOR.png')))\n",
    "                        # image += 1\n",
    "                        \n",
    "                        detectionbox = t8.combine_boxes(potential_door_boxes_wall[0][id0], potential_door_boxes_wall[1][id1])\n",
    "                        probability = (potential_door_info_wall[0][id0][4]+ potential_door_info_wall[1][id1][4])/2\n",
    "                        \n",
    "                        opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                        # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %((str(count)), bestscore, reference_level, opening_width, opening_height))\n",
    "                        score = t8.is_door(probability, opening_width, opening_height, reference_level, prob_weight=0.15, width_weight=0.15, height_weight=0.3, ref_level_weight=0.3)\n",
    "                        if score > t_score:\n",
    "                            boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                            \n",
    "                            doornode = BIMNode(\n",
    "                                name= \"Doors_\" + str(door_count),\n",
    "                                axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                                startpoint= boundaryPoints[0],\n",
    "                                endpoint= boundaryPoints[1],\n",
    "                                doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                                height = opening_height,\n",
    "                                doornessScore = score,\n",
    "                                singleFaced = False,\n",
    "                                depth = n.width,\n",
    "                                object_id = class_id *4000 + door_count,\n",
    "                                blackness = percentage_black_pixles,\n",
    "                                reference_level = reference_level,\n",
    "                                host = n)\n",
    "                            \n",
    "                            doorNodes.append(doornode)\n",
    "                            \n",
    "                            # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                            # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                            # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                            door_count += 1 \n",
    "                        \n",
    "                #If the detection is not found on both sides of the wall but it is a double faced wall we add a penalty\n",
    "                for id0 in unmatched_boxes0: #Two faced walls with a detection on only one side\n",
    "                    score = potential_door_info_wall[0][id0][4]-0.2\n",
    "                    if score > t_score:\n",
    "                        detectionbox = np.array([potential_door_boxes_wall[0][id0]])\n",
    "                        \n",
    "                        opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                        \n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "            \n",
    "                        doornode = BIMNode(\n",
    "                            name= \"Doors_\" + str(door_count),\n",
    "                            axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                            startpoint= boundaryPoints[0],\n",
    "                            endpoint= boundaryPoints[1],\n",
    "                            doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                            height = opening_height,\n",
    "                            doornessScore = score,\n",
    "                            singleFaced = True,\n",
    "                            depth = n.width,\n",
    "                            object_id = class_id *4000 + door_count,\n",
    "                            blackness = percentage_black_pixles,\n",
    "                            reference_level = reference_level,\n",
    "                            host = n)\n",
    "                        \n",
    "                        doorNodes.append(doornode)\n",
    "                        # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                        door_count += 1 \n",
    "                    \n",
    "                for id1 in unmatched_boxes1: #Two faced walls with a detection on only one side\n",
    "                    score = potential_door_info_wall[1][id1][4]-0.2\n",
    "                    if score > t_score:\n",
    "                        detectionbox = np.array([potential_door_boxes_wall[1][id1]])\n",
    "\n",
    "                        opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[1], image_resolution = image_resolution)\n",
    "                        \n",
    "                        boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                            \n",
    "                        doornode = BIMNode(\n",
    "                            name= \"Doors_\" + str(door_count),\n",
    "                            axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                            startpoint= boundaryPoints[0],\n",
    "                            endpoint= boundaryPoints[1],\n",
    "                            doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                            height = opening_height,\n",
    "                            doornessScore = score,\n",
    "                            singleFaced = True,\n",
    "                            depth = n.width,\n",
    "                            object_id = class_id *4000 + door_count,\n",
    "                            blackness = percentage_black_pixles,\n",
    "                            reference_level = reference_level,\n",
    "                            host = n)\n",
    "                        \n",
    "                        doorNodes.append(doornode)\n",
    "                        # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                        # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                        # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                        door_count += 1 \n",
    "\n",
    "            elif len(potential_door_boxes_wall) > 0: #For single faced walls\n",
    "                if len(potential_door_boxes_wall) == 1:\n",
    "                    for i, box in enumerate(potential_door_boxes_wall[0]):\n",
    "                        #This are single faced walls so the penalty is less.\n",
    "                        score = potential_door_info_wall[0][i][4]-0.1\n",
    "                        # image_resource = t8.extract_box_with_margin(n.orthos[0], np.array([box])[0])\n",
    "                        # image_resource = image_resource[...,::-1] # BGR to RGB\n",
    "                        # Image.fromarray(image_resource).save(os.path.join(output_folder,(\"BlackDoor_\" + str(door_count) + '.png')))\n",
    "                        # bl_px = t8.calculate_percentage_black_pixels(image_resource)\n",
    "                        \n",
    "                        if score > t_score: #and bl_px > 0.6:\n",
    "                            detectionbox = np.array([box])\n",
    "                            \n",
    "                            opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[0], image_resolution = image_resolution)\n",
    "                            \n",
    "                            boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                                \n",
    "                            doornode = BIMNode(\n",
    "                                name= \"Doors_\" + str(door_count),\n",
    "                                axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                                startpoint= boundaryPoints[0],\n",
    "                                endpoint= boundaryPoints[1],\n",
    "                                doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                                height = opening_height,\n",
    "                                doornessScore = score,\n",
    "                                singleFaced = True,\n",
    "                                depth = n.width,\n",
    "                                object_id = class_id *4000 + door_count,\n",
    "                                blackness = percentage_black_pixles,\n",
    "                                reference_level = reference_level,\n",
    "                                host = n)\n",
    "                            \n",
    "                            doorNodes.append(doornode)\n",
    "                            # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                            # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                            # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                            # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                            door_count += 1 \n",
    "            \n",
    "                if len(potential_door_boxes_wall) == 2:    \n",
    "                        for i, box in enumerate(potential_door_boxes_wall[1]):\n",
    "                            #This are single faced walls so the penalty is less.\n",
    "                            score = potential_door_info_wall[1][i][4]-0.1\n",
    "                            \n",
    "                            if score > t_score:\n",
    "                                detectionbox = np.array([box])\n",
    "                                \n",
    "                                opening_width, opening_height, detection_center_u, detection_center_v, reference_level, percentage_black_pixles = t8.compute_door_parameters(detectionbox, ortho = n.orthos[1], image_resolution = image_resolution)\n",
    "                                    \n",
    "                                boundaryPoints = t8.line_with_width_coordinates(n.startpoint, n.endpoint, detectionbox[0][0], opening_width, reference_level)\n",
    "                                \n",
    "                                \n",
    "                                doornode = BIMNode(\n",
    "                                    name= \"Doors_\" + str(door_count),\n",
    "                                    axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1]),\n",
    "                                    startpoint= boundaryPoints[0],\n",
    "                                    endpoint= boundaryPoints[1],\n",
    "                                    doorWidth = np.round(np.linalg.norm(boundaryPoints[0] - boundaryPoints[1]),2),\n",
    "                                    height = opening_height,\n",
    "                                    doornessScore = score,\n",
    "                                    singleFaced = True,\n",
    "                                    depth = n.width,\n",
    "                                    object_id = class_id *4000 + door_count,\n",
    "                                    blackness = percentage_black_pixles,\n",
    "                                    reference_level = reference_level,\n",
    "                                    host = n)\n",
    "                                \n",
    "                                doorNodes.append(doornode)\n",
    "                                # print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, reference_level, opening_width, opening_height))\n",
    "                                # annotated_frame = annotate(image_source= n.orthos[0], boxes=torch.from_numpy(detectionbox), logits=torch.from_numpy(np.array([doornode.doornessScore])), phrases=[\"Door\"])\n",
    "                                # annotated_frame = annotated_frame[...,::-1] # BGR to RGB\n",
    "                                # Image.fromarray(annotated_frame).save(os.path.join(output_folder,(\"Door_\" + str(door_count) + '.png')))\n",
    "\n",
    "                                door_count += 1 \n",
    "            \n",
    "        wall += 1  \n",
    "    if len(doorNodes) >= 1:\n",
    "        for n in doorNodes:\n",
    "            pointList=[]\n",
    "            points=np.asarray(n.axis.points)\n",
    "            # pointList.extend(points+n.sign*n.normal*n.width/2)\n",
    "            pointList.extend(points+n.host.normal*n.host.width/2)\n",
    "\n",
    "            # pointList.extend(points-n.sign*n.normal*n.width/2)\n",
    "            pointList.extend(points-n.host.normal*n.host.width/2)\n",
    "\n",
    "            pointList.extend(np.array(pointList)+np.array([0,0,n.height]))\n",
    "            pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "            box=pcd.get_oriented_bounding_box()\n",
    "            n.resource = o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "            n.resource.paint_uniform_color(ut.literal_to_array(n.host.color))\n",
    "            n.doorBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "            n.doorBox.paint_uniform_color([0,0,1])\n",
    "            \n",
    "            n.center = t8.compute_center(n.startpoint, n.endpoint)\n",
    "            n.cartesianTransform = copy.deepcopy(n.host.cartesianTransform)\n",
    "            n.cartesianTransform[:3,3] = n.center\n",
    "            n.normal = n.host.normal\n",
    "            n.rotation = t8.get_angle_with_x_axis(n.startpoint, n.endpoint)\n",
    "\n",
    "    if len(doorNodes) >= 1:  \n",
    "        # Function to calculate the distance between two points\n",
    "        def calculate_distance(point1, point2):\n",
    "            return np.linalg.norm(np.array(point1) - np.array(point2))\n",
    "\n",
    "\n",
    "        avg_doorWidth = np.mean(np.array([e.doorWidth for e in doorNodes]))\n",
    "        #remove single faced doors that are in a 90 degree angle with double faced doors.\n",
    "        dbscan = DBSCAN(eps=1.5*avg_doorWidth, min_samples=1, metric=t8.calculate_distance) #eps=1.5*avg_doorWidth\n",
    "        labels = dbscan.fit_predict([n.center for n in doorNodes])\n",
    "\n",
    "        cluster_ids = [-1] * len(doorNodes)\n",
    "        unique_labels = set(labels)\n",
    "\n",
    "        current_cluster_id = 0\n",
    "        for label in unique_labels:\n",
    "            cluster_lines = [doorNodes[i] for i in range(len(doorNodes)) if labels[i] == label]\n",
    "            for line in cluster_lines:\n",
    "                line_index = None\n",
    "                for i, l in enumerate(doorNodes):\n",
    "                    if np.array_equal(l, line):\n",
    "                        line_index = i\n",
    "                        break\n",
    "                cluster_ids[line_index] = current_cluster_id\n",
    "            current_cluster_id += 1\n",
    "\n",
    "        all_clusters_indices = []\n",
    "\n",
    "        # Get unique cluster labels\n",
    "        unique_labels = np.unique(cluster_ids)\n",
    "\n",
    "        # Iterate through each unique cluster label\n",
    "        for cluster_label in unique_labels:\n",
    "            if not cluster_label == -1:\n",
    "                cluster_indices = [i for i, label in enumerate(cluster_ids) if label == cluster_label]\n",
    "                all_clusters_indices.append(cluster_indices)\n",
    "            else: \n",
    "                for i, label in enumerate(cluster_ids):\n",
    "                    if label == cluster_label:\n",
    "                        all_clusters_indices.append([i])\n",
    "        FP = []\n",
    "        for cluster_indices in all_clusters_indices:\n",
    "            if len(cluster_indices) > 1:\n",
    "                doors_to_check = []\n",
    "                for i in cluster_indices:\n",
    "                    # doors_to_check.append((doorNodes[i].name, doorNodes[i].doornessScore))\n",
    "                    if doorNodes[i].blackness  < 0.8:\n",
    "                        # print(f\"door: {doorNodes[i].name} will be removed\")\n",
    "                        FP.append(doorNodes[i].subject)\n",
    "\n",
    "        doorNodes = [doornode for doornode in doorNodes if doornode.subject not in FP]\n",
    "\n",
    "        door_count = len(doorNodes)\n",
    "        # print(f'name: {n.name}, score: {n.doornessScore} ,doorWidth: {n.doorWidth}, height: {n.height}')\n",
    "    \n",
    "    for doornode in doorNodes:\n",
    "        print(\"%s : Door Score: %s => Referencelevel: %s; Width: %s; height: %s\" %(doornode.name, doornode.doornessScore, doornode.reference_level, doornode.doorWidth, doornode.height))    \n",
    "    \n",
    "    print(f\"Number of doors: {len(doorNodes)}\")\n",
    "    \n",
    "    t8.write_obj_with_submeshes(os.path.join(output_folder,f'{ut.get_filename(f_pcd)}_doors.obj') , [n.resource for n in doorNodes], [n.name for n in doorNodes])\n",
    "    \n",
    "    reform_name='_'.join(ut.get_filename(f_pcd).split('_')[:4])+'_doors'\n",
    "\n",
    "    json_data=t8.doors_to_json(doorNodes)\n",
    "    with open(os.path.join(output_folder,reform_name+'.json'), 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "    print(\"JSON data written to file:\", os.path.join(output_folder,reform_name+'.json'))\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CVPR2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
