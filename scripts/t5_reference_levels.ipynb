{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T5. REFERENCE LEVELS\n",
    "\n",
    "In this notebook, we extract the reference levels from the t1_semantic segmentation/ t2_instance segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "#IMPORT PACKAGES\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "from rdflib import Graph, URIRef, Literal, Namespace\n",
    "\n",
    "# from tabulate import tabulate\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "import geomapi.tools.progresstools as pt\n",
    "\n",
    "#import utils\n",
    "import context \n",
    "import utils as utl\n",
    "import utils.t5_utils as t5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\n"
     ]
    }
   ],
   "source": [
    "#paths\n",
    "path=Path(os.getcwd()).parents[2] # On Onedrive this is 2, on GPU server this is 0\n",
    "\n",
    "print(path)\n",
    "input_folder=path/'data'/'t4'/'test' \n",
    "# input_folder=path/'data'/'t4'/'train' \n",
    "\n",
    "class_file=path/'data'/'_classes.json'\n",
    "output_folder=path/'data'/'t5'/ 'test'\n",
    "# output_folder=path/'data'/'t5'/ 'train'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#parameters\n",
    "threshold_horizontal_clustering=100#m\n",
    "threshold_vertical_clustering=0.5#m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'unassigned', 'id': 255, 'temp_id': 0, 'color': '#9da2ab'}, {'name': 'floors', 'id': 0, 'temp_id': 1, 'color': '#03c2fc'}, {'name': 'ceilings', 'id': 1, 'temp_id': 2, 'color': '#e81416'}, {'name': 'walls', 'id': 2, 'temp_id': 3, 'color': '#ffa500'}, {'name': 'columns', 'id': 3, 'temp_id': 4, 'color': '#faeb36'}, {'name': 'doors', 'id': 4, 'temp_id': 5, 'color': '#79c314'}, {'name': 'beams', 'id': 5, 'temp_id': 6, 'color': '#79c314'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESS LEVELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\11_MedOffice_05_F2_small_pred.ttl\n",
      "processing 11_MedOffice_05_F2_small_pred ...\n",
      "156 Nodes found\n",
      "3 floor nodes and 5 ceiling nodes found\n",
      "2 levels created at heights [0.0161679523, 2.74903721]\n",
      "JSON data written to file: c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t5\\test\\11_MedOffice_05_F2_small_pred_levels.json\n",
      " Saving joint references : True\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\11_MedOffice_05_F4_small_pred.ttl\n",
      "processing 11_MedOffice_05_F4_small_pred ...\n",
      "152 Nodes found\n",
      "8 floor nodes and 9 ceiling nodes found\n",
      "4 levels created at heights [-4.21099628, 0.0604897509, 2.78621407, 4.15988102]\n",
      "JSON data written to file: c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t5\\test\\11_MedOffice_05_F4_small_pred_levels.json\n",
      " Saving joint references : True\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\25_Parking_01_F1_small_pred.ttl\n",
      "processing 25_Parking_01_F1_small_pred ...\n",
      "111 Nodes found\n",
      "18 floor nodes and 33 ceiling nodes found\n",
      "3 levels created at heights [-0.0152047619, 0.72754617, 3.90959681]\n",
      "JSON data written to file: c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t5\\test\\25_Parking_01_F1_small_pred_levels.json\n",
      " Saving joint references : True\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\25_Parking_01_F2_small_pred.ttl\n",
      "processing 25_Parking_01_F2_small_pred ...\n",
      "110 Nodes found\n",
      "21 floor nodes and 30 ceiling nodes found\n",
      "7 levels created at heights [-2.82363624, -2.19015511, -1.27174933, 0.00143420707, 0.5913446, 2.94969298, 4.53497272]\n",
      "JSON data written to file: c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t5\\test\\25_Parking_01_F2_small_pred_levels.json\n",
      " Saving joint references : True\n",
      "c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t4\\test\\34_Parking_04_F1_small_pred.ttl\n",
      "processing 34_Parking_04_F1_small_pred ...\n",
      "19 Nodes found\n",
      "1 floor nodes and 3 ceiling nodes found\n",
      "3 levels created at heights [-0.01429057, 2.43856236, 4.19882012]\n",
      "JSON data written to file: c:\\Users\\u0094523\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\t5\\test\\34_Parking_04_F1_small_pred_levels.json\n",
      " Saving joint references : True\n"
     ]
    }
   ],
   "source": [
    "files=utl.get_list_of_files(input_folder,'.laz')\n",
    "\n",
    "for f in files[2:]: \n",
    "    \n",
    "    #import graph\n",
    "    f_g=Path(f).with_suffix('.ttl')\n",
    "    print(f_g)\n",
    "    pcdNodes=tl.graph_path_to_nodes(graphPath=str(f_g))\n",
    "    \n",
    "    #import pcd and check if las/pcd variable is already defined    \n",
    "    print(f'processing {ut.get_filename(f)} ...')      \n",
    "    las = laspy.read(f) #if 'las' not in globals() else las\n",
    "    pcd=gmu.las_to_pcd(las) #if 'pcd' not in globals() else pcd # this is the slowest step\n",
    "        \n",
    "    #match pcd to nodes\n",
    "    for c in class_dict['classes']:\n",
    "        if c['id'] in [0,1]: \n",
    "            idx=np.where((las['classes']==c['id']))[0]\n",
    "            class_pcd=pcd.select_by_index(idx)\n",
    "            object_labels=las['objects'][idx]\n",
    "            \n",
    "            for j in np.unique(object_labels):\n",
    "                indices=np.where(object_labels==j)[0]\n",
    "                object_pcd=class_pcd.select_by_index(indices)\n",
    "                pcdNode=next((x for x in pcdNodes if int(x.object_id) == j), None)\n",
    "                pcdNode.resource=object_pcd if pcdNode is not None else None\n",
    "            \n",
    "    print(f'{len(pcdNodes)} Nodes found')     \n",
    "    \n",
    "    #retrieve levelNodes -> CVPR they take highest element in the group instead of the average -> this even should be 20cm higher but this is arbitrary in the CVPR dataset -> 4% error\n",
    "    floorNodes=[n for n in pcdNodes if n.class_id ==0]\n",
    "    ceilingNodes=[n for n in pcdNodes if n.class_id ==1]    \n",
    "    print(f'{len(floorNodes)} floor nodes and {len(ceilingNodes)} ceiling nodes found')\n",
    "    levelNodes=t5.create_level_nodes((floorNodes+ceilingNodes),threshold_horizontal_clustering=threshold_horizontal_clustering,threshold_vertical_clustering=threshold_vertical_clustering)\n",
    "    print(f'{len(levelNodes)} levels created at heights {[n.height for n in levelNodes]}')      \n",
    "    \n",
    "    #write this information to the 3D detection json\n",
    "    json_data=t5.levels_to_json(levelNodes,f)\n",
    "    with open(os.path.join(output_folder,f'{ut.get_filename(f)}_levels.json'), 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "    print(\"JSON data written to file:\", os.path.join(output_folder,f'{ut.get_filename(f)}_levels.json') )\n",
    "    \n",
    "    #write geometries to file\n",
    "    joined_references=gmu.join_geometries([n.plane for n in levelNodes])\n",
    "    success=o3d.io.write_triangle_mesh(filename=os.path.join(output_folder,f'{ut.get_filename(f)}_levels.obj'), mesh=joined_references) \n",
    "    print(f' Saving joint references : {success}')\n",
    "    \n",
    "    #write graph to file\n",
    "    graphPath=os.path.join(output_folder,f'{ut.get_filename(f)}_levels.ttl')\n",
    "    graph=tl.nodes_to_graph(levelNodes,graphPath=graphPath,save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VISUALIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([p.resource.paint_uniform_color(ut.random_color()) for p in objectNodes])\n",
    "# o3d.visualization.draw_geometries([joined_pcd,gmu.sample_geometry(class_pcd)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([n.plane.paint_uniform_color(ut.random_color()) for n in levelNodes if n.resource is not None])\n",
    "# joined_pcd2=gmu.join_geometries([n.resource.paint_uniform_color(ut.random_color()) for n in (floorNodes+ceilingNodes) if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd2]+[n.box for n in levelNodes if n.resource is not None])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
