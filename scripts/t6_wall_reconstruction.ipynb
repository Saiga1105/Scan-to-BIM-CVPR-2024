{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T6. WALL RECONSTRUCTION\n",
    "\n",
    "In this script, we reconstruct parametric wall geometries from the instance segmentation and reference heights.\n",
    "Specifically, we need:\n",
    " - T2: instances of walls, ceilings and other objects\n",
    " - T5: reference levels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT PACKAGES\n",
    "from rdflib import Graph, URIRef\n",
    "import os.path\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import open3d as o3d\n",
    "import uuid    \n",
    "import pye57 \n",
    "import ifcopenshell\n",
    "import ifcopenshell.geom as geom\n",
    "import ifcopenshell.util\n",
    "from ifcopenshell.util.selector import Selector\n",
    "import multiprocessing\n",
    "import random as rd\n",
    "import pandas as pd\n",
    "# from tabulate import tabulate\n",
    "import cv2\n",
    "import laspy\n",
    "import json\n",
    "from scipy.spatial.transform import Rotation   \n",
    "import copy\n",
    "import geomapi\n",
    "from geomapi.nodes import *\n",
    "import geomapi.utils as ut\n",
    "from geomapi.utils import geometryutils as gmu\n",
    "import geomapi.tools as tl\n",
    "\n",
    "#import utils\n",
    "from context import utils\n",
    "import utils as utl\n",
    "import utils.t1_utils as t1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INPUTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name='beton_labels'\n",
    "\n",
    "path=Path(os.getcwd()).parents[2]/'data'\n",
    "pcd_input_path=os.path.join(path,f'{name}.laz')\n",
    "class_file=path/'_classes.json'\n",
    "\n",
    "name=name.split('_')[0]\n",
    "json_output_path=os.path.join(path,f'{name}_walls.json') \n",
    "geometry_output_path= os.path.join(path,f'{name}_walls.obj') # these are the bounding surfaces of the reference levels (optional)\n",
    "\n",
    "#bimfolder\n",
    "# bimFolder=os.mkdir(path/name/'BIM')\n",
    "graphPath=str(path/f'{name}Graph.ttl')\n",
    "\n",
    "#thresholds\n",
    "t_level=0.5\n",
    "t_distance=0.7\n",
    "t_thickness=0.12\n",
    "t_topology=5\n",
    "t_intersection=0.5\n",
    "t_orthogonal=0.5\n",
    "t_topo_floors_ceilings=False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': [{'name': 'Unassigned', 'id': 255, 'temp_id': -1, 'color': '#9da2ab'}, {'name': 'Floors', 'id': 0, 'temp_id': 0, 'color': '#03c2fc'}, {'name': 'Ceilings', 'id': 1, 'temp_id': 1, 'color': '#e81416'}, {'name': 'Walls', 'id': 2, 'temp_id': 2, 'color': '#ffa500'}, {'name': 'Columns', 'id': 3, 'temp_id': 3, 'color': '#faeb36'}, {'name': 'Doors', 'id': 4, 'temp_id': 4, 'color': '#79c314'}, {'name': 'Windows', 'id': 5, 'temp_id': 5, 'color': '#4b369d'}], 'default': 255, 'type': 'semantic_segmentation', 'format': 'kitti', 'created_with': {'name': 'Saiga', 'version': '1.0.1'}}\n"
     ]
    }
   ],
   "source": [
    "# Read the JSON file\n",
    "with open(class_file, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Create a dictionary\n",
    "class_dict = {\n",
    "    'classes': json_data['classes'],\n",
    "    'default': json_data['default'],\n",
    "    'type': json_data['type'],\n",
    "    'format': json_data['format'],\n",
    "    'created_with': json_data['created_with']\n",
    "}\n",
    "print(class_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29 wallNodes detected!\n",
      "33 ceilingsNodes detected!\n",
      "9 floorsNodes detected!\n"
     ]
    }
   ],
   "source": [
    "graph=Graph().parse(graphPath)\n",
    "nodes=tl.graph_to_nodes(graph)\n",
    "wallNodes=[n for n in nodes if 'Walls' in n.subject and type(n)==PointCloudNode]\n",
    "ceilingsNodes=[n for n in nodes if 'Ceilings' in n.subject and type(n)==PointCloudNode]\n",
    "floorsNodes=[n for n in nodes if 'Floors' in n.subject and type(n)==PointCloudNode]\n",
    "print(f'{len(wallNodes)} wallNodes detected!')\n",
    "print(f'{len(ceilingsNodes)} ceilingsNodes detected!')\n",
    "print(f'{len(floorsNodes)} floorsNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import PCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laz=laspy.read(pcd_input_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "match point clouds with graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in wallNodes:#+ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in wallNodes if n.resource is not None])\n",
    "# o3d.visualization.draw_geometries([joined_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Reference Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 levelNodes detected!\n"
     ]
    }
   ],
   "source": [
    "levelNodes=[n for n in nodes if 'level' in n.subject]\n",
    "referenceNodes=[]\n",
    "for l in levelNodes:\n",
    "    new_graph=ut.get_subject_graph(graph,levelNodes[0].subject)\n",
    "    n=SessionNode(graph=new_graph)\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.resource=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(n.orientedBoundingBox)\n",
    "    referenceNodes.append(n) # something is wrong in the tl.graph_to_nodes function\n",
    "levelNodes=referenceNodes\n",
    "print(f'{len(levelNodes)} levelNodes detected!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import ceilings and floors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in ceilingsNodes+floorsNodes: # this is quite slow because you iterate through 2 scalar fields every time\n",
    "    idx=np.where((laz['classes']==n.class_id) & (laz['objects']==n.object_id))\n",
    "    pcd=o3d.geometry.PointCloud()\n",
    "    pcd.points=o3d.utility.Vector3dVector(laz.xyz[idx])\n",
    "    n.resource=pcd\n",
    "    n.get_oriented_bounding_box()\n",
    "    n.orientedBoundingBox.color=[1,1,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute base constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, base_constraint: level_00, base_offset: 0.07059945767538167\n",
      "name: 2_Walls_44, base_constraint: level_00, base_offset: 0.0505994576753821\n",
      "name: 2_Walls_45, base_constraint: level_00, base_offset: 2.690599457675381\n",
      "name: 2_Walls_46, base_constraint: level_00, base_offset: 0.010599457675381174\n",
      "name: 2_Walls_47, base_constraint: level_00, base_offset: 0.010599457675381174\n",
      "name: 2_Walls_48, base_constraint: level_00, base_offset: 0.28059945767538075\n",
      "name: 2_Walls_49, base_constraint: level_00, base_offset: 0.33059945767538146\n",
      "name: 2_Walls_50, base_constraint: level_00, base_offset: 0.010599457675381174\n",
      "name: 2_Walls_51, base_constraint: level_00, base_offset: -0.0094005423246184\n",
      "name: 2_Walls_52, base_constraint: level_00, base_offset: 0.37490945767538086\n",
      "name: 2_Walls_53, base_constraint: level_00, base_offset: 1.281599457675382\n",
      "name: 2_Walls_54, base_constraint: level_00, base_offset: 0.16701945767538184\n",
      "name: 2_Walls_55, base_constraint: level_00, base_offset: 0.1805994576753811\n",
      "name: 2_Walls_56, base_constraint: level_00, base_offset: -0.029400542324617973\n",
      "name: 2_Walls_57, base_constraint: level_00, base_offset: -0.029400542324617973\n",
      "name: 2_Walls_58, base_constraint: level_00, base_offset: -0.019400542324618186\n",
      "name: 2_Walls_59, base_constraint: level_00, base_offset: 0.0072794576753807405\n",
      "name: 2_Walls_60, base_constraint: level_00, base_offset: 0.11597945767538143\n",
      "name: 2_Walls_61, base_constraint: level_00, base_offset: 2.5305994576753807\n",
      "name: 2_Walls_62, base_constraint: level_00, base_offset: 0.02059945767538096\n",
      "name: 2_Walls_63, base_constraint: level_00, base_offset: 0.030599457675380748\n",
      "name: 2_Walls_64, base_constraint: level_00, base_offset: 0.030599457675380748\n",
      "name: 2_Walls_65, base_constraint: level_00, base_offset: 0.030599457675380748\n",
      "name: 2_Walls_66, base_constraint: level_00, base_offset: 0.040599457675380535\n",
      "name: 2_Walls_67, base_constraint: level_00, base_offset: -0.0094005423246184\n",
      "name: 2_Walls_68, base_constraint: level_00, base_offset: 0.0005994576753813874\n",
      "name: 2_Walls_69, base_constraint: level_00, base_offset: 0.0505994576753821\n",
      "name: 2_Walls_70, base_constraint: level_00, base_offset: 0.060599457675381885\n",
      "name: 2_Walls_71, base_constraint: level_00, base_offset: 0.030599457675380748\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    #compute minheight of the resource at 0.1% of the height (absolute minimum might be wrong)\n",
    "    z_values = np.sort(np.asarray(n.resource.points)[:,2])\n",
    "    minheight = np.percentile(z_values, 0.1)\n",
    "\n",
    "    #compute base constraint. select the intersecting level that is closest to the bottom of the wall. Else, just take first levelNode.\n",
    "    nearby_ref_levels= tl.select_nodes_with_intersecting_bounding_box(n,levelNodes)\n",
    "    n.base_constraint= next((n for n in nearby_ref_levels if np.absolute(n.height-minheight)<t_level),levelNodes[0])  if nearby_ref_levels else levelNodes[0] #this is a link!\n",
    "    \n",
    "    #compute base offset\n",
    "    n.base_offset=minheight-n.base_constraint.height\n",
    "    print(f'name: {n.name}, base_constraint: {n.base_constraint.name}, base_offset: {n.base_offset}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([n.resource,o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(n.orientedBoundingBox)]+[levelNodes[0].resource])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute top constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, top_constraint: level_00, top_offset: 3.350599457675381\n",
      "name: 2_Walls_44, top_constraint: level_00, top_offset: 3.230599457675382\n",
      "name: 2_Walls_45, top_constraint: level_00, top_offset: 3.4505994576753807\n",
      "name: 2_Walls_46, top_constraint: level_00, top_offset: 1.680599457675381\n",
      "name: 2_Walls_47, top_constraint: level_00, top_offset: 1.9691194576754079\n",
      "name: 2_Walls_48, top_constraint: level_00, top_offset: 3.2805994576753807\n",
      "name: 2_Walls_49, top_constraint: level_00, top_offset: 4.280599457675381\n",
      "name: 2_Walls_50, top_constraint: level_00, top_offset: 4.300599457675382\n",
      "name: 2_Walls_51, top_constraint: level_00, top_offset: 2.4505994576753807\n",
      "name: 2_Walls_52, top_constraint: level_00, top_offset: 4.300599457675382\n",
      "name: 2_Walls_53, top_constraint: level_00, top_offset: 2.940599457675381\n",
      "name: 2_Walls_54, top_constraint: level_00, top_offset: 2.7805994576753807\n",
      "name: 2_Walls_55, top_constraint: level_00, top_offset: 2.5705994576753817\n",
      "name: 2_Walls_56, top_constraint: level_00, top_offset: 2.5805994576753815\n",
      "name: 2_Walls_57, top_constraint: level_00, top_offset: 2.480599457675382\n",
      "name: 2_Walls_58, top_constraint: level_00, top_offset: 2.4605994576753805\n",
      "name: 2_Walls_59, top_constraint: level_00, top_offset: 4.300599457675382\n",
      "name: 2_Walls_60, top_constraint: level_00, top_offset: 2.690599457675381\n",
      "name: 2_Walls_61, top_constraint: level_00, top_offset: 2.6970394576753822\n",
      "name: 2_Walls_62, top_constraint: level_00, top_offset: 3.3872394576753884\n",
      "name: 2_Walls_63, top_constraint: level_00, top_offset: 2.6307994576753853\n",
      "name: 2_Walls_64, top_constraint: level_00, top_offset: 2.4412394576753833\n",
      "name: 2_Walls_65, top_constraint: level_00, top_offset: 2.440599457675381\n",
      "name: 2_Walls_66, top_constraint: level_00, top_offset: 4.2905994576753805\n",
      "name: 2_Walls_67, top_constraint: level_00, top_offset: 4.340599457675381\n",
      "name: 2_Walls_68, top_constraint: level_00, top_offset: 2.4605994576753805\n",
      "name: 2_Walls_69, top_constraint: level_00, top_offset: 4.300599457675382\n",
      "name: 2_Walls_70, top_constraint: level_00, top_offset: 4.2905994576753805\n",
      "name: 2_Walls_71, top_constraint: level_00, top_offset: 4.300599457675382\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    #compute maxheight of the resource at 0.1% of the height (absolute minimum might be wrong)\n",
    "    z_values = np.sort(np.asarray(n.resource.points)[:,2])\n",
    "    minheight = np.percentile(z_values, 0.1)\n",
    "    maxheight = np.percentile(z_values, 99.9)\n",
    "\n",
    "    #compute base constraint. select the intersecting level that is closest to the top of the wall. Else, just take last levelNode.\n",
    "    nearby_ref_levels= tl.select_nodes_with_intersecting_bounding_box(n,levelNodes)\n",
    "    n.top_constraint= next((n for n in nearby_ref_levels if np.absolute(n.height-maxheight)<t_level),levelNodes[-1]) if nearby_ref_levels else levelNodes[-1] #this is a link!\n",
    "    \n",
    "    #compute base offset\n",
    "    n.top_offset=maxheight-n.top_constraint.height\n",
    "\n",
    "    #compute wall height\n",
    "    n.height=maxheight-minheight\n",
    "    print(f'name: {n.name}, top_constraint: {n.top_constraint.name}, top_offset: {n.top_offset}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joined_pcd=gmu.join_geometries([n.resource.paint_uniform_color(ut.literal_to_array(n.color)) for n in wallNodes if n.resource is not None])\n",
    "# for n in wallNodes:\n",
    "#     n.orientedBoundingBox.color=[1,0,0]\n",
    "# o3d.visualization.draw_geometries([joined_pcd]+[n.orientedBoundingBox for n in wallNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall Orientation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, plane: [ 7.41299277e-01  6.71174629e-01  0.00000000e+00 -2.07577740e+05], inliers: 30451/31366\n",
      "name: 2_Walls_44, plane: [-7.34897220e-01 -6.78178498e-01 -0.00000000e+00 -2.08286890e+05], inliers: 7216/9829\n",
      "name: 2_Walls_45, plane: [-6.61686551e-01  7.49780573e-01  0.00000000e+00 -7.72712474e+04], inliers: 885/1271\n",
      "name: 2_Walls_46, plane: [-7.50009201e-01 -6.61427395e-01 -0.00000000e+00 -2.06590316e+05], inliers: 2592/3088\n",
      "name: 2_Walls_47, plane: [ 6.69026742e-01 -7.43238333e-01 -0.00000000e+00 -7.52487979e+04], inliers: 11612/16149\n",
      "name: 2_Walls_48, plane: [ 7.42678080e-01  6.69648616e-01  0.00000000e+00 -2.07438888e+05], inliers: 4552/7837\n",
      "name: 2_Walls_49, plane: [ 7.46443530e-01  6.65448764e-01  0.00000000e+00 -2.07019241e+05], inliers: 4858/9533\n",
      "name: 2_Walls_50, plane: [-6.64211724e-01  7.47544504e-01  0.00000000e+00 -7.65858551e+04], inliers: 23329/32940\n",
      "name: 2_Walls_51, plane: [ 7.76699792e-01 -6.29870966e-01  0.00000000e+00  4.20036720e+04], inliers: 3055/5216\n",
      "name: 2_Walls_52, plane: [-7.43318714e-01 -6.68937433e-01 -0.00000000e+00 -2.07369409e+05], inliers: 36721/73432\n",
      "name: 2_Walls_53, plane: [ 7.42733177e-01  6.69587505e-01  0.00000000e+00 -2.07438553e+05], inliers: 1072/1811\n",
      "name: 2_Walls_54, plane: [ 7.39584271e-01  6.73063969e-01  0.00000000e+00 -2.07784338e+05], inliers: 1690/2322\n",
      "name: 2_Walls_55, plane: [-7.47706169e-01 -6.64029732e-01 -0.00000000e+00 -2.06864370e+05], inliers: 2877/3587\n",
      "name: 2_Walls_56, plane: [-7.83158484e-01 -6.21822152e-01 -0.00000000e+00 -2.02332971e+05], inliers: 2022/4152\n",
      "name: 2_Walls_57, plane: [-7.46818545e-01 -6.65027865e-01 -0.00000000e+00 -2.06965423e+05], inliers: 3601/6645\n",
      "name: 2_Walls_58, plane: [-7.46376451e-01 -6.65524000e-01 -0.00000000e+00 -2.07016213e+05], inliers: 5038/7617\n",
      "name: 2_Walls_59, plane: [-7.43364061e-01 -6.68887041e-01 -0.00000000e+00 -2.07367677e+05], inliers: 63164/122669\n",
      "name: 2_Walls_60, plane: [-7.38891071e-01 -6.73824892e-01 -0.00000000e+00 -2.07846051e+05], inliers: 1587/2539\n",
      "name: 2_Walls_61, plane: [ 6.67004264e-01 -7.45053899e-01 -0.00000000e+00 -7.57983658e+04], inliers: 669/679\n",
      "name: 2_Walls_62, plane: [-6.63730148e-01  7.47972119e-01  0.00000000e+00 -7.67180323e+04], inliers: 7295/13337\n",
      "name: 2_Walls_63, plane: [-6.63903394e-01  7.47818349e-01  0.00000000e+00 -7.66705335e+04], inliers: 7325/10981\n",
      "name: 2_Walls_64, plane: [ 6.62443433e-01 -7.49111940e-01 -0.00000000e+00 -7.70765574e+04], inliers: 3931/3937\n",
      "name: 2_Walls_65, plane: [-7.45385433e-01 -6.66633750e-01 -0.00000000e+00 -2.07120876e+05], inliers: 3181/3201\n",
      "name: 2_Walls_66, plane: [ 7.43399072e-01  6.68848129e-01  0.00000000e+00 -2.07232902e+05], inliers: 26261/36557\n",
      "name: 2_Walls_67, plane: [-6.67813305e-01  7.44328818e-01  0.00000000e+00 -7.55795810e+04], inliers: 52383/59053\n",
      "name: 2_Walls_68, plane: [-6.78559958e-01 -7.34545018e-01 -0.00000000e+00 -2.13414111e+05], inliers: 8424/14901\n",
      "name: 2_Walls_69, plane: [-6.68155318e-01  7.44021821e-01  0.00000000e+00 -7.54958111e+04], inliers: 79270/158237\n",
      "name: 2_Walls_70, plane: [-7.44493530e-01 -6.67629676e-01 -0.00000000e+00 -2.07208727e+05], inliers: 120540/190850\n",
      "name: 2_Walls_71, plane: [ 6.66327772e-01 -7.45658970e-01 -0.00000000e+00 -7.59900396e+04], inliers: 65811/115456\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:    \n",
    "    #Compute the dominant plane on the point cloud\n",
    "    n.plane_model, inliers = n.resource.segment_plane(distance_threshold=0.03,\n",
    "                                            ransac_n=3,\n",
    "                                            num_iterations=1000)\n",
    "    \n",
    "    #get center of the face and postion it on the correct height (base constraint + base offset)   \n",
    "    n.faceCenter=n.resource.select_by_index(inliers).get_center()  \n",
    "    n.faceCenter[2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #compute the normal of the plane in 2D (third component should be zero, normal should point outwards of the wall)\n",
    "    n.normal=n.plane_model[:3]\n",
    "    n.normal[2]=0\n",
    "    n.normal/=np.linalg.norm(n.normal)\n",
    "\n",
    "\n",
    "    #compute the sign.\n",
    "    #if n.orientedBoundingBox width is > than 0.1, the sign is  given by the dotproduct of the normal of the face with the vector between the center of the face and the center of the oriented bounding box\n",
    "    boxCenter=n.orientedBoundingBox.get_center()\n",
    "    boxCenter[2]=n.base_constraint.height + n.base_offset\n",
    "    n.sign=np.sign(np.dot(n.normal,n.faceCenter-boxCenter))\n",
    "\n",
    "    #if n.orientedBoundingBox width < t_thickness, take a look at the ceiling and floor nodes to see on which side they are, and use them to spawn the wall away from these nodes\n",
    "    if n.orientedBoundingBox.extent[2]<=t_thickness:   \n",
    "        #combine list\n",
    "        combined_list = ceilingsNodes + floorsNodes\n",
    "        #create reference pcd from these resources\n",
    "        referencePcd,identityArray=gmu.create_identity_point_cloud([n.resource for n in combined_list if n.resource is not None])\n",
    "        #find nearest point near the top and the bottom \n",
    "        topPoint=copy.deepcopy(boxCenter)\n",
    "        topPoint[2]=n.base_constraint.height + n.base_offset+n.height\n",
    "        bottomPoint=boxCenter\n",
    "        idx,distances=gmu.compute_nearest_neighbors(np.asarray([topPoint,bottomPoint]),np.asarray(referencePcd.points)) \n",
    "        points=np.asarray(referencePcd.points)[idx[:,0]]\n",
    "\n",
    "\n",
    "        \n",
    "        #compute orthogonal distance to the plane and select node with lowest distance\n",
    "        idx=idx[np.argmin(np.absolute(np.einsum('i,ji->j',n.normal,points-boxCenter))) ][0]\n",
    "        index=identityArray[idx]\n",
    "        referenceNode=combined_list[index]\n",
    "        point=np.asarray(referencePcd.points)[idx]\n",
    "        point[2]=n.base_constraint.height + n.base_offset\n",
    "        n.sign=np.sign(np.dot(n.normal,point-boxCenter))\n",
    "    \n",
    "    #flip the normal if it points inwards\n",
    "    n.normal*=-1 if n.sign==-1 else 1\n",
    "\n",
    "    print(f'name: {n.name}, plane: {n.plane_model}, inliers: {len(inliers)}/{len(np.asarray(n.resource.points))}')      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall thickness (this seems very subjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, BB_extent: [6.49056159 4.75590426 0.10778002], wallThickness: 0.12399008990760982\n",
      "name: 2_Walls_44, BB_extent: [3.27018629 1.36183811 0.26310474], wallThickness: 0.20350508612633442\n",
      "name: 2_Walls_45, BB_extent: [0.94117845 0.89088775 0.40682449], wallThickness: 0.12\n",
      "name: 2_Walls_46, BB_extent: [1.69050668 0.96558248 0.17433685], wallThickness: 0.1708367589477503\n",
      "name: 2_Walls_47, BB_extent: [5.55492086 2.06237987 0.17774122], wallThickness: 0.1889883117936702\n",
      "name: 2_Walls_48, BB_extent: [3.05043157 1.48686731 0.19833939], wallThickness: 0.1960373945924063\n",
      "name: 2_Walls_49, BB_extent: [4.0895122  1.98675756 0.27309029], wallThickness: 0.19567083119821713\n",
      "name: 2_Walls_50, BB_extent: [5.62433934 5.54840923 0.17348883], wallThickness: 0.14428168432717453\n",
      "name: 2_Walls_51, BB_extent: [2.55619854 1.59419888 0.19475631], wallThickness: 0.20055854145596164\n",
      "name: 2_Walls_52, BB_extent: [11.42473702  4.53005322  0.23531543], wallThickness: 0.1671448362749318\n",
      "name: 2_Walls_53, BB_extent: [1.75734296 1.25369617 0.22822628], wallThickness: 0.19041883383709257\n",
      "name: 2_Walls_54, BB_extent: [2.82599232 1.227049   0.50021432], wallThickness: 0.4476431577580974\n",
      "name: 2_Walls_55, BB_extent: [2.6579637  1.23119646 0.58454775], wallThickness: 0.48777524007655326\n",
      "name: 2_Walls_56, BB_extent: [2.90521239 1.89350823 0.23104766], wallThickness: 0.24888810290785407\n",
      "name: 2_Walls_57, BB_extent: [2.83569922 2.4670596  0.21542609], wallThickness: 0.15242247991035981\n",
      "name: 2_Walls_58, BB_extent: [2.96194278 2.80615583 0.20620684], wallThickness: 0.20535936401912966\n",
      "name: 2_Walls_59, BB_extent: [13.57069653  5.034062    0.30030084], wallThickness: 0.21040153697848146\n",
      "name: 2_Walls_60, BB_extent: [2.83308443 1.20553822 0.67272874], wallThickness: 0.635954321355124\n",
      "name: 2_Walls_61, BB_extent: [1.66697008 0.17025913 0.07612989], wallThickness: 0.12\n",
      "name: 2_Walls_62, BB_extent: [3.87960586 3.45270705 0.30338106], wallThickness: 0.18407234792605517\n",
      "name: 2_Walls_63, BB_extent: [3.37910075 2.85551732 0.26692625], wallThickness: 0.17774464166330234\n",
      "name: 2_Walls_64, BB_extent: [2.41709861 1.13576832 0.08025841], wallThickness: 0.12\n",
      "name: 2_Walls_65, BB_extent: [3.44327873 2.12660409 0.10547739], wallThickness: 0.12\n",
      "name: 2_Walls_66, BB_extent: [11.50696358  4.81995421  0.24634289], wallThickness: 0.1561108383537229\n",
      "name: 2_Walls_67, BB_extent: [14.78533209  4.71847006  0.21178965], wallThickness: 0.1660593725106388\n",
      "name: 2_Walls_68, BB_extent: [4.78036601 2.48997993 0.19315087], wallThickness: 0.18315182112803005\n",
      "name: 2_Walls_69, BB_extent: [19.51740187  4.52674001  0.36618982], wallThickness: 0.24067357094945502\n",
      "name: 2_Walls_70, BB_extent: [15.54263312  4.69653653  0.46108953], wallThickness: 0.3264036760261852\n",
      "name: 2_Walls_71, BB_extent: [19.27025402  4.48536434  0.79311547], wallThickness: 0.5213392963238546\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    #compute the normals of the wall\n",
    "    pcd_tree = o3d.geometry.KDTreeFlann(n.resource)\n",
    "    n.resource.estimate_normals() if not n.resource.has_normals() else None\n",
    "\n",
    "    #for every 10th point in P, that has the same normal as the dominant plane, select nearest points in P that meet a distance threshold    \n",
    "    points=np.asarray(n.resource.points)[::100]\n",
    "    normals=np.asarray(n.resource.normals)[::100]\n",
    "    idx=np.where(np.absolute(np.einsum('i,ji->j',n.normal,normals))>0.9)\n",
    "    points=points[idx]\n",
    "    normals=normals[idx]\n",
    "    distances=[]\n",
    "\n",
    "    for p,q in zip(points,normals):\n",
    "        #compute distances\n",
    "        [k, idx, _] = pcd_tree.search_radius_vector_3d(p, t_distance)        \n",
    "        #retain only the distances for which the normal is within 0.7 radians of the normal of the point\n",
    "        kNormals=np.asarray(n.resource.normals)[idx]\n",
    "        indices=np.asarray(idx)[np.where(np.absolute(np.einsum('i,ji->j',q,kNormals))>0.9)]\n",
    "        #compute the dotproduct between the point and the normals of the points in the radius\n",
    "        vectors=p-np.asarray(n.resource.select_by_index(indices).points)\n",
    "        #keep the max distance (orthogonal distance between the planes)\n",
    "        distances.append(np.absolute(np.einsum('i,ji->j', q, vectors)).max())\n",
    "\n",
    "    #take the distance at the 99% percentile\n",
    "    distance = np.percentile(np.sort(np.array(distances)), 90) \n",
    "    n.wallThickness=distance if distance > t_thickness else t_thickness\n",
    "\n",
    "    print(f'name: {n.name}, BB_extent: {n.orientedBoundingBox.extent}, wallThickness: {n.wallThickness}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([n.resource for n in wallNodes if n.wallThickness <=t_thickness]+\n",
    "                                  [n.orientedBoundingBox for n in wallNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, wallLength: 5.875090390993783\n",
      "name: 2_Walls_44, wallLength: 1.3299927371738023\n",
      "name: 2_Walls_45, wallLength: 0.9033193318989302\n",
      "name: 2_Walls_46, wallLength: 1.0488921710960453\n",
      "name: 2_Walls_47, wallLength: 5.612618047537559\n",
      "name: 2_Walls_48, wallLength: 1.5416269829949627\n",
      "name: 2_Walls_49, wallLength: 1.8021875431290686\n",
      "name: 2_Walls_50, wallLength: 3.951299793593518\n",
      "name: 2_Walls_51, wallLength: 1.51635145998837\n",
      "name: 2_Walls_52, wallLength: 11.492814490999757\n",
      "name: 2_Walls_53, wallLength: 1.2115571956435773\n",
      "name: 2_Walls_54, wallLength: 1.5276557080598296\n",
      "name: 2_Walls_55, wallLength: 1.5745039117326889\n",
      "name: 2_Walls_56, wallLength: 1.9831065238089256\n",
      "name: 2_Walls_57, wallLength: 2.082775383487014\n",
      "name: 2_Walls_58, wallLength: 2.1176636313185613\n",
      "name: 2_Walls_59, wallLength: 13.488557866026992\n",
      "name: 2_Walls_60, wallLength: 1.7913149949269351\n",
      "name: 2_Walls_61, wallLength: 1.6917022341946941\n",
      "name: 2_Walls_62, wallLength: 2.5652901395733445\n",
      "name: 2_Walls_63, wallLength: 2.4680697645125003\n",
      "name: 2_Walls_64, wallLength: 1.1335777234066986\n",
      "name: 2_Walls_65, wallLength: 2.6259894770476273\n",
      "name: 2_Walls_66, wallLength: 11.210345152974082\n",
      "name: 2_Walls_67, wallLength: 14.700883926687267\n",
      "name: 2_Walls_68, wallLength: 4.838977374343751\n",
      "name: 2_Walls_69, wallLength: 19.59110304361644\n",
      "name: 2_Walls_70, wallLength: 15.717611341050992\n",
      "name: 2_Walls_71, wallLength: 19.64089805112757\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:     \n",
    "    \n",
    "    \n",
    "\n",
    "    #offset the center of the plane with half the wall thickness in the direction of the normal of the plane  \n",
    "    # wallCenter=n.faceCenter-n.sign*n.normal*n.wallThickness/2 \n",
    "    wallCenter=n.faceCenter-n.normal*n.wallThickness/2 \n",
    "\n",
    "    wallCenter[2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #project axis aligned bounding points on the plane\n",
    "    box=n.resource.get_axis_aligned_bounding_box()    \n",
    "    points=np.asarray(box.get_box_points())\n",
    "    points[:,2]=n.base_constraint.height + n.base_offset\n",
    "\n",
    "    #translate the points to the plane\n",
    "    vectors=points-wallCenter\n",
    "    translation=np.einsum('ij,j->i',vectors,n.normal)\n",
    "    points=points - translation[:, np.newaxis] * n.normal\n",
    "\n",
    "    # Calculate the pairwise distances between all boundary points\n",
    "    distances = np.linalg.norm(points[:, np.newaxis] - points, axis=2)\n",
    "\n",
    "    # Get the indices of the two points with the maximum distance\n",
    "    max_indices = np.unravel_index(np.argmax(distances), distances.shape)\n",
    "\n",
    "    # Retain only the two points with the maximum distance\n",
    "    n.boundaryPoints = points[max_indices,:]\n",
    "\n",
    "    #create the axis\n",
    "    n.axis=o3d.geometry.LineSet(points=o3d.utility.Vector3dVector(n.boundaryPoints),lines=o3d.utility.Vector2iVector([[0,1]])).paint_uniform_color([0,0,1])\n",
    "    n.startPoint=n.boundaryPoints[0]\n",
    "    n.endPoint=n.boundaryPoints[1]\n",
    "    # Calculate the length\n",
    "    n.wallLength = np.linalg.norm(n.boundaryPoints[0] - n.boundaryPoints[1])\n",
    "\n",
    "    print(f'name: {n.name}, wallLength: {n.wallLength}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o3d.visualization.draw_geometries([joined_pcd]+\n",
    "#                                   [n.orientedBoundingBox for n in wallNodes]+\n",
    "#                                   [n.axis for n in wallNodes]+\n",
    "#                                   [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(n.boundaryPoints)) for n in wallNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall Geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name: 2_Walls_43, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_44, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_45, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_46, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_47, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_48, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_49, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_50, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_51, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_52, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_53, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_54, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_55, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_56, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_57, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_58, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_59, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_60, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_61, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_62, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_63, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_64, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_65, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_66, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_67, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_68, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_69, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_70, wall: TriangleMesh with 8 points and 12 triangles.\n",
      "name: 2_Walls_71, wall: TriangleMesh with 8 points and 12 triangles.\n"
     ]
    }
   ],
   "source": [
    "for n in wallNodes:\n",
    "    pointList=[]\n",
    "    points=np.asarray(n.axis.points)\n",
    "    # pointList.extend(points+n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points+n.normal*n.wallThickness/2)\n",
    "\n",
    "    # pointList.extend(points-n.sign*n.normal*n.wallThickness/2)\n",
    "    pointList.extend(points-n.normal*n.wallThickness/2)\n",
    "\n",
    "    pointList.extend(np.array(pointList)+np.array([0,0,n.height]))\n",
    "    pcd=o3d.geometry.PointCloud(points=o3d.utility.Vector3dVector(pointList))\n",
    "\n",
    "    box=pcd.get_oriented_bounding_box()\n",
    "    n.wall=o3d.geometry.TriangleMesh.create_from_oriented_bounding_box(box)\n",
    "    n.wall.paint_uniform_color(ut.literal_to_array(n.color))\n",
    "    n.wallBox=o3d.geometry.LineSet.create_from_oriented_bounding_box(box)\n",
    "    n.wallBox.paint_uniform_color([0,0,1])\n",
    "\n",
    "    print(f'name: {n.name}, wall: {n.wall}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Open3D WARNING] GLFW Error: WGL: Failed to make context current: De ingang is ongeldig. \n"
     ]
    }
   ],
   "source": [
    "o3d.visualization.draw_geometries([joined_pcd]+\n",
    "                                  [n.wallBox for n in wallNodes]+\n",
    "                                  [n.axis for n in wallNodes]+\n",
    "                                  [o3d.geometry.PointCloud(o3d.utility.Vector3dVector(n.boundaryPoints)) for n in wallNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Wall topology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersect_line_2d(p0, p1, q0, q1,strict=True):\n",
    "    \"\"\"\n",
    "    Compute the intersection between two lines in 3D.\n",
    "    Each line is defined by a pair of points.\n",
    "    \n",
    "    Parameters:\n",
    "    - p0, p1: points (arrays) defining the first line.\n",
    "    - q0, q1: points (arrays) defining the second line.\n",
    "    - strict: if True, the intersection point must lie within the line segments.\n",
    "    \n",
    "    Returns:\n",
    "    - The intersection point as a numpy array if it exists, otherwise None.\n",
    "    \"\"\"\n",
    "    # Direction vectors of the lines\n",
    "    dp = p1 - p0\n",
    "    dq = q1 - q0\n",
    "    \n",
    "    # Matrix and vector for the linear system\n",
    "    A = np.vstack((dp, -dq)).T\n",
    "    b = q0 - p0\n",
    "    \n",
    "    # Solve the linear system\n",
    "    try:\n",
    "        t, u = np.linalg.solve(A, b)\n",
    "    except np.linalg.LinAlgError:\n",
    "        # The system is singular: lines are parallel or identical\n",
    "        return None\n",
    "    \n",
    "    # Intersection point\n",
    "    intersection = p0 + t * dp\n",
    "    \n",
    "    if strict:\n",
    "    # Since the system has a solution, check if it lies within the line segments\n",
    "        if np.allclose(intersection, q0 + u * dq):\n",
    "            return intersection\n",
    "        else:\n",
    "            return None\n",
    "    else:\n",
    "        return intersection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got scalar array instead:\narray=PointCloud with 128620 points..\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m referencePcd,identityArray\u001b[38;5;241m=\u001b[39mgmu\u001b[38;5;241m.\u001b[39mcreate_identity_point_cloud([w\u001b[38;5;241m.\u001b[39mresource \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m wallNodesBIM \u001b[38;5;28;01mif\u001b[39;00m w\u001b[38;5;241m!=\u001b[39mn])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m#compute nearest neighbors\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m idx,distances\u001b[38;5;241m=\u001b[39m\u001b[43mgmu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_nearest_neighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxisPoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43mreferencePcd\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#filter out the points that are too far away\u001b[39;00m\n\u001b[0;32m     20\u001b[0m idx\u001b[38;5;241m=\u001b[39midx[np\u001b[38;5;241m.\u001b[39mwhere(distances\u001b[38;5;241m<\u001b[39mt_intersection)]\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\geomapi\\utils\\geometryutils.py:334\u001b[0m, in \u001b[0;36mcompute_nearest_neighbors\u001b[1;34m(query_points, reference_points, n)\u001b[0m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_nearest_neighbors\u001b[39m(query_points:np\u001b[38;5;241m.\u001b[39mndarray,reference_points:np\u001b[38;5;241m.\u001b[39mndarray, n:\u001b[38;5;28mint\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39mTuple[np\u001b[38;5;241m.\u001b[39mndarray,np\u001b[38;5;241m.\u001b[39mndarray]:\n\u001b[0;32m    322\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute nearest neighbors (indices and distances) from querry to reference points.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m \n\u001b[0;32m    324\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;124;03m        np.array[n,2]: indices, distances\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m    \n\u001b[1;32m--> 334\u001b[0m     nbrs \u001b[38;5;241m=\u001b[39m \u001b[43mNearestNeighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkd_tree\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreference_points\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m     distances,indices, \u001b[38;5;241m=\u001b[39m nbrs\u001b[38;5;241m.\u001b[39mkneighbors(query_points)\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m indices,distances\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\sklearn\\neighbors\\_unsupervised.py:175\u001b[0m, in \u001b[0;36mNearestNeighbors.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;66;03m# NearestNeighbors.metric is not validated yet\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    157\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the nearest neighbors estimator from the training dataset.\u001b[39;00m\n\u001b[0;32m    160\u001b[0m \n\u001b[0;32m    161\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m        The fitted nearest neighbors estimator.\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 175\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\sklearn\\neighbors\\_base.py:498\u001b[0m, in \u001b[0;36mNeighborsBase._fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, (KDTree, BallTree, NeighborsBase)):\n\u001b[1;32m--> 498\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_algorithm_metric()\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetric_params \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m check_array(X, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\Maarten\\.conda\\envs\\geomapi_installed\\lib\\site-packages\\sklearn\\utils\\validation.py:930\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_2d:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;66;03m# If input is scalar raise error\u001b[39;00m\n\u001b[0;32m    929\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 930\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    931\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got scalar array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    932\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    933\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    934\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    935\u001b[0m         )\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got scalar array instead:\narray=PointCloud with 128620 points..\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "#in preparation, compute orthonal curves to the wall axes at the start and end point\n",
    "for n in wallNodesBIM:\n",
    "    n.orthogonalStartpoint = n.startPoint + n.normal * n.wallThickness/2\n",
    "    n.orthogonalEndpoint = n.endPoint + n.normal * n.wallThickness/2     \n",
    "\n",
    "#next, investigate the connections between the walls\n",
    "for n in wallNodesBIM:\n",
    "    #gather the start and end point the nearby walls\n",
    "    axisPoints=np.array([n.startPoint,n.endPoint])\n",
    "    axisPointsOthogonal=np.array([n.orthogonalStartpoint,n.orthogonalEndpoint])\n",
    "\n",
    "    #create reference point cloud of all wall start-and endpoints\n",
    "    referencePcd,identityArray=gmu.create_identity_point_cloud([w.resource for w in wallNodesBIM if w!=n])\n",
    "\n",
    "    #compute nearest neighbors\n",
    "    idx,distances=gmu.compute_nearest_neighbors(axisPoints,referencePcd,n=10)\n",
    "    #filter out the points that are too far away\n",
    "    idx=idx[np.where(distances<t_intersection)]\n",
    "    points=np.asarray(referencePcd.points)[idx]\n",
    "    indices=identityArray[idx]\n",
    "    nearbyWalls=[wallNodes[i] for i in indices]\n",
    "    print(f'found {len(nearbyWalls)} nearby walls for {n.name}')\n",
    "\n",
    "    #1.compute the intersections between neighboring curves\n",
    "    for w in nearbyWalls:\n",
    "        intersection_point = intersect_line_2d(n.startPoint, n.endPoint, w.startPoint, w.endPoint,strict=False)\n",
    "        if intersection_point is not None:\n",
    "            #compute the distance between the intersection point and the wall axes\n",
    "            d = distance.euclidean(intersection_point, n.startPoint)\n",
    "            #filter out the points that are too far away\n",
    "            if d<t_intersection:\n",
    "                print(f'intersection between {n.name} and {w.name} at {intersection_point}, distance: {d}',strict=False)\n",
    "                \n",
    "    #2.compute a orthogonal curve to the wall axis at the start and end point\n",
    "    for w in nearbyWalls:\n",
    "        intersection_point = intersect_line_2d(n.orthogonalStartpoint, n.orthogonalEndpoint, w.startPoint, w.endPoint)\n",
    "        if intersection_point is not None:\n",
    "            #compute the distance between the intersection point and the wall axes\n",
    "            d = distance.euclidean(intersection_point, n.orthogonalStartpoint)\n",
    "            #filter out the points that are too far away\n",
    "            if d<t_orthogonal:\n",
    "                print(f'orthogonal intersection between {n.name} and {w.name} at {intersection_point}, distance: {d}')\n",
    "                \n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "'break' outside loop (668683560.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[163], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    break\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m 'break' outside loop\n"
     ]
    }
   ],
   "source": [
    "break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON data written to file: c:\\Users\\Maarten\\OneDrive - KU Leuven\\2024-05 CVPR scan-to-BIM challenge\\data\\beton_walls.json\n"
     ]
    }
   ],
   "source": [
    "#declare json\n",
    "json_data = {\n",
    "        \"filename\": ut.get_filename(json_output_path),\n",
    "        \"objects\": []\n",
    "    }\n",
    "#fill json\n",
    "for n in wallNodes:\n",
    "    obj = {\n",
    "            \"name\": n.name,\n",
    "            \"base_constraint\":n.base_constraint.name,\n",
    "            \"base_offset\":n.base_offset,\n",
    "            \"top_constraint\":n.top_constraint.name,\n",
    "            \"top_offset\":n.top_offset,\n",
    "            \"height\": n.height,\n",
    "            \"wallThickness\": n.wallThickness,\n",
    "            \"wallLength\": n.wallLength,\n",
    "            \"normal\": {\n",
    "                \"x\": n.normal[0],\n",
    "                \"y\": n.normal[1],\n",
    "                \"z\": n.normal[2]\n",
    "            },\n",
    "            \"startpoint\": {\n",
    "                \"x\": n.boundaryPoints[0][0],\n",
    "                \"y\": n.boundaryPoints[0][1],\n",
    "                \"z\": n.boundaryPoints[0][2]\n",
    "            }\n",
    "            ,\n",
    "            \"endpoint\": {\n",
    "                \"x\": n.boundaryPoints[1][0],\n",
    "                \"y\": n.boundaryPoints[1][1],\n",
    "                \"z\": n.boundaryPoints[1][2]\n",
    "            }\n",
    "            }\n",
    "    json_data[\"objects\"].append(obj)\n",
    "#write this information to the 3D detection json\n",
    "with open(json_output_path, \"w\") as json_file:\n",
    "    json.dump(json_data, json_file, indent=4)\n",
    "print(\"JSON data written to file:\", json_output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "obj with walls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_obj_with_submeshes(filename, meshes, mesh_names):\n",
    "    \"\"\"\n",
    "    Write multiple Open3D TriangleMesh objects to a single OBJ file with submeshes.\n",
    "\n",
    "    Parameters:\n",
    "    - filename: str, the name of the output OBJ file.\n",
    "    - meshes: list of open3d.geometry.TriangleMesh, the meshes to write.\n",
    "    - mesh_names: list of str, the names of the submeshes.\n",
    "    \"\"\"\n",
    "    if len(meshes) != len(mesh_names):\n",
    "        raise ValueError(\"meshes and mesh_names must have the same length\")\n",
    "\n",
    "    vertex_offset = 1  # OBJ files are 1-indexed\n",
    "    with open(filename, 'w') as file:\n",
    "        for mesh, name in zip(meshes, mesh_names):\n",
    "            file.write(f\"g {name}\\n\")  # Start a new group for the submesh\n",
    "\n",
    "            # Write vertices\n",
    "            for vertex in mesh.vertices:\n",
    "                file.write(f\"v {vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "\n",
    "            # Write faces, adjusting indices based on the current offset\n",
    "            for triangle in mesh.triangles:\n",
    "                adjusted_triangle = triangle + vertex_offset\n",
    "                file.write(f\"f {adjusted_triangle[0]} {adjusted_triangle[1]} {adjusted_triangle[2]}\\n\")\n",
    "\n",
    "            # Update the vertex offset for the next mesh\n",
    "            vertex_offset += len(mesh.vertices)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming mesh1 and mesh2 are your Open3D TriangleMesh objects\n",
    "mesh1 = o3d.geometry.TriangleMesh.create_sphere(radius=1.0)\n",
    "mesh1.compute_vertex_normals()\n",
    "\n",
    "mesh2 = o3d.geometry.TriangleMesh.create_box(width=1.0, height=1.0, depth=1.0)\n",
    "mesh2.compute_vertex_normals()\n",
    "\n",
    "write_obj_with_submeshes(geometry_output_path, [n.wall for n in wallNodes], [n.name for n in wallNodes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "graph with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[a rdfg:Graph;rdflib:storage [a rdflib:Store;rdfs:label 'Memory']].\n"
     ]
    }
   ],
   "source": [
    "wallNodesBIM=[]\n",
    "for n in wallNodes:\n",
    "    b=BIMNode(subject=n.subject+'_BIM',\n",
    "            derivedFrom=n.subject, #this should be a URI\n",
    "            resource=n.wall,\n",
    "            base_constraint=n.base_constraint.subject,\n",
    "            base_constraint_name=n.base_constraint.name,\n",
    "            base_offset=n.base_offset,\n",
    "            top_constraint=n.top_constraint.subject,\n",
    "            top_constraint_name=n.top_constraint.name,\n",
    "            top_offset=n.top_offset,\n",
    "            height=n.height,\n",
    "            wallThickness=n.wallThickness,\n",
    "            wallLength=n.wallLength,\n",
    "            normal=n.normal,\n",
    "            startpoint=n.boundaryPoints[0],\n",
    "            endpoint=n.boundaryPoints[1],\n",
    "            color=n.color)\n",
    "    wallNodesBIM.append(b)\n",
    "new_graph=tl.nodes_to_graph(wallNodesBIM,overwrite=True)\n",
    "\n",
    "#remove all BIM nodes from original graph\n",
    "for n in wallNodesBIM:\n",
    "    graph.remove((URIRef(n.subject),None,None))\n",
    "graph=graph+new_graph\n",
    "print(graph.serialize(graphPath, format=\"turtle\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geomapi_installed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
